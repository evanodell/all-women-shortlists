---
title: "All Women Shortlists Methodology"
bibliography: women.bib
csl: apa.csl
lof: yes
lot: yes
output:
  bookdown::word_document2:
    df_print: paged
    toc: yes
    toc_depth: 3
  bookdown::html_document2:
    df_print: paged
    toc: yes
    toc_depth: 3
    number_sections: true
  word_document:
    toc: yes
    toc_depth: 3
    number_sections: true
  pdf_document:
    toc: yes
    toc_depth: 3
    number_sections: true
    includes:  
      in_header: preamble.tex
link-citations: yes
editor_options:
  chunk_output_type: console
always_allow_html: yes
fig_caption: true
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE)
```


```{r setup, include = FALSE}
library(reticulate)

use_condaenv(condaenv = "spacy_condaenv", 
             conda = "/Users/evanodell/Documents/anaconda3/bin/conda")
```

\clearpage

# Descriptive Statistics

Table 1 shows the number of Labour MPs elected in each general election from 1997 to 2015, including newly elected MPs (the ``intake''), the number of newly elected MPs from all women shortlists (AWS), and the number of candidates selected through all women shortlists. Data in Table 1 is from the House of Commons Library [@kelly2016; @audickas2017]. All women shortlists were not used by Labour during the 2001 General Election.

```{r lab-desc-stats-table, echo=FALSE, message=FALSE, results='asis'}
library(flextable)
library(dplyr)

labour_intakes_table <- tibble::tribble(
  ~general_election, ~total_mps, ~total_labour_mps, ~total_female_labour_mps, ~newly_elected_mps, ~intake_women, ~intake_short_list, ~nominated_short_list,
  1997L, 659L, 418L, "101 (24%)", 177L, "64 (36%)", 35L, 38L,
  2001L, 659L, 412L, "95 (23%)", 38L, "4 (11%)", 0L, 0L,
  2005L, 646L, 355L, "98 (28%)", 40L, "26 (65%)", 23L, 30L,
  2010L, 650L, 258L, "81 (31%)", 64L, "32 (50%)", 28L, 63L,
  2015L, 650L, 232L, "99 (43%)", 49L, "31 (63%)", 31L, 77L
)

# | General Election | Total MPs | Total Labour MPs | Total Female Labour MPs | Percentage Women MPs | Newly elected MPs | Intake Women | Percentage Intake Women | Intake Shortlist | Nominated Shortlist |
# |------------------|-----------|------------------|-------------------------|----------------------|-------------------|--------------|-------------------------|-------------------|----------------------|
# | 1997 | 659 | 418 | 101 | 24.2% | 177 | 64 | 36% | 35 | 38 |
# | 2001 | 659 | 412 | 95 | 23.1% | 38 | 4 | 11% | 0 | 0 |
# | 2005 | 646 | 355 | 98 | 27.6% | 40 | 26 | 65% | 23 | 30 |
# | 2010 | 650 | 258 | 81 | 31.4% | 64 | 32 | 50% | 28 | 63 |
# | 2015 | 650 | 232 | 99 | 42.7% | 49 | 31 | 63% | 31 | 77 |

labour_intakes_table <- regulartable(labour_intakes_table)
labour_intakes_table <- labour_intakes_table %>%
  align(align = "right", part = "all")
labour_intakes_table

```

Table 2 shows the total size of the dataset in speeches and words by each party, including by gender for each party, and in the case of female Labour MPs, by AWS status. Details on inclusion criteria are given [below](#methodology).

```{r speech-stats-table, echo=FALSE, results = 'asis'}
library(kableExtra)
library(knitr)
library(dplyr)
library(readr)
library(knitr)
library(kableExtra)
library(dplyr)

speech_sum_table <- read_rds("data/speech_sum_table.rds")
## table for total MP numbers

lab_nums <- read_rds("data/lab_nums.rds")

speech_sum_table2 <- speech_sum_table %>% 
  mutate(speeches = formatC(speeches, big.mark = ","),
         words = formatC(words, big.mark = ","))

speech_sum_table2 <- regulartable(speech_sum_table2)
speech_sum_table2 <- merge_v(speech_sum_table2, ~ party_group) %>% 
  italic(i = ~ gender == "Non-All Women Shortlists" | 
          gender == "All Women Shortlists", 
        j = ~ gender) %>%
  align(j = c("party_group", "gender"), 
              align = "left", part = "all") %>% 
  align(j = c("speeches", "words"), 
        align = "right", part = "all")  %>% autofit()
speech_sum_table2
```


# Methodology

Previous research on gender differences in political speech patterns has focused on differences between male and female politicians [@yu2014] or on variations in Hilary Clinton's speech patterns [@jones2016; @bligh2010]. This paper focuses on differences in speech patterns between female Labour MPs nominated through All Women Shortlists (AWS) and female Labour MPs nominated through open shortlists. We examined differences in speaking styles using the `Linguistic Inquiry and Word Count 2015` (LIWC) dictionary [@pennebaker2015] and the `spaCy` [@honnibal2017] Parts-of-Speech (POS) tagger. We examined differences in the topics discussed by AWS and non-AWS MPs, using ${\chi}^2$ tests for individual words and for bigrams. We trained a Naive Bayes classifier to distinguish AWS and non-AWS speeches. We used structured topic models (STM) to identify the topics discussed by AWS and non-AWS MPs.

To account for the possible effects of age, parliamentary experience and cohort, and in order to compare women selected through all women shortlists to women who were not (but who theoretically had the opportunity to contest all-women shortlists), our analysis is been restricted only to Labour MPs first elected to the House of Commons in the 1997 General Election, up to but excluding the 2017 General Election. Comparisons between MPs of different parties are also restricted to MPs first elected in the 1997 General Election, and before the 2017 General Election. Speeches made by the Speaker, including Deputy Speakers, were also excluded. Words contained in parentheses were removed, as they are added by Hansard to provide additional information not actually spoken by the MP.[^1] Speeches and data on MPs' gender and party affiliation are from a previously assembled dataset [@odell2018]. Information on candidates selected through all women shortlists is from the House of Commons Library [@kelly2016]. Unsuccessful General Election candidates selected through all women shortlists who were subsequently elected in a byelection are classified as having been selected on an all women shortlist, regardless of the selection process for that byelection. Speeches made by MPs while suspended from the Labour party where classified the same as if they had not been suspended. The dataset includes `r sum(lab_nums$distinct)` different Labour MPs, `r sum(lab_nums$distinct[lab_nums$gender=="Female"])` female MPs, `r lab_nums$distinct[lab_nums$gender=="Female" & lab_nums$short_list==TRUE]` elected from All Women Shortlists and `r lab_nums$distinct[lab_nums$gender=="Female" & lab_nums$short_list==FALSE]` elected from open shortlists, along with `r lab_nums$distinct[lab_nums$gender=="Male"]` male MPs.


# Results

## Linguistic Inquiry and Word Count

Word classification used the `Linguistic Inquiry and Word Count 2015` (LIWC) dictionary [@pennebaker2015] and tokenising tools from the `Quanteda` `R` package [@benoit2018]. Word counts and words-per-sentence, and calculations for determining grade level [@kincaid1975] were produced using `stringi` [@gagolewski2018], an `R` wrapper to the ICU regex library.

Following research by @yu2014 and @newman2008 on gender differences in language, we focused on the following LIWC categories to compare MPs' speeches:

* All Pronouns (pronoun)<!-- Feminine: -->
* First person singular pronouns (i) <!-- Feminine: -->
* First person plural pronouns (we)<!-- Masculine: -->
* Verbs (verb)<!-- Feminine: -->
* Auxiliary verbs (auxverb) <!-- Feminine: -->
* Social processes (social) <!-- Feminine: -->
* Positive emotions (posemo) <!-- Feminine: -->
* Negative emotions (negemo) <!-- Feminine: -->
* Tentative words (tentat)<!-- Feminine: -->
* Articles (article) <!-- Masculine: -->
* Prepositions (preps) <!-- Masculine: -->
* Anger words (anger)<!-- Masculine: -->
* Swear words (swear)<!-- Masculine: -->
* Cognitive processes (cogproc)<!-- Masculine: -->
* Words longer than six letters (Sixltr)<!-- Masculine: -->

We also included mean words-per-sentence (WPS), total speach word count (WC) and Fleschâ€“Kincaid grade level (FK) [@kincaid1975], calculated using the `Quanteda` [@benoit2018] and `stringi` [@gagolewski2018] `R` packages.

### Women vs Men

```{r gender-effect-sizes-table, echo=FALSE, results = 'asis'}
library(readr)
library(flextable)

fem_mac_df <- read_rds("data/fem_mac_df.rds")
fem_mac_df <- regulartable(fem_mac_df)
fem_mac_df <- fem_mac_df %>%  align(align = "right", part = "all")  %>%
  align(j = c("word_type", "magnitude"), 
              align = "left", part = "all")  %>% autofit()
fem_mac_df
```

There are no categories where gender differences meet the effect size threshold of $|0.2|$ suggested by Cohen [-@cohen1988, 25--26] to indicate a small effect. 4 categories -- words with more than six letters, prepositions, words-per-sentence and Flesh-Kincaid grade level -- met or exceeded the $|0.1|$ threshold suggested by @newman2008.

### Shortlists vs Non-Shortlists

```{r liwc-shortlists, include=FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(purrr)
library(effsize)

fem_mac <- c("pronoun", "i", "we", "verb", "auxverb", "social", "posemo", 
             "negemo", "tentat", "Sixltr",  "article", "prep",
             "anger", "swear", "cogproc", "WPS", "WC", "FK")

lab_liwc_women <- read_rds("data/lab_liwc_women.rds")

## Group by gender, short_lsit, see what's up
cols <- names(lab_liwc_women)[4:92]

lab_liwc_women_mean <- list(c("WC"), cols) %>%
 map2(lst(mean=mean, funs(weighted.mean(., WC, na.rm=TRUE))),
  ~ lab_liwc_women %>%
   group_by(short_list, y_since_start) %>%
   summarise_at(.x, .y)) %>%
 reduce(inner_join)

lab_liwc_women_tidy_mean <- gather(lab_liwc_women_mean, "attribute",
                                   "weighted_mean", -short_list,
                                   -y_since_start) 

lab_liwc_women_sd <- list(c("WC"), cols) %>%
 map2(lst(mean=mean, funs(sd(., na.rm=TRUE))),
  ~ lab_liwc_women %>%
   group_by(gender, short_list, y_since_start) %>%
   summarise_at(.x, .y)) %>%
 reduce(inner_join)

lab_liwc_women_tidy_sd <- gather(lab_liwc_women_sd, "attribute",
                                 "sd", -short_list, -gender,
                                 -y_since_start) 

## Joining together the SD and Means to get CIs
lab_liwc_women2 <- left_join(lab_liwc_women_tidy_mean,
                             lab_liwc_women_tidy_sd) %>% 
 left_join(lab_liwc_women %>% 
    group_by(gender, short_list, y_since_start) %>% summarise(n=n())) %>%
 mutate(se = sd / sqrt(n),
   lower_ci = weighted_mean - qt(1 - (0.05 / 2), n - 1) * se,
   upper_ci = weighted_mean + qt(1 - (0.05 / 2), n - 1) * se)

lab_liwc_women2_subset <- lab_liwc_women2 %>%
  filter(attribute %in% c(fem_mac, "WC"))

```

Figure \@ref(fig:sl-key-y-since-start) shows changes in the occurrences of selected LIWC terms, words-per-sentence, total word count and Fleschâ€“Kincaid grade level, over the course of an MP's career, as measured since the time an MP was first elected. There do not appear to be any notable changes in speaking style over the course of female Labour MPs' careers. Figure \@ref(fig:sl-key-date) shows changes in the occurrences of the same selected terms from 1997--2017. As in Figure \@ref(fig:sl-key-y-since-start), there do not appear to be any meaningful trends in the use of the selected terms over time.

```{r sl-key-y-since-start, echo=FALSE, fig.cap="Occurrence of selected LIWC terms, by time as MP", fig.height=8}
library(ggplot2)

lab_liwc_women2_subset$attribute <- recode(lab_liwc_women2_subset$attribute,
               "pronoun" = "All pronouns",
               "i" = "First person\nsingular pronouns",
               "verb" = "Verbs",
               "auxverb" = "Auxiliary verbs",
               "social" = "Social processes ",
               "posemo" = "Positive emotions",
               "negemo" = "Negative emotions",
               "tentat" = "Tentative words",
               "Sixltr" = "More than six letters",
               "we" = "First person\nplural pronouns",
               "article" = "Articles",
               "prep" = "Prepositions",
               "anger" = "Anger words",
               "swear" = "Swear words",
               "cogproc" = "Cognitive processes",
               "WPS" = "Words per sentence",
               "WC" = "Word count",
               "FK" = "Flesh-Kincaid Grade Level")

lab_liwc_women2_subset$short_list <- recode(
  as.factor(lab_liwc_women2_subset$short_list), 
  "FALSE" = "Open ShortList",
  "TRUE" = "All Women Shortlist")

p01_sl_y_since_start <- ggplot(data = lab_liwc_women2_subset %>%
                                 filter(attribute != "Words per sentence",
                                        attribute != "Word count",
                                        attribute != "Flesh-Kincaid Grade Level"),
                               aes(x = y_since_start, y = weighted_mean,
                                   colour = short_list)) + 
  geom_line(alpha=0.7) +
  scale_y_continuous(labels = function(x) paste0(x, "%")) +
  facet_wrap(~attribute) + 
  labs(colour = "",
       x = "Weighted Mean",
       y = "Year") + 
  theme(legend.position = "bottom")

ggsave("p01_sl_y_since_start.svg", plot = p01_sl_y_since_start,
       path="plots", device = "svg", width = 20, height = 20, units = "cm")

p01_sl_y_since_start
```


```{r sl-key-date, echo=FALSE, fig.cap="Occurrence of selected LIWC terms, by date", fig.height=8}
library(ggplot2)
library(lubridate)

cols <- names(lab_liwc_women)[4:92]

lab_liwc_women$quarter <- quarter(lab_liwc_women$speech_date, with_year = TRUE)

lab_liwc_women_mean_date <- list(c("WC"), cols) %>%
 map2(lst(mean=mean, funs(weighted.mean(., WC, na.rm=TRUE))),
  ~ lab_liwc_women %>%
   group_by(short_list, quarter) %>%
   summarise_at(.x, .y)) %>%
 reduce(inner_join)

lab_liwc_women_tidy_mean_date <- gather(lab_liwc_women_mean_date, "attribute",
                                   "weighted_mean", -short_list,
                                   -quarter) 

lab_liwc_women_sd_date <- list(c("WC"), cols) %>%
 map2(lst(mean=mean, funs(sd(., na.rm=TRUE))),
  ~ lab_liwc_women %>%
   group_by(gender, short_list, quarter) %>%
   summarise_at(.x, .y)) %>%
 reduce(inner_join)

lab_liwc_women_tidy_sd_date <- gather(lab_liwc_women_sd_date, "attribute",
                                 "sd", -short_list, -gender,
                                 -quarter) 

## Joining together the SD and Means to get CIs
lab_liwc_women2_date <- left_join(lab_liwc_women_tidy_mean_date,
                             lab_liwc_women_tidy_sd_date) %>% 
 left_join(lab_liwc_women %>% 
    group_by(gender, short_list, quarter) %>% summarise(n=n())) %>%
 mutate(se = sd / sqrt(n),
   lower_ci = weighted_mean - qt(1 - (0.05 / 2), n - 1) * se,
   upper_ci = weighted_mean + qt(1 - (0.05 / 2), n - 1) * se)

lab_liwc_women2_subset_date <- lab_liwc_women2_date %>%
  filter(attribute %in% c(fem_mac, "WC"))

lab_liwc_women2_subset_date$attribute <- recode(
  lab_liwc_women2_subset_date$attribute,
               "pronoun" = "All pronouns",
               "i" = "First person\nsingular pronouns",
               "verb" = "Verbs",
               "auxverb" = "Auxiliary verbs",
               "social" = "Social processes ",
               "posemo" = "Positive emotions",
               "negemo" = "Negative emotions",
               "tentat" = "Tentative words",
               "Sixltr" = "More than six letters",
               "we" = "First person\nplural pronouns",
               "article" = "Articles",
               "prep" = "Prepositions",
               "anger" = "Anger words",
               "swear" = "Swear words",
               "cogproc" = "Cognitive processes",
               "WPS" = "Words per sentence",
               "WC" = "Word count",
               "FK" = "Flesh-Kincaid Grade Level")

lab_liwc_women2_subset_date$short_list <- recode(
  as.factor(lab_liwc_women2_subset_date$short_list), 
  "FALSE" = "Open ShortList",
  "TRUE" = "All Women Shortlist")

p02_sl_date <- ggplot(data = lab_liwc_women2_subset_date %>%
                        filter(attribute != "Words per sentence",
                               attribute != "Word count",
                               attribute != "Flesh-Kincaid Grade Level"),
                      aes(x = quarter, y = weighted_mean, 
                          colour = short_list)) + 
  geom_line(alpha=0.7) +
  scale_y_continuous(labels = function(x) paste0(x, "%")) +
  facet_wrap(~attribute) + 
  labs(colour = "",
       x = "Weighted Mean",
       y = "Year") + 
  theme(legend.position = "bottom")

ggsave("p02_sl_date.svg", plot = p02_sl_date,
       path="plots", device = "svg", width = 20, height = 20, units = "cm")

p02_sl_date
```


```{r sl-effect-sizes, echo=FALSE, results = 'asis'}
fem_mac_df_sl <- read_rds("data/fem_mac_df_sl.rds")
fem_mac_df_sl <- regulartable(fem_mac_df_sl)
fem_mac_df_sl <- fem_mac_df_sl %>%  align(align = "right", part = "all") %>%
  align(j = c("word_type", "magnitude"), 
              align = "left", part = "all")  %>% autofit()
fem_mac_df_sl
```

There are no categories among female Labour MPs by selection process meeting the $|0.2|$ threshold. Only one category -- first person plural pronouns, _d_=0.19 -- exceeded $|0.1|$.

### Conservatives vs Labour

```{r tory-labour-effect-sizes-table, echo=FALSE, results = 'asis'}
library(knitr)
library(kableExtra)

lab_con_df <- read_rds("data/lab_con_df.rds")

lab_con_df <- regulartable(lab_con_df)
lab_con_df <- lab_con_df %>%  align(align = "right", part = "all")  %>%
  align(j = c("word_type", "magnitude"), 
              align = "left", part = "all")  %>% autofit()
lab_con_df
```

There are no categories with effect sizes exceeding $|0.2|$ between Labour and Conservative MPs, and only one (first person plural pronouns) exceeding $|0.1|$.


### All MPs Gender Differences

There are no categories with effect sizes exceeding $|0.2|$ when comparing all male and female MPs elected from 1997 onwards. There is only one category, "Articles", with an effect size of 0.11, greater than the $|0.1|$ threshold suggested by @newman2008.

```{r all-party-effect-sizes, echo=FALSE, results = 'asis'}
library(knitr)
library(kableExtra)
library(readr)
all_party_gender_df <- read_rds("data/all_party_gender_df.rds")

all_party_gender_df <- regulartable(all_party_gender_df)
all_party_gender_df <- all_party_gender_df %>%  
  align(align = "right", part = "all")  %>%
  align(j = c("word_type", "magnitude"), 
              align = "left", part = "all")  %>% autofit()
all_party_gender_df
```


## POS Analysis

```{r tag-means, include=FALSE}
library(readr)
library(purrr)
library(dplyr)
library(tidyr)

ano_lab_tag <- read_rds("data/ano_lab_tag.rds")

ano_lab_tag_gender <- ano_lab_tag %>% 
  select(NN, NNS, gender) %>% 
  #gather(key = "type", value = "value", NN, NNS) %>%
  group_by(gender)

ano_lab_tag_gender2 <- ano_lab_tag_gender %>% 
  gather(key = "type", value = "value", NN, NNS) %>%
  group_by(gender, type) %>%
  summarise(mean = mean(value, na.rm = TRUE),
            sd = sd(value, na.rm = TRUE))

ano_lab_tag_sl <- ano_lab_tag %>%
  select(NN, NNS, short_list, gender) %>% 
  #gather(key = "type", value = "value", NN, NNS) %>%
  group_by(short_list) %>% filter(gender == "Female") %>% select(-gender)

ano_lab_tag_sl2 <- ano_lab_tag_sl %>% 
  gather(key = "type", value = "value", NN, NNS) %>%
  group_by(short_list, type) %>%
  summarise(mean = mean(value, na.rm = TRUE),
            sd = sd(value, na.rm = TRUE))
```

```{r pos-means, include=FALSE}
library(readr)
library(purrr)
library(dplyr)
library(tidyr)

ano_lab_pos <- read_rds("data/ano_lab_pos.rds")

ano_lab_pos_gender <- ano_lab_pos %>% 
  select(NOUN, ADV, VERB, ADJ, gender) %>% 
  group_by(gender)

ano_lab_pos_gender2 <- ano_lab_pos_gender %>% 
  gather(key = "type", value = "value", NOUN, ADV, VERB, ADJ) %>%
  group_by(gender, type) %>%
  summarise(mean = mean(value, na.rm = TRUE),
            sd = sd(value, na.rm = TRUE))

ano_lab_pos_sl <- ano_lab_pos %>%
  select(NOUN, ADV, VERB, ADJ, short_list, gender) %>% 
  group_by(short_list) %>% filter(gender == "Female") %>% select(-gender)

ano_lab_pos_sl2 <- ano_lab_pos_sl %>% 
  gather(key = "type", value = "value", NOUN, ADV, VERB, ADJ) %>%
  group_by(short_list, type) %>%
  summarise(mean = mean(value, na.rm = TRUE),
            sd = sd(value, na.rm = TRUE))
```

```{r pos-tag-tables, include=FALSE}
library(effsize)

pos_df_gender <- bind_rows(ano_lab_pos_gender2, ano_lab_tag_gender2)

pos_df_gender <- pos_df_gender %>% 
  gather(variable, value, -(gender:type)) %>%
  unite(temp, gender, variable) %>%
  spread(temp, value)

pos_df_gender$cohen_d <- NA
pos_df_gender$magnitude <- NA

for (i in pos_df_gender$type) {
  
  if (i=="NN" || i == "NNS") {
  
   d <- (cohen.d(ano_lab_tag[[i]], ano_lab_tag$gender,
                na.rm = TRUE, noncentral = FALSE, pooled = TRUE))
  } else {
    
     d <- (cohen.d(ano_lab_pos[[i]], ano_lab_pos$gender,
                na.rm = TRUE, noncentral = FALSE, pooled = TRUE))
  }
   
  pos_df_gender$cohen_d[pos_df_gender$type==i] <- (d$estimate[[1]])
  
  pos_df_gender$magnitude[pos_df_gender$type==i] <- as.character(d$magnitude[[1]])
}

pos_df_gender$type <- factor(pos_df_gender$type, levels=c("NOUN", "NNS", "NN", "ADJ", "ADV", "VERB"))

## Recoding pos_df_sl$type into pos_df_sl$type_rec
pos_df_gender$type <- recode(pos_df_gender$type,
               "NOUN" = "All Nouns",
               "NNS" = "Plural Nouns",
               "NN" = "Singular Nouns",
               "ADJ" = "Adjectives",
               "ADV" = "Adverbs",
               "VERB" = "Verbs")

pos_df_gender <- pos_df_gender[order(pos_df_gender$type),]

pos_df_gender[2:5] <- pos_df_gender[2:5] * 100

pos_df_sl <- bind_rows(ano_lab_pos_sl2, ano_lab_tag_sl2)

pos_df_sl <- pos_df_sl %>% 
  gather(variable, value, -(short_list:type)) %>%
  unite(temp, short_list, variable) %>%
  spread(temp, value)

pos_df_sl$cohen_d <- NA
pos_df_sl$magnitude <- NA

for (i in pos_df_sl$type) {
  
  if (i=="NN" || i == "NNS") {
  
   d <- (cohen.d(ano_lab_tag[[i]], ano_lab_tag$short_list,
                na.rm = TRUE, noncentral = FALSE, pooled = TRUE))
  } else {
    
     d <- (cohen.d(ano_lab_pos[[i]], ano_lab_pos$short_list,
                na.rm = TRUE, noncentral = FALSE, pooled = TRUE))
  }
   
  pos_df_sl$cohen_d[pos_df_sl$type==i] <- (d$estimate[[1]])
  
  pos_df_sl$magnitude[pos_df_sl$type==i] <- as.character(d$magnitude[[1]])
}

pos_df_sl$type <- factor(pos_df_sl$type, levels=c("NOUN", "NNS", "NN", "ADJ", "ADV", "VERB"))

## Recoding pos_df_sl$type into pos_df_sl$type_rec
pos_df_sl$type <- recode(pos_df_sl$type,
               "NOUN" = "All Nouns",
               "NNS" = "Plural Nouns",
               "NN" = "Singular Nouns",
               "ADJ" = "Adjectives",
               "ADV" = "Adverbs",
               "VERB" = "Verbs")

pos_df_sl <- pos_df_sl[order(pos_df_sl$type),]

pos_df_sl[2:5] <- pos_df_sl[2:5] * 100

```

```{r pos-gender-table, echo=FALSE, results = 'asis'}
pos_df_gender <- regulartable(pos_df_gender)
pos_df_gender <- pos_df_gender %>% 
  align(align = "right", part = "all")  %>%
   align(j = c("type", "magnitude"), 
               align = "left", part = "all") %>% autofit()
pos_df_gender
```

```{r pos-sl-table, echo=FALSE, results = 'asis'}
pos_df_sl <- regulartable(pos_df_sl)
pos_df_sl <- pos_df_sl %>% 
  align(align = "right", part = "all")  %>%
   align(j = c("type", "magnitude"), 
               align = "left", part = "all") %>% autofit()
pos_df_sl
```

Part-of-speech (POS) tagging was done using the `spaCy` library [@honnibal2017] and the `spacyr` package [@benoit2018a]. There is one small gender difference (_d_ = -0.22) in the use of plural nouns, which make up  `r paste0(formatC(pos_df_gender$Female_mean[pos_df_gender$type=="Plural Nouns"], digits = 3),"%")` of the words used by female Labour MPs, compared to  `r paste0(formatC(pos_df_gender$Male_mean[pos_df_gender$type=="Plural Nouns"], digits = 3),"%")` of words spoken by male Labour MPs. As with LIWC, there are no categories where _d_ >= $|0.2|$ when comparing female Labour MPs by selection process, and only one category -- plural nouns -- with an effect size of _d_ >= $|0.1|$.

## Keyness

We calculated the keyness of words to identify gender differences in the choices of topics raised and terminology used by both male and female Labour MPs, and by short-list and non-shortlist female Labour MPs. We have also calculated keyness between Labour and Conservative MPs for the purposes of illustration. All keyness figures include the 25 most disproportionately common words among each group, as determined by ${\chi}^2$ tests using `quanteda` [@benoit2018].

### Labour Men vs Women

Keyness -- a linguistic measure of the frequency of different words in two groups of texts -- reveals clear gender differences in the most disproportionately common words used by female and male Labour MPs, illustrated in Figure \@ref(fig:gender-keyness-plot).

Unsurprisingly, despite male MPs saying almost twice as many words (`r formatC(speech_sum_table$words[speech_sum_table$party_group == "Labour" & speech_sum_table$gender == "Male"], big.mark = ",")` vs `r formatC(speech_sum_table$words[speech_sum_table$party_group == "Labour" & speech_sum_table$gender == "Female"], big.mark = ",")`) as their female colleagues, female Labour MPs were more than two-and-a-half (2.61) times as likely to say "women". They were also much more likely to use "women's" and "woman" in parliamentary debate. Female Labour MPs also appear much more likely to discuss "children", "people", "care", "families", "home", "parents", "work" and social policy areas such as "services", "disabled [people]" and "housing" than their male colleagues. Male MPs were more likely to refer to military topics ("Iraq", "nuclear"), and to parliamentary process and protocol  -- "question", "political", "conservative", "electoral", "house", "party", "argument" "liberal" and "point" are far more common in speeches by male Labour MPs than by female ones. This could suggest that male Labour MPs are more comfortable using the traditional language of House of Commons debate, and are more concerned with the rules, procedures and processes of the parliamentary system than their female colleagues.

```{r gender-keyness-plot, echo=FALSE, fig.height=8, message=FALSE, warning=FALSE, fig.cap="Keyness between Labour MPs, by Gender"}
library(ggplot2)
library(readr)
library(dplyr)
library(quanteda)

lab_dfm_key <- read_rds("data/lab_dfm_key.rds")

lab_keyness <- textstat_keyness(lab_dfm_key, measure = c("chi2"))

lab_keyness_plot <- textplot_keyness(lab_keyness, n = 25, 
                                     color = c("purple", "darkgreen")) +  
  scale_x_continuous(limits = c(-3500, 14100), 
                     breaks = seq(-3000, 15000, by = 1500)) + 
  labs(x = "Chi2") + 
  theme(legend.position = "bottom")

ggsave("p03_lab_keyness_plot.svg", plot = lab_keyness_plot,
       device = "svg", path = "plots",
       width = 20, height = 20, units = "cm")

lab_keyness_plot
```

### Shortlists vs Non-Shortlists

Keyness differences by selection process (Figure \@ref(fig:sl-keyness)) are not as obviously stereotypical. Nonetheless, the most common words amongst AWS MPs included "carers", "disabled", "bedroom" and "sen" (Special Educational Needs). Also of note is AWS MPs making more references to their "constituency" and its "constituents", suggesting that AWS MPs may draw more heavily on the fact they were elected by their constituents as a source political legitimacy, or are more likely to illustrate a point with an example from their constitutency, compared to non-AWS MPs.

```{r sl-keyness, echo=FALSE, fig.height=8, message=FALSE, warning=FALSE, fig.cap="Keyness between Female Labour MPs, by Selection Process"}

lab_dfm_key_fem <- read_rds("data/lab_dfm_key_fem.rds")

lab_keyness_fem <- textstat_keyness(lab_dfm_key_fem, measure = c("chi2"))

#head(lab_keyness_fem)

fem_keyness_plot <- textplot_keyness(lab_keyness_fem, n=25) + 
  scale_color_manual(labels = c("Non-AWS", "AWS"),
                     values = c("#ff674c", "#02d5a1"), name = NULL) +
  scale_x_continuous(limits = c(-700, 700), 
                     breaks = seq(-500, 800, by = 100)) + 
  labs(x = "Chi2") + 
  theme(legend.position = "bottom")

ggsave("p04_fem_keyness_plot.svg", plot = fem_keyness_plot,
       device = "svg", path = "plots",
       width = 20, height = 20, units = "cm")

fem_keyness_plot
```

### Labour vs Conservative

The keyness differences (Figure \@ref(fig:lab-con-keyness)) between Labour and Conservative MPs are much greater than gender or AWS differences within Labour. The very high use of "Lady" by Conservative MPs is reflective of the greater proportion of female MPs in other parties, as it is often used to refer to comments by other members of the house. It may also represent a greater use of traditional house decorum by Conservative MPs.

```{r lab-con-keyness, echo=FALSE, fig.height=8, message=FALSE, warning=FALSE, fig.cap="Keyness between Labour and Conservative MPs"}
library(ggplot2)
library(quanteda)

lab_con_dfm <- read_rds("data/lab_con_dfm.rds")

lab_con_keyness <- textstat_keyness(lab_con_dfm, measure = c("chi2"))

#head(lab_keyness_fem)

lab_con_keyness_plot <- textplot_keyness(lab_con_keyness, n=25, 
                                         color = c("blue", "red")) + 
  scale_x_continuous(limits = c(-4400, 7500), 
                     breaks = seq(-4000, 8000, by = 1000)) +
  labs(x = "Chi2") + 
  theme(legend.position = "bottom")

ggsave("p05_lab_con_keyness_plot.svg", plot = lab_con_keyness_plot,
       device = "svg", path = "plots",
       width = 20, height = 20, units = "cm")

lab_con_keyness_plot
```

## Bigrams

We created bigrams of all first person plural and singular pronouns for female Labour MPs (Figure \@ref(fig:bigrams-sl-keyness)). As above, AWS MPs are far more likely to make references to their constituency or their constituents, and the use of bigrams confirms these references are to their specific constituency/constituents, rather than those of other MPs, or constituencies in general.

```{r bigrams-sl-keyness, echo=FALSE, message=FALSE, warning=FALSE, fig.height=8, fig.cap="Bigram Keyness in Female Labour MPs by Selection Process"}
library(quanteda)
library(readr)
library(ggplot2)

pro_bigram <- read_rds("data/pro_bigram.rds")

pro_dfm <- dfm(pro_bigram, verbose=TRUE, groups = "short_list")

pro_dfm_key <- textstat_keyness(pro_dfm, target = "FALSE", measure = "chi2")

#pro_dfm_key$n_total <- pro_dfm_key$n_reference + pro_dfm_key$n_target

pro_dfm_key_plot <- textplot_keyness(pro_dfm_key, n=25) +  
    scale_color_manual(labels = c("Non-AWS", "AWS"), 
                      values = c("#ff674c", "#02d5a1"), name = NULL) +
    scale_x_continuous(limits = c(-750, 560), 
                     breaks = seq(-600, 500, by = 100)) +
  labs(x = "Chi2") + 
  theme(legend.position = "bottom")

ggsave("p06_pro_dfm_key_plot.svg", plot = pro_dfm_key_plot,
       device = "svg", path = "plots",
       width = 20, height = 20, units = "cm")

pro_dfm_key_plot

```

## Naive Bayes classification

We trained a Naive Bayes classifier with document-frequency priors and a multinomial distribution to predict the gender of speakers when given speeches by all Labour MPs in our dataset, and the selection process when only given female Labour MPs. The accuracy of both models were roughly equivalent, 70.67% accuracy when predicting gender and 71.22% when predicting shortlists. By contrast, the classifier could distinguish between Labour and Conservative speeches with 74.23% accuracy. 

## Topic Models

Using topic models to classify text is widely used in social sciences [@grimmer2013], as, when combined with the large volume of plain text data available, it allows for a rapid and consistent method of analysis . Topic modelling and other statistic methods of textual analysis are not a substitute for reading the texts themselves, but can augment other analysis or -- as in this case -- analyse and classify larger amounts of text than would be feasible using human coders [@grimmer2013]. Topic models classify a series of documents (in this case individual speeches) into one of a given number of topics, identifying terms that are common in some documents but rare in others. When developing topic models, there is a trade-off between high precision in the classification of each document with broader topics when using smaller numbers of topics, or lower precision in individual speech classification with more finely-grained topics when using larger numbers of topics. @grimmer2013 also highlight the importance of validating unsurpervised topic models when applied to new sets of texts, which we have done [below](#Manual Validation).

The R package `stm` [@roberts2018] implements a structured topic model (STM) [@roberts2016; @arora2013]. An STM incorporates covariates into the topic classification algorithm, creating possibilities for hypothesis testing. This differs from traditional topic modelling methods using latent variables to identify topics [e.g. with latent Dirichlet allocation @blei2003], and then comparing proportions of each topic to one or more external variables. STM allows us to incorporate the variables we are interested in to the topic model itself using a generalised linear model; i.e. the proportion of speechs classified as belonging to each topic can vary as a function of the AWS and gender variables.

We incorporated the AWS status of speakers and their gender as prevalence covariates into our topic model. 

We created six topic models with different numbers of topics (_K_). We created models with 30, 45, 60, 80 and 100 topics, and used a topic selection algorithm developed by @lee2014c, implemented in the `stm` package [@roberts2018], which resulted in _K_ = 66. Figure \@ref(fig:topic-model-selection-plot) shows, clockwise from the top-left, the exclusivity score, held out likelihood with 50% of documents held out, the multinomial dispersion of the STM residuals [@taddy2012], semantic coherence [@mimno2011], and the lower bound of each topic model.

```{r topic-model-selection-plot, echo=FALSE, fig.cap="Topic Model Selection"}
library(readr)
library(tidyr)
library(ggplot2)
library(purrr)
library(dplyr)

topic_model_k0 <- read_rds("data/topic_model_k0_m.rds")

k_models <- read_rds("data/k_models.rds")

k_result <- k_models %>%
  transmute(K,
            `Lower bound (000,000's)` = lbound/1000000,
            Residuals = map_dbl(check_residuals, "dispersion"),
            `Semantic coherence` = map_dbl(semantic_coherence, mean),
            `Held-out likelihood` = map_dbl(eval_heldout, "expected.heldout"),
            Exclusivity = map_dbl(exclusivity, mean)) %>%
  gather(label, value, -K)

p_k_result <- ggplot(k_result, aes(K, value, color = label)) +
  geom_line(size = 1.45, alpha = 0.9, show.legend = FALSE) +
  scale_colour_viridis_d(end = 0.9) + 
  scale_x_continuous(breaks = c(30, 45, 60, 66, 80, 100)) + 
  facet_wrap(~label, scales = "free_y", nrow = 3) +
  labs(x = expression(italic("K")),
       y = NULL)

ggsave("p07_k_result.svg", plot = p_k_result, path="plots", device = "svg",
       width = 20, height = 20, units = "cm")

p_k_result
```

As seen in Figure \@ref(fig:topic-model-selection-plot), the _K_ = 66 result appears to produce the best result, a topic model with `r formatC(topic_model_k0$settings$dim$K, , big.mark = ",")` topics, across `r formatC(topic_model_k0$settings$dim$N, , big.mark = ",")` speeches with a dictionary of `r formatC(topic_model_k0$settings$dim$V, , big.mark = ",")` words. All models were created using the "spectral" method developed by @arora2013, implemented in the `stm` package by @roberts2018. 

Figure \@ref(fig:stm-network-graph) is a Fruchterman-Reingold force-directed diagram [@fruchterman1991] of correlations between different topics. Larger vertices indicate more common topics (amongst both male and female Labour MPs), and the colour scale indicates the proportion of speeches classed in that topic made by AWS and non-AWS female Labour MPs, respectively. Edges indicate positive correlations between the two linked topics.

```{r stm-network-graph, echo=FALSE, message=FALSE, warning=FALSE, fig.height=7, fig.cap="Fruchterman-Reingold plot of Topic Network"}
library(readr)
library(stm)
library(viridis)
library(dplyr)
library(igraph)
library(ggplot2)
library(quanteda)
library(tidystm)

corr_topic_k0 <- read_rds("data/corr_topic_k0_m.rds")

prep_k0 <- read_rds("data/prep_k0_m.rds")

lab_corpus_stm <- read_rds("data/lab_corpus_stm.rds")

prep_df_k0 <- summary(prep_k0)[[3]]

prep_df_k0 <- as.data.frame(do.call(rbind, prep_df_k0))

prep_df_k0$topic <- NA

prep_df_k0$topic <- rep(1:66, each = 3)

prep_df_k0$type <- row.names(prep_df_k0)

prep_df_k0$type <- gsub("\\.[0-9][0-9]", "", prep_df_k0$type)

prep_df_k0$type <- gsub("\\.[0-9]", "", prep_df_k0$type)

prep_df_k0$type <- gsub("\\.$", "", prep_df_k0$type)

prep_df_k0_fem  <- prep_df_k0 %>% filter(type != "genderMale")

prep_df_k0_coeff <- prep_df_k0 %>% filter(type == "short_listTRUE")

vlabels=NULL
layout=NULL

topics <- 1:nrow(corr_topic_k0$posadj)
  
x <- corr_topic_k0$posadj[topics, topics]
  
g <- igraph::graph.adjacency(x, mode="directed", weighted=TRUE, diag=FALSE)
igraph::E(g)$size <- 1
igraph::E(g)$lty <- 2
igraph::E(g)$color <- "black"
igraph::V(g)$label <- topics

plotcord_k0 <- data.frame(layout_with_fr(g))
  
edgelist_k0 <- get.edgelist(g)

#convert to a four column edge data frame with source and destination coordinates
edges_k0 <- data.frame(plotcord_k0[edgelist_k0[,1],], 
                    plotcord_k0[edgelist_k0[,2],])

colnames(edges_k0) <- c("X1","Y1","X2","Y2")

plotcord_k0$topic <- as.numeric(row.names(plotcord_k0))
  
#plotcord_k0 <- plotcord_k0 %>% left_join(prep_df_k0)

lab_corpus_stm$meta$eo_id <- docnames(lab_corpus_stm$documents)

topic_dt_k0 <- make.dt(topic_model_k0, lab_corpus_stm$meta)

topic_dt_k0$assigned_topic <- as.factor(topic_dt_k0$assigned_topic)

## Reordering x$assigned_topic
topic_dt_k0$assigned_topic <- factor(topic_dt_k0$assigned_topic, 
                           levels=c("Topic1", "Topic2", "Topic3",
                                    "Topic4", "Topic5", "Topic6",
                                    "Topic7", "Topic8", "Topic9",
                                    "Topic10", "Topic11", "Topic12",
                                    "Topic13", "Topic14", "Topic15",
                                    "Topic16", "Topic17", "Topic18",
                                    "Topic19", "Topic20", "Topic21",
                                    "Topic22", "Topic23", "Topic24",
                                    "Topic25", "Topic26", "Topic27",
                                    "Topic28", "Topic29", "Topic30",
                                    "Topic31", "Topic32", "Topic33",
                                    "Topic34", "Topic35", "Topic36",
                                    "Topic37", "Topic38", "Topic39",
                                    "Topic40", "Topic41", "Topic42",
                                    "Topic43", "Topic44", "Topic45",
                                    "Topic46", "Topic47", "Topic48",
                                    "Topic49", "Topic50", "Topic51",
                                    "Topic52", "Topic53", "Topic54",
                                    "Topic55", "Topic56", "Topic57",
                                    "Topic58", "Topic59", "Topic60",
                                    "Topic61", "Topic62", "Topic63",
                                    "Topic64", "Topic65", "Topic66"))

## Get the sum for each topic in topic_dt_k0, as a proportion

topic_dt_k0_2 <- topic_dt_k0 %>% 
  summarise_at(vars(Topic1:Topic66), sum, na.rm = TRUE) %>%
  gather(assigned_topic, theta)

effect2 <- extract.estimateEffect(x = prep_k0,
                                  covariate = "gender_sl",
                                  method = "difference",
                                  model = topic_model_k0,
                                  cov.value1 = "Female_TRUE",
                                  cov.value2 = "Female_FALSE") %>%
  mutate(assigned_topic = paste0("Topic", topic)) %>% select(assigned_topic, 
                                                             estimate, label)

topic_dt_k0_3 <- topic_dt_k0_2 %>% left_join(effect2)

plotcord_k0$assigned_topic <- paste0("Topic", plotcord_k0$topic)

plotcord_k0_2 <- plotcord_k0 %>% 
  inner_join(topic_dt_k0_3)

set.seed(808)
p_network_k0 <- ggplot() + 
  geom_segment(aes(x=X1, y=Y1, xend = X2, yend = Y2),
               data=edges_k0, size = 0.5, colour="grey") +
  geom_point(data = plotcord_k0_2, 
             aes(X1, X2, colour = estimate, size = theta)) + 
  geom_text(aes(X1, X2, label=topic), hjust = "center", vjust="top",
            size = 5, data = plotcord_k0_2) + 
  scale_colour_viridis(breaks = c(max(plotcord_k0_2$estimate),
                                  min(plotcord_k0_2$estimate)), 
                       labels = c("More AWS", "More non-AWS"),
                       name = NULL, option = "plasma",
                       end = 0.95, begin = 0.05) + 
  scale_size(guide = "none") + 
  theme_void() + 
  theme(legend.position = "bottom",
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),  
    axis.title.x = element_blank(), 
    axis.title.y = element_blank())

ggsave("p08_network_k0.svg", plot = p_network_k0, path = "plots",
       device = "svg", width = 20, height = 20, units = "cm")

p_network_k0
```

The `stm` package includes the `estimateEffect` function, which creates a regression model (Table \@ref(tab:estimate-table-k0)) using individual documents (speeches) as observations, with the proportion of a each document fitting each topic as the dependent variable and model covariates (AWS status and gender) as independent variables. The intercept in this model is all speeches by male Labour MPs.

```{r estimate-table-k0, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
library(knitr)
library(kableExtra)
library(dplyr)
library(flextable)

row.names(prep_df_k0) <- NULL
prep_df_k0$type <- gsub("X.Intercept", "Intercept", prep_df_k0$type)
prep_df_k0$type <- gsub("gender_slFemale_TRUE", "AWS", prep_df_k0$type)
prep_df_k0$type <- gsub("gender_slFemale_FALSE", "Non-AWS", prep_df_k0$type)

prep_df_k0 <- prep_df_k0 %>% rename("p" = "Pr(>|t|)")

prep_df_k0_2 <- prep_df_k0 %>% mutate(
  stars = case_when(p < 0.001 ~ "***", 
                    p < 0.01 ~ "**",
                    p < 0.05 ~ "*", 
                    TRUE ~ ""),
  p = paste(pixiedust::pval_string(p,  digits = 4), stars)) %>%
  select(topic, type, Estimate, `Std. Error`, `t value`, p)

prep_df_k0_2$topic <- recode(prep_df_k0_2$topic, 
                          "1" = "(1) Employment & unions",
                          "2" = "(2) Legal system",
                          "3" = "(3) Roads",
                          "4" = "(4) Housing",
                          "5" = "(5) Police, firefighters & prison",
                          "6" = "(6) Northern Ireland",
                          "7" = "(7) Committee",
                          "8" = "(8) Schools",
                          "9" = "(9) Energy & climate change",
                          "10" = "(10) Defence",
                          "11" = "(11) Parliament",
                          "12" = "(12) International politics",
                          "13" = "(13) Ministers",
                          "14" = "(14) Policy impact",
                          "15" = "(15) Gender",
                          "16" = "(16) Regional development",
                          "17" = "(17) Communications",
                          "18" = "(18) Immigration",
                          "19" = "(19) Health system",
                          "20" = "(20) International development",
                          "21" = "(21) Benefits & disability",
                          "22" = "(22) Sport & culture",
                          "23" = "(23) History",
                          "24" = "(24) Higher education & skills",
                          "25" = "(25) Concurring point",
                          "26" = "(26) Pensions",
                          "27" = "(27) Points of order",
                          "28" = "(28) Issues",
                          "29" = "(29) Constituencies",
                          "30" = "(30) Ethnic groups & racism",
                          "31" = "(31) Amendments",
                          "32" = "(32) Reports",
                          "33" = "(33) People",
                          "34" = "(34) Wales & Scotland",
                          "35" = "(35) Alcohol & tobacco",
                          "36" = "(36) Place names",
                          "37" = "(37) Budget",
                          "38" = "(38) Tax",
                          "39" = "(39) Private companies",
                          "40" = "(40) Environment & fishing",
                          "41" = "(41) Crime",
                          "42" = "(42) Bills",
                          "43" = "(43) Children",
                          "44" = "(44) Utilities & PFI",
                          "45" = "(45) Middle East",
                          "46" = "(46) Local authorities",
                          "47" = "(47) Elections",
                          "48" = "(48) Debate",
                          "49" = "(49) Transport",
                          "50" = "(50) Questions",
                          "51" = "(51) Families",
                          "52" = "(52) Health research",
                          "53" = "(53) Dispatch box",
                          "54" = "(54) Parties",
                          "55" = "(55) Statements",
                          "56" = "(56) European Union",
                          "57" = "(57) Locations",
                          "58" = "(58) Jobs & manufacturing",
                          "59" = "(59) Small business",
                          "60" = "(60) Agreement & disagreement",
                          "61" = "(61) Voluntary sector",
                          "62" = "(62) Comments",
                          "63" = "(63) Social care",
                          "64" = "(64) Time",
                          "65" = "(65) Media & animals",
                          "66" = "(66) Other")


prep_df_k0_2 <- regulartable(prep_df_k0_2)
prep_df_k0_2 <- merge_v(prep_df_k0_2, ~ topic)
prep_df_k0_2 <- align(prep_df_k0_2, j = c("topic", "type"), 
              align = "left", part = "all") %>% 
  align(j = c("Estimate", "Std. Error", "t value", "p"), 
        align = "right", part = "all") %>% autofit()
prep_df_k0_2
```


```{r topic-dt3-creation-k0, include=FALSE}
topic_dt_assign <- make.dt(topic_model_k0, lab_corpus_stm$meta)

set.seed(24)
topic_dt_assign$assigned_topic <- colnames(topic_dt_assign[,2:67])[max.col(topic_dt_assign[,2:67],ties.method="random")]

topic_dt_assign$theta <- apply(topic_dt_assign[,2:67], 1, max)

#topic_dt_assign$assigned_topic <- as.factor(topic_dt_assign$assigned_topic)

topic_dt_assign_2 <- topic_dt_assign %>%
  mutate(short_list_g = paste0(short_list, "_", gender)) %>%
  group_by(assigned_topic, short_list_g) %>%
  summarise(count = n()) %>%
  ungroup() %>%
  spread(key = "short_list_g", value = "count") %>%
   rename("AWS" = "TRUE_Female", "non_AWS" = "FALSE_Female",
          "man_count" = "FALSE_Male") %>%
   mutate(AWS_freq = AWS/sum(AWS, na.rm = TRUE),
          non_AWS_freq = non_AWS/sum(non_AWS, na.rm = TRUE),
          man_freq = man_count/sum(man_count, na.rm = TRUE),
          assigned_topic = gsub("Topic", "Topic ", assigned_topic)) %>%
   mutate(assigned_topic = factor(assigned_topic, levels=c(
                                    "Topic 1", "Topic 2", "Topic 3",
                                    "Topic 4", "Topic 5", "Topic 6",
                                    "Topic 7", "Topic 8", "Topic 9",
                                    "Topic 10", "Topic 11", "Topic 12",
                                    "Topic 13", "Topic 14", "Topic 15",
                                    "Topic 16", "Topic 17", "Topic 18",
                                    "Topic 19", "Topic 20", "Topic 21",
                                    "Topic 22", "Topic 23", "Topic 24",
                                    "Topic 25", "Topic 26", "Topic 27",
                                    "Topic 28", "Topic 29", "Topic 30",
                                    "Topic 31", "Topic 32", "Topic 33",
                                    "Topic 34", "Topic 35", "Topic 36",
                                    "Topic 37", "Topic 38", "Topic 39",
                                    "Topic 40", "Topic 41", "Topic 42",
                                    "Topic 43", "Topic 44", "Topic 45",
                                    "Topic 46", "Topic 47", "Topic 48",
                                    "Topic 49", "Topic 50", "Topic 51",
                                    "Topic 52", "Topic 53", "Topic 54",
                                    "Topic 55", "Topic 56", "Topic 57",
                                    "Topic 58", "Topic 59", "Topic 60",
                                    "Topic 61", "Topic 62", "Topic 63",
                                    "Topic 64", "Topic 65", "Topic 66")),
          assigned_topic = recode(assigned_topic, 
                          "Topic 1" = "(1) Employment & unions",
                          "Topic 2" = "(2) Legal system",
                          "Topic 3" = "(3) Roads",
                          "Topic 4" = "(4) Housing",
                          "Topic 5" = "(5) Police, firefighters & prison",
                          "Topic 6" = "(6) Northern Ireland",
                          "Topic 7" = "(7) Committee",
                          "Topic 8" = "(8) Schools",
                          "Topic 9" = "(9) Energy & climate change",
                          "Topic 10" = "(10) Defence",
                          "Topic 11" = "(11) Parliament",
                          "Topic 12" = "(12) International politics",
                          "Topic 13" = "(13) Ministers",
                          "Topic 14" = "(14) Policy impact",
                          "Topic 15" = "(15) Gender",
                          "Topic 16" = "(16) Regional development",
                          "Topic 17" = "(17) Communications",
                          "Topic 18" = "(18) Immigration",
                          "Topic 19" = "(19) Health system",
                          "Topic 20" = "(20) International development",
                          "Topic 21" = "(21) Benefits & disability",
                          "Topic 22" = "(22) Sport & culture",
                          "Topic 23" = "(23) History",
                          "Topic 24" = "(24) Higher education & skills",
                          "Topic 25" = "(25) Concurring point",
                          "Topic 26" = "(26) Pensions",
                          "Topic 27" = "(27) Points of order",
                          "Topic 28" = "(28) Issues",
                          "Topic 29" = "(29) Constituencies",
                          "Topic 30" = "(30) Ethnic groups & racism",
                          "Topic 31" = "(31) Amendments",
                          "Topic 32" = "(32) Reports",
                          "Topic 33" = "(33) People",
                          "Topic 34" = "(34) Wales & Scotland",
                          "Topic 35" = "(35) Alcohol & tobacco",
                          "Topic 36" = "(36) Place names",
                          "Topic 37" = "(37) Budget",
                          "Topic 38" = "(38) Tax",
                          "Topic 39" = "(39) Private companies",
                          "Topic 40" = "(40) Environment & fishing",
                          "Topic 41" = "(41) Crime",
                          "Topic 42" = "(42) Bills",
                          "Topic 43" = "(43) Children",
                          "Topic 44" = "(44) Utilities & PFI",
                          "Topic 45" = "(45) Middle East",
                          "Topic 46" = "(46) Local authorities",
                          "Topic 47" = "(47) Elections",
                          "Topic 48" = "(48) Debate",
                          "Topic 49" = "(49) Transport",
                          "Topic 50" = "(50) Questions",
                          "Topic 51" = "(51) Families",
                          "Topic 52" = "(52) Health research",
                          "Topic 53" = "(53) Dispatch box",
                          "Topic 54" = "(54) Parties",
                          "Topic 55" = "(55) Statements",
                          "Topic 56" = "(56) European Union",
                          "Topic 57" = "(57) Locations",
                          "Topic 58" = "(58) Jobs & manufacturing",
                          "Topic 59" = "(59) Small business",
                          "Topic 60" = "(60) Agreement & disagreement",
                          "Topic 61" = "(61) Voluntary sector",
                          "Topic 62" = "(62) Comments",
                          "Topic 63" = "(63) Social care",
                          "Topic 64" = "(64) Time",
                          "Topic 65" = "(65) Media & animals",
                          "Topic 66" = "(66) Other")) %>%
  arrange(assigned_topic) %>%
    mutate(AWS_freq = paste0(formatC(round(AWS_freq*100, 2), 
            format = "f", digits = 2), "%"),
          non_AWS_freq = paste0(formatC(round(non_AWS_freq*100, 2), 
            format = "f", digits = 2), "%"),
          AWS = formatC(AWS, big.mark = ","),
          non_AWS = formatC(non_AWS, big.mark = ","),
          man_freq = paste0(formatC(
            round((man_freq*100), 2), 
            format = "f", digits = 2), "%"),
          man_count = formatC(man_count, big.mark = ",")) %>%
  select(assigned_topic, AWS, AWS_freq, non_AWS, non_AWS_freq, man_count, man_freq)

```

Table \@ref(topic-summary-table) shows the number and percentage of speeches assigned to each topic, based on its $\theta$ value. The results in this table differ slightly from those in Table \@ref(tab:estimate-table-k0), as it uses a "winner-take-all" method to assign an overall topic to each speech, rather than a prevalence of a given topic across all speeches. One of the topics -- Topic 66 -- is never the most likely topic in the matrix of number of documents by number of topics -- labelled $\theta$ by @roberts2018 -- and so while it is included in the model, assignment of single topics to speeches uses the highest $\theta$ for each speech. Other topics are rarely used -- Topic 53, which we labelled "Dispatch Box", only has five topics assigned to it, four from Male MPs and one from an AWS MP.

```{r topic-summary-table, echo=FALSE, results = 'asis'}
topic_dt_assign_2 <- regulartable(topic_dt_assign_2)
topic_dt_assign_2 <- topic_dt_assign_2 %>% align( 
        align = "right", part = "all") %>%
  align(j = "assigned_topic",
              align = "left", part = "all") %>% autofit()
topic_dt_assign_2
```


### Topic Graphs

The estimate effects in these graphs were extracted using the `tidystm` package by Mikael Poul Johannesson.[^2] Figure \@ref(fig:tidystm-graphs) highlights nine topics with different expected proportions between male, AWS and non-AWS Labour MPs, with the error bars representing 95% confidence intervals. See Figure \@ref(fig:topic-bar) for a graph of all 66 topics.

```{r tidystm-graphs, echo=FALSE, fig.cap="Selected Topic Proportions", message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(stringr)
effect <- read_rds("data/effect.rds")

effect$label_wrap <- str_wrap(effect$label, 12)

p_k0_sel_bar <- ggplot(filter(effect,
                           topic %in% c(27, 2, 21, 63, 60, 54, 29, 30, 38)),
                       aes(y = estimate, x = label_wrap,
                           group = covariate.value, fill = covariate.value)) + 
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_errorbar(aes(ymin = ci.lower, ymax = ci.upper), 
                color = "black", width = 0.3, position = position_dodge(.9)) + 
   scale_y_continuous(labels = scales::percent) + 
  scale_fill_manual(values = c("#a06dba", "#7aa457", "#cb6a49"),
                    labels = c( "Men", "Non-AWS", "AWS"),
                    name = "") + 
  labs(x = "Topic",
       y = "Expected Topic Proportion") +
  theme(legend.position = "bottom")

ggsave("p09_k0_sel_bar.svg", plot = p_k0_sel_bar,
       path="plots", device = "svg", width = 20, height = 20, units = "cm")

p_k0_sel_bar
```

```{r topic-bar, echo=FALSE, fig.cap="All Topic Proportions", message=FALSE, warning=FALSE}
p_k0_bar <- ggplot(effect, aes(y = estimate, x = as.factor(topic),
                   group = covariate.value, fill = covariate.value)) + 
  geom_bar(stat = "identity", position=position_dodge()) +
  # geom_errorbar(aes(ymin = ci.lower, ymax = ci.upper), 
  #               color = "black", width = 0.3, position=position_dodge(.9)) + 
   scale_y_continuous(labels = scales::percent) + 
  scale_fill_manual(values = c("#a06dba", "#7aa457", "#cb6a49"),
                    labels = c( "Men", "Non-AWS", "AWS"),
                    name = "") + 
  labs(x = "Topic",
       y = "Expected Topic Proportion") +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90, hjust = 1.1, vjust = 0.5))

ggsave("p10_k0_bar.svg", plot = p_k0_bar,
       path="plots", device = "svg", width = 20, height = 20, units = "cm")

p_k0_bar
```

### Word Occurrences

The table below shows the twenty most common words in each topic, and the twenty words with the highest FREX score, a measure that uses a harmonic mean of word exclusivity and topic coherence [@airoldi2016]. We have named each topic based on the most common words and highest FREX score words in each topic.

```{r stm-topic-words-prep, message=FALSE, warning=FALSE, include=FALSE}
library(tidyr)
topic_words <- labelTopics(topic_model_k0, n = 20, frexweight = 0.5)

topic_words_highest <- tibble::as_tibble(topic_words[[1]])

topic_words_highest <- topic_words_highest %>% unite(V1:V20, sep = ", ") %>%
  rename("highest" = "V1:V20")

topic_words_highest$topic <- row.names(topic_words_highest)

topic_words_frex <- tibble::as_tibble(topic_words[[2]])

topic_words_frex <- topic_words_frex %>% unite(V1:V20, sep = ", ") %>%
  rename("FREX" = "V1:V20")

topic_words_frex$topic <- row.names(topic_words_frex)

topic_words2 <- topic_words_highest %>% left_join(topic_words_frex) %>% 
  select(topic, everything()) %>%
  mutate(topic = recode(topic,
                        "1" = "(1) Employment & unions",
                        "2" = "(2) Legal system",
                        "3" = "(3) Roads",
                        "4" = "(4) Housing",
                        "5" = "(5) Police, firefighters & prison",
                        "6" = "(6) Northern Ireland",
                          "7" = "(7) Committee",
                          "8" = "(8) Schools",
                          "9" = "(9) Energy & climate change",
                          "10" = "(10) Defence",
                          "11" = "(11) Parliament",
                          "12" = "(12) International politics",
                          "13" = "(13) Ministers",
                          "14" = "(14) Policy impact",
                          "15" = "(15) Gender",
                          "16" = "(16) Regional development",
                          "17" = "(17) Communications",
                          "18" = "(18) Immigration",
                          "19" = "(19) Health system",
                          "20" = "(20) International development",
                          "21" = "(21) Benefits & disability",
                          "22" = "(22) Sport & culture",
                          "23" = "(23) History",
                          "24" = "(24) Higher education & skills",
                          "25" = "(25) Concurring point",
                          "26" = "(26) Pensions",
                          "27" = "(27) Points of order",
                          "28" = "(28) Issues",
                          "29" = "(29) Constituencies",
                          "30" = "(30) Ethnic groups & racism",
                          "31" = "(31) Amendments",
                          "32" = "(32) Reports",
                          "33" = "(33) People",
                          "34" = "(34) Wales & Scotland",
                          "35" = "(35) Alcohol & tobacco",
                          "36" = "(36) Place names",
                          "37" = "(37) Budget",
                          "38" = "(38) Tax",
                          "39" = "(39) Private companies",
                          "40" = "(40) Environment & fishing",
                          "41" = "(41) Crime",
                          "42" = "(42) Bills",
                          "43" = "(43) Children",
                          "44" = "(44) Utilities & PFI",
                          "45" = "(45) Middle East",
                          "46" = "(46) Local authorities",
                          "47" = "(47) Elections",
                          "48" = "(48) Debate",
                          "49" = "(49) Transport",
                          "50" = "(50) Questions",
                          "51" = "(51) Families",
                          "52" = "(52) Health research",
                          "53" = "(53) Dispatch box",
                          "54" = "(54) Parties",
                          "55" = "(55) Statements",
                          "56" = "(56) European Union",
                          "57" = "(57) Locations",
                          "58" = "(58) Jobs & manufacturing",
                          "59" = "(59) Small business",
                          "60" = "(60) Agreement & disagreement",
                          "61" = "(61) Voluntary sector",
                          "62" = "(62) Comments",
                          "63" = "(63) Social care",
                          "64" = "(64) Time",
                          "65" = "(65) Media & animals",
                          "66" = "(66) Other"))
```

```{r topic-words-table-k0, echo=FALSE, results = 'asis'}
library(flextable)

# kable(topic_words2, escape = FALSE, booktabs = TRUE, longtable = TRUE, 
#       caption = "Words in Topic",
#       col.names = c("Topic Number", "Top Twenty Words", "Top Twenty FREX")) %>%
#     kable_styling(bootstrap_options = c("basic", "HOLD_position",  "repeat_header"), full_width = TRUE ) %>% 
#   column_spec(2:3, width = "6cm")


topic_words2 <- regulartable(topic_words2)
topic_words2 <- topic_words2 %>%
  align(align = "left", part = "all")

topic_words2

```


### Manual Validation

We have validated both the topics produced by the model and our labels of those topics to ensure the topics themselves are both interesting and relevant. Validation is particularly important in unsupervised models including STM [@grimmer2013]. @quinn2010 suggest that topics are valid if they correspond to external events. Figure \@ref(fig:middle-east-plot) shows the number of speeches by Labour MPs on the "Middle East" topic, with a spike in 2003 (at the start of the Iraq War), another spike in 2008 and 2009, as the bulk of British troops left Iraq, a small spike in 2011 coinciding with UK participation in NATO's military intervention in Libya, and another spike resulting from debate in 2014--2016 over UK participation in military interventions in the Syrian Civil War. 

Figure \@ref(fig:wales-scotland-plot) shows debate over the devolved authorities of Wales and Scotland peaking in 2014, to coincide with Scotland's independence referendum. The post-2015 decline also likely stems from the SNP winning all but three seats in Scotland during the 2015 General Election. Figure \@ref(fig:eu-plot) shows the increase in debate over the European Union coinciding with the referendum on the UK's member of the European Union. 

```{r validation-prep, include=FALSE}
library(lubridate)
library(ggplot2)

#head(topic_dt_assign)

topic_dt_k0_valid <- topic_dt_assign %>% 
  group_by(assigned_topic, year) %>%
  summarise(count = n())

# test10 <- topic_dt_k0_valid %>% filter(assigned_topic == "Topic10")
# 
# plot10 <- ggplot(aes(x=year, y = count), data = test10) +
#   geom_line() + 
#   labs(x = "Year", y = "Number of Speeches")
# 
# plot10

```

```{r middle-east-plot, echo=FALSE,fig.cap="Number of Speeches in \"Middle East\" Topic per Year", fig.height=4.5}
test45 <- topic_dt_k0_valid %>% filter(assigned_topic == "Topic45")

plot45 <- ggplot(aes(x=year, y = count), data = test45) +
  geom_line() + 
  labs(x = "Year", y = "Number of Speeches")

plot45

ggsave("p11_middle_east_valid.svg", plot = plot45,
       path="plots", device = "svg", width = 20, height = 20, units = "cm")

```

```{r wales-scotland-plot, echo=FALSE,fig.cap="Number of Speeches in \"Wales & Scotland\" Topic per Year", fig.height=4.5}
test34 <- topic_dt_k0_valid %>% filter(assigned_topic == "Topic34")

plot34 <- ggplot(aes(x=year, y = count), data = test34) +
  geom_line() + 
  labs(x = "Year", y = "Number of Speeches")

plot34

ggsave("p12_wales_scotland_valid.svg", plot = plot34,
       path="plots", device = "svg", width = 20, height = 20, units = "cm")
```

```{r eu-plot, echo=FALSE,fig.cap="Number of Speeches in \"European Union\" Topic per Year", fig.height=4.5}

test56 <- topic_dt_k0_valid %>% filter(assigned_topic == "Topic56")

plot56 <- ggplot(aes(x=year, y = count), data = test56) +
  geom_line() + 
  labs(x = "Year", y = "Number of Speeches")

plot56

ggsave("p13_eu_valid.svg", plot = plot56,
       path="plots", device = "svg", width = 20, height = 20, units = "cm")

```


# Discussion

There do not appear to be substantial or meaningful differences in the speaking styles of female Labour MPs selected through all women shortlists when compared to their female colleagues selected through open shortlists using LIWC. This is possibly due to the speaking style dominant in British parliamentary debate, which is more formal than the speech used in most day-to-day conversation. LIWC was developed by American researchers, and the LIWC dictionary may not be able to capture stylistic differences between American and British English, and may not include words commonly used in formal British English speech, limiting its usefulness in the context of British political debate.

There is more distinction between AWS and non-AWS MPs in terms and topics. [Naive Bayes classification](# Naive Bayes classification) was able to accurately determine the AWS status of female Labour MPs with slightly greater accuracy than it could distinguish between male and female Labour MPs (71.22% and 70.67%, respectively).

AWS MPs are far more likely to make reference to their constituency and constituents. In the debate between whether MPs should be "delegates" or "trustees" -- the "mandate-independence controversy" outlined by @pitkin1967 -- the references to their constituents and constituencies suggests AWS MPs shy away from the Burkean concept of trusteeship and see themselves more as strict representatives of their constituents. In Andeweg & Thomassen's [-@andeweg2005] typology of _ex ante_/_ex post_ and above/below political representation, AWS MPs lean towards representation "from below", although their selection process is _ex ante_/_ex post_. AWS MPs also use events and individuals in their constituency as examples when speaking on a given topic (see the [Appendix](# AWS References to Constituents in Context) for more examples).

AWS MPs refer to their constituents both specifically and in the abstract, particularly when criticising government policy. For example, in debate on 4th March 2015, Gemma Doyle, than the Labour MP for West Dunbartonshire (elected on an AWS in 2010), when asked if she would give way to Conservative MP Stephen Mosley, responded:

>No, I will not [give way], because my constituents want me to make these points, not to give more time to Conservative Members.

On 2nd June 2010, during debate on Israel-Palestine, Valerie Vaz, MP for Walsall South, also used the views of her constituents to support her position:

>My constituents want more than pressure. Will the Foreign Secretary come back to the House and report on a timetable for the discussions on a diplomatic solution, just as we did on Ireland?

On 4th April 2001, Betty Williams, member for Conwy from 1997--2010, raised the case of a wilderness guide in her constituency unable to access parts of the countryside due to foot and mouth disease:

>Is my right hon. Friend aware that there is continuing concern about the limited access to the countryside and crags of north Wales? May I draw his attention to the circumstances of my constituent, Ric Potter? Like many others, he has had to travel to Scotland, where there is greater access. Will my right hon. Friend help us to enable people such as Ric Potter to find work in outdoor pursuits?

\clearpage


# Appendix

## Gender effect estimates

Estimate effects of different topics, using only gender.

```{r estimate-table-gender, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
library(knitr)
library(kableExtra)
library(dplyr)

prep_k0_gender <- read_rds("data/prep_k0_gender.rds")

prep_df_k0_gender <- summary(prep_k0_gender)[[3]]

prep_df_k0_gender <- as.data.frame(do.call(rbind, prep_df_k0_gender))

prep_df_k0_gender$topic <- NA

prep_df_k0_gender$topic <- rep(1:66, each = 2)

prep_df_k0_gender$type <- row.names(prep_df_k0_gender)

prep_df_k0_gender$type <- gsub("\\.[0-9][0-9]", "", prep_df_k0_gender$type)

prep_df_k0_gender$type <- gsub("\\.[0-9]", "", prep_df_k0_gender$type)

prep_df_k0_gender$type <- gsub("\\.$", "", prep_df_k0_gender$type)

row.names(prep_df_k0_gender) <- NULL
prep_df_k0_gender$type <- gsub("X.Intercept", "Intercept", prep_df_k0_gender$type)
prep_df_k0_gender$type <- gsub("genderFemale", "Female", prep_df_k0_gender$type)

prep_df_k0_gender <- prep_df_k0_gender %>% rename(
  "p" = "Pr(>|t|)"
)

# prep_df_k0_gender$stars <- case_when(prep_df_k0_gender$p < 0.001 ~ "***", 
#                               prep_df_k0_gender$p < 0.01 ~ "**",
#                               prep_df_k0_gender$p < 0.05 ~ "*", 
#                               TRUE ~ "")

prep_df_k0_gender_2 <- prep_df_k0_gender %>% mutate(
  stars = case_when(p < 0.001 ~ "***", 
                    p < 0.01 ~ "**",
                    p < 0.05 ~ "*", 
                    TRUE ~ ""),
  p = paste(pixiedust::pval_string(p,  digits = 4), stars)) %>%
  select(topic, type, Estimate, `Std. Error`, `t value`, p)

prep_df_k0_gender_2$topic <- recode(prep_df_k0_gender_2$topic, 
                          "1" = "(1) Employment & unions",
                          "2" = "(2) Legal system",
                          "3" = "(3) Roads",
                          "4" = "(4) Housing",
                          "5" = "(5) Police, firefighters & prison",
                          "6" = "(6) Northern Ireland",
                          "7" = "(7) Committee",
                          "8" = "(8) Schools",
                          "9" = "(9) Energy & climate change",
                          "10" = "(10) Defence",
                          "11" = "(11) Parliament",
                          "12" = "(12) International politics",
                          "13" = "(13) Ministers",
                          "14" = "(14) Policy impact",
                          "15" = "(15) Gender",
                          "16" = "(16) Regional development",
                          "17" = "(17) Communications",
                          "18" = "(18) Immigration",
                          "19" = "(19) Health system",
                          "20" = "(20) International development",
                          "21" = "(21) Benefits & disability",
                          "22" = "(22) Sport & culture",
                          "23" = "(23) History",
                          "24" = "(24) Higher education & skills",
                          "25" = "(25) Concurring point",
                          "26" = "(26) Pensions",
                          "27" = "(27) Points of order",
                          "28" = "(28) Issues",
                          "29" = "(29) Constituencies",
                          "30" = "(30) Ethnic groups & racism",
                          "31" = "(31) Amendments",
                          "32" = "(32) Reports",
                          "33" = "(33) People",
                          "34" = "(34) Wales & Scotland",
                          "35" = "(35) Alcohol & tobacco",
                          "36" = "(36) Place names",
                          "37" = "(37) Budget",
                          "38" = "(38) Tax",
                          "39" = "(39) Private companies",
                          "40" = "(40) Environment & fishing",
                          "41" = "(41) Crime",
                          "42" = "(42) Bills",
                          "43" = "(43) Children",
                          "44" = "(44) Utilities & PFI",
                          "45" = "(45) Middle East",
                          "46" = "(46) Local authorities",
                          "47" = "(47) Elections",
                          "48" = "(48) Debate",
                          "49" = "(49) Transport",
                          "50" = "(50) Questions",
                          "51" = "(51) Families",
                          "52" = "(52) Health research",
                          "53" = "(53) Dispatch box",
                          "54" = "(54) Parties",
                          "55" = "(55) Statements",
                          "56" = "(56) European Union",
                          "57" = "(57) Locations",
                          "58" = "(58) Jobs & manufacturing",
                          "59" = "(59) Small business",
                          "60" = "(60) Agreement & disagreement",
                          "61" = "(61) Voluntary sector",
                          "62" = "(62) Comments",
                          "63" = "(63) Social care",
                          "64" = "(64) Time",
                          "65" = "(65) Media & animals",
                          "66" = "(66) Other")


prep_df_k0_gender_2 <- regulartable(prep_df_k0_gender_2)
prep_df_k0_gender_2 <- merge_v(prep_df_k0_gender_2, ~ topic)
prep_df_k0_gender_2 <- align(prep_df_k0_gender_2, j = c("topic", "type"), 
              align = "left", part = "all") %>% 
  align(j = c("Estimate", "Std. Error", "t value", "p"), 
        align = "right", part = "all") %>% autofit()
prep_df_k0_gender_2

```


## $\theta$ distribution

Figure \@ref(fig:theta-boxplot) shows the distribution of $\theta$ scores used to assign overall topics to individual speeches in Table \@ref(tab:topic-summary-table), per topic.


```{r theta-boxplot, echo=FALSE, fig.height=7, fig.cap="Theta Values in Topic Assignment"}
library(ggplot2)

topic_dt_k0_theta <- make.dt(topic_model_k0, lab_corpus_stm$meta)


set.seed(24)
topic_dt_k0_theta$assigned_topic <- colnames(topic_dt_k0_theta[,2:67])[max.col(topic_dt_k0_theta[,2:67],
                                                                               ties.method="random")]

topic_dt_k0_theta$theta <- apply(topic_dt_k0_theta[,2:67], 1, max)

p_theta <- ggplot(data = topic_dt_k0_theta, aes(assigned_topic, theta)) + 
  geom_boxplot(alpha = 0.7) + 
  scale_x_discrete(labels = c(1:65)) + 
  labs(x = "Assigned Topic",
       y = "Theta") +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90, hjust = 1.1, vjust = 0.5))
  
ggsave("p14_theta_distribution.svg", plot = p_theta,
       path="plots", device = "svg", width = 20, height = 20, units = "cm")

p_theta
```


## AWS References to Constituents in Context

A random selection of 2% of all references to "my constituency", "my constituent" and "my constituents", by AWS MPs, in context. 

```{r constituent-kwic, echo=FALSE, message=FALSE}
library(quanteda)
library(readr)
library(stringi)
library(dplyr)
library(knitr)
library(kableExtra)

## Get this working to remove needless characters

lab_speech <- read_rds("data/lab_speech.rds")

lab_speech$speech <- stri_replace_all_fixed(lab_speech$speech, "\n", " ")

lab_speech$speech <- stri_replace_all_regex(lab_speech$speech, "\\ n\\s", " ")

lab_speech$speech <- stri_replace_all_regex(lab_speech$speech, "\ n\\s", " ")

#head(lab_speech$speech)

lab_fem_sl <- lab_speech %>% 
  filter(gender == "Female" & short_list == TRUE)

set.seed(191)
constit_kwic <- kwic(lab_fem_sl$speech, phrase("my constit*"),
                     window = 10, valuetype = "glob", remove_punct = FALSE) %>% 
  tibble::as_tibble() %>% 
  select(pre:post) %>% 
  sample_frac(0.02) 

constit_kwic$pre <- stri_replace_all_fixed(constit_kwic$pre, " \\ n ", " ")

constit_kwic$post <- stri_replace_all_fixed(constit_kwic$post, " \\ n ", " ")

constit_kwic$post <- stri_replace_all_regex(constit_kwic$post, "^\\\\ n ", " ")

constit_kwic$post <- stri_replace_all_regex(constit_kwic$post, " \\\\ n$", " ")

constit_kwic$post <- stri_replace_all_regex(constit_kwic$post, "^n ", "")

constit_kwic$post <- stri_replace_all_regex(constit_kwic$post, " \\\"", " ")

constit_kwic$post <- stri_replace_all_regex(constit_kwic$post, " ([:punct:])", "$1")

constit_kwic$pre <- stri_replace_all_fixed(constit_kwic$pre, " \\ n ", " ")

constit_kwic$pre <- stri_replace_all_regex(constit_kwic$pre, "^\\\\ n ", " ")

constit_kwic$pre <- stri_replace_all_regex(constit_kwic$pre, " \\\\ n$", " ")

constit_kwic$pre <- stri_replace_all_regex(constit_kwic$pre, "^n ", "")

constit_kwic$pre <- stri_replace_all_regex(constit_kwic$pre, " \\\"", " ")

constit_kwic$pre <- stri_replace_all_regex(constit_kwic$pre, " ([:punct:])", "$1", vectorize_all = TRUE)

# kable(constit_kwic, escape = FALSE, booktabs = TRUE, longtable = TRUE, 
#       col.names = c("Pre", "Keyword", "Post"),
#       caption = "A random sample of KWIC's", row.names = FALSE) %>%
#     kable_styling(bootstrap_options = c("basic", "HOLD_position",  "repeat_header"), full_width = TRUE )


constit_kwic <- regulartable(constit_kwic)
constit_kwic <- constit_kwic %>%
  align(align = "center", part = "all") 

constit_kwic


```

# References

[^1]: e.g. a reference to "the member for Bethnal Green and Bow" in keeping with Parliamentary convention of identifying MPs by their seat rather than their name would be followed by "(Rushnara Ali)".

[^2]: Available online at: https://github.com/mikajoh/tidystm
