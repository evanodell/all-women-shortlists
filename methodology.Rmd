---
title: "All Women Shortlists Methodology"
bibliography: women.bib
csl: apa.csl
lof: true
lot: true
output:
  pdf_document:
    toc: yes
    toc_depth: 3
    number_sections: true
    includes:  
      in_header: preamble.tex
  word_document:
    toc: yes
    toc_depth: 3
    number_sections: true
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 3
    number_sections: true
link-citations: yes
editor_options:
  chunk_output_type: console
always_allow_html: yes
fig_caption: yes
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set()
```


```{r setup, include = FALSE}
library(reticulate)

use_condaenv(condaenv = "spacy_condaenv", 
             conda = "/Users/evanodell/Documents/anaconda3/bin/conda")
```

\clearpage

# Descriptive Statistics

Data in Table 1 is from House of Commons Library reports [@kelly2016; @audickas2017]. All women shortlists were not used by Labour during the 2001 General Election.


```{r lab-desc-stats-table, echo=FALSE, message=FALSE, results='asis'}
library(knitr)
library(kableExtra)
library(dplyr)

labour_intakes_table <- tibble::tribble(
  ~general_election, ~total_mps, ~total_labour_mps, ~total_female_labour_mps, ~newly_elected_mps, ~intake_women, ~intake_short_list, ~nominated_short_list,
  1997L, 659L, 418L, "101 (24%)", 177L, "64 (36%)", 35L, 38L,
  2001L, 659L, 412L, "95 (23%)", 38L, "4 (11%)", 0L, 0L,
  2005L, 646L, 355L, "98 (28%)", 40L, "26 (65%)", 23L, 30L,
  2010L, 650L, 258L, "81 (31%)", 64L, "32 (50%)", 28L, 63L,
  2015L, 650L, 232L, "99 (43%)", 49L, "31 (63%)", 31L, 77L
)

# | General Election | Total MPs | Total Labour MPs | Total Female Labour MPs | Percentage Women MPs | Newly elected MPs | Intake Women | Percentage Intake Women | Intake Shortlist | Nominated Shortlist |
# |------------------|-----------|------------------|-------------------------|----------------------|-------------------|--------------|-------------------------|-------------------|----------------------|
# | 1997 | 659 | 418 | 101 | 24.2% | 177 | 64 | 36% | 35 | 38 |
# | 2001 | 659 | 412 | 95 | 23.1% | 38 | 4 | 11% | 0 | 0 |
# | 2005 | 646 | 355 | 98 | 27.6% | 40 | 26 | 65% | 23 | 30 |
# | 2010 | 650 | 258 | 81 | 31.4% | 64 | 32 | 50% | 28 | 63 |
# | 2015 | 650 | 232 | 99 | 42.7% | 49 | 31 | 63% | 31 | 77 |

kable(labour_intakes_table,  booktabs = TRUE,
      digits = 2, escape = TRUE, 
      align = c("r","r","r","r","r","r","r","r"),
      caption = "Labour MPs and Intakes",
      col.names = c("General Election",
                    "Total MPs",
                    "Labour MPs",
                    "Female Labour MPs",
                    #"Percentage Women MPs",
                    "Labour MPs Intake",
                    "Intake Women",
                    #"Percentage Intake Women",
                    "Intake Shortlist",
                    "Nominated Shortlist")) %>% 
  column_spec(1, width = "1.5cm") %>%
  column_spec(2, width = "1cm") %>%
  column_spec(3, width = "1.5cm") %>%
  column_spec(4:5, width = "2cm") %>%
  column_spec(6:7, width = "1.5cm") %>%
  column_spec(8, width = "2cm") %>%
  kable_styling(latex_options = c("striped", "HOLD_position"), full_width = FALSE)

```

```{r speech-stats-table-prep, include=FALSE}
library(readr)
library(knitr)
library(kableExtra)
library(dplyr)

speech_sum_table <- read_rds("data/speech_sum_table.rds")

speech_sum_table <- speech_sum_table %>% ungroup() %>%
  arrange(party_group, gender, short_list)

speech_sum_table$gender <- case_when(speech_sum_table$short_list==TRUE ~
                                       "All Women Shortlists",
                                     TRUE ~ speech_sum_table$gender)

speech_sum_table$gender <- case_when(speech_sum_table$short_list==FALSE & 
                                       speech_sum_table$party_group=="Labour" & 
                                       speech_sum_table$gender=="Female" ~
                                       "Non-All Women Shortlists",
                                     TRUE ~ speech_sum_table$gender )

speech_sum_table <- speech_sum_table %>% 
  select(-short_list) %>%
  select(party_group, gender, everything())

## table for total MP numbers

lab_nums <- read_rds("data/lab_nums.rds")
```

```{r speech-stats-table, echo=FALSE, results = 'asis'}
library(kableExtra)
library(knitr)
library(dplyr)

speech_sum_table2 <- speech_sum_table %>% select(-party_group) %>%
  mutate(speeches = formatC(speeches, big.mark = ","),
         words = formatC(words, big.mark = ","))

kable(speech_sum_table2,  booktabs = TRUE, digits = 2, 
      caption = "Number of Speeches and Words in Dataset",
      col.names = c("Gender", "Speeches", "Words"),
      align = c("l", "r", "r"))  %>%
  kable_styling(latex_options = c("striped", "HOLD_position"))  %>%
  group_rows("Conservatives", 4, 6) %>%
    group_rows("Labour", 7, 11) %>%
  group_rows("Liberal Democrat", 12, 14) %>%
    group_rows("Other", 15, 17) %>%
  add_indent(c(9:10))
```


# Methodology

Previous research on gender differences in political speech patterns has focused on differences between male and female politicians [@yu2014] or on variations in Hilary Clinton's speech patterns [@jones2016; @bligh2010]. This paper focuses on differences in speech patterns between female Labour MPs nominated through All Women Shortlists (AWS) and female Labour MPs nominated through open shortlists. We examined differences in speaking styles using the `Linguistic Inquiry and Word Count 2015` (LIWC) dictionary [@pennebaker2015] and the `spaCy` [@honnibal2017] Parts-of-Speech (POS) tagger. We examined differences in the topics discussed by AWS and non-AWS MPs, using ${\chi}^2$ tests for individual words and for bigrams. We trained a Naive Bayes classifier to distinguish AWS and non-AWS speeches. We used structured topic models (STM) to identify the topics discussed by AWS and non-AWS MPs.

To account for the possible effects of age, parliamentary experience and cohort, and in order to compare women selected through all women shortlists to women who were not (but who theoretically had the opportunity to contest all-women shortlists), our analysis is been restricted only to Labour MPs first elected to the House of Commons in the 1997 General Election, up to but excluding the 2017 General Election. Comparisons between MPs of different parties are also restricted to MPs first elected in the 1997 General Election, and before the 2017 General Election. Speeches made by the Speaker, including Deputy Speakers, were also excluded. Words contained in parentheses were removed, as they are added by Hansard to provide additional information not actually spoken by the MP.[^1] Speeches and data on MPs' gender and party affiliation are from a previously assembled dataset [@odell2018]. Information on candidates selected through all women shortlists is from the House of Commons Library [@kelly2016]. Unsuccessful General Election candidates selected through all women shortlists who were subsequently elected in a byelection are classified as having been selected on an all women shortlist, regardless of the selection process for that byelection. Speeches made by MPs while suspended from the Labour party where classified the same as if they had not been suspended. The dataset includes `r sum(lab_nums$distinct)` different Labour MPs, `r sum(lab_nums$distinct[lab_nums$gender=="Female"])` female MPs, `r lab_nums$distinct[lab_nums$gender=="Female" & lab_nums$short_list==TRUE]` elected from All Women Shortlists and `r lab_nums$distinct[lab_nums$gender=="Female" & lab_nums$short_list==FALSE]` elected from open shortlists, along with `r lab_nums$distinct[lab_nums$gender=="Male"]` male MPs.


# Results

## Linguistic Inquiry and Word Count

Word classification used the `Linguistic Inquiry and Word Count 2015` (LIWC) dictionary [@pennebaker2015] and tokenising tools from the `Quanteda` R package [@benoit2018]. Word counts and words-per-sentence were calculated using `stringi` [@gagolewski2018], a wrapper to the ICU regex library.

Following research by @yu2014 and @newman2008 on gender differences in language, we compared MPs speeches using the following LIWC categories:

* All Pronouns (pronoun)<!-- Feminine: -->
* First person singular pronouns (i) <!-- Feminine: -->
* First person plural pronouns (we)<!-- Masculine: -->
* Verbs (verb)<!-- Feminine: -->
* Auxiliary verbs (auxverb) <!-- Feminine: -->
* Social processes (social) <!-- Feminine: -->
* Positive emotions (posemo) <!-- Feminine: -->
* Negative emotions (negemo) <!-- Feminine: -->
* Tentative words (tentat)<!-- Feminine: -->
* Articles (article) <!-- Masculine: -->
* Prepositions (preps) <!-- Masculine: -->
* Anger words (anger)<!-- Masculine: -->
* Swear words (swear)<!-- Masculine: -->
* Cognitive processes (cogproc)<!-- Masculine: -->
* Words longer than six letters (Sixltr)<!-- Masculine: -->

We also included mean words-per-sentence (WPS), total speach word count (WC) and Flesch–Kincaid grade level (FK) [@kincaid1975], calculated using `Quanteda` [@benoit2018] and `stringi` [@gagolewski2018].

### Women vs Men

```{r liwc-tables, include=FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(effsize)

lab_liwc <- read_rds("data/lab_liwc.rds")

fem_mac <- c("pronoun", "i", "we", "verb", "auxverb", "social", "posemo", 
             "negemo", "tentat", "Sixltr",  "article", "prep",
             "anger", "swear", "cogproc", "WPS", "WC", "FK")

# lab_liwc_men_women2_subset <- lab_liwc_men_women2 %>%
#   filter(attribute %in% fem_mac)

fem_mac_df <- tibble::tibble(
  word_type = fem_mac,
  women = c(1:length(fem_mac)),
  women_sd = c(1:length(fem_mac)),
  men = c(1:length(fem_mac)),
  men_sd = c(1:length(fem_mac)),
  cohen_d = c(1:length(fem_mac)),
  magnitude = c(1:length(fem_mac)))

for (i in fem_mac) {
  d <- (cohen.d(lab_liwc[[i]], lab_liwc$gender, na.rm = TRUE,
                noncentral = FALSE, pooled = TRUE))
  fem_mac_df$women[fem_mac_df$word_type==i] <- mean(lab_liwc[lab_liwc$gender == "Female", i], na.rm = TRUE)
  fem_mac_df$men[fem_mac_df$word_type==i] <- mean(lab_liwc[lab_liwc$gender == "Male", i], na.rm = TRUE)
  fem_mac_df$women_sd[fem_mac_df$word_type==i] <- sd(lab_liwc[lab_liwc$gender == "Female", i], na.rm = TRUE)
  fem_mac_df$men_sd[fem_mac_df$word_type==i] <- sd(lab_liwc[lab_liwc$gender == "Male", i], na.rm = TRUE)
  fem_mac_df$cohen_d[fem_mac_df$word_type==i] <- (d$estimate[[1]])
  fem_mac_df$magnitude[fem_mac_df$word_type==i] <- as.character(d$magnitude[[1]])
}

#fem_mac_df

fem_mac_df$word_type <- recode(fem_mac_df$word_type,
               "pronoun" = "All Pronouns",
               "i" = "First person singular pronouns",
               "verb" = "Verbs",
               "auxverb" = "Auxiliary verbs",
               "social" = "Social processes ",
               "posemo" = "Positive emotions",
               "negemo" = "Negative emotions",
               "tentat" = "Tentative words",
               "Sixltr" = "More than six letters",
               "we" = "First person plural pronouns",
               "article" = "Articles",
               "prep" = "Prepositions",
               "anger" = "Anger words",
               "swear" = "Swear words",
               "cogproc" = "Cognitive processes",
               "WPS" = "Words per Sentence",
               "WC" = "Total Word Count",
               "FK" = "Flesh-Kincaid Grade Level")

```

```{r gender-effect-sizes-table, echo=FALSE, results = 'asis'}
library(knitr)
library(kableExtra)
kable(fem_mac_df,  booktabs = TRUE,  digits = 2, 
      caption = "Effect Sizes for Male and Female Labour MPs",
      col.names = c("", "Mean", "SD", "Mean", "SD",
                    "Cohen's D", "Magnitude") )  %>%
  kable_styling(latex_options = c("striped", "HOLD_position")) %>% 
  add_header_above(c(" " = 1, "Women" = 2, "Men" = 2, "Effect Size" = 2))
```

There are no categories where gender differences meet the effect size threshold of $|0.2|$ suggested by Cohen [-@cohen1988, 25--26] to indicate a small effect. 4 categories -- words with more than six letters, prepositions, words-per-sentence and Flesh-Kincaid grade level -- exceeded the $|0.1|$ threshold suggested by Newman et al [-@newman2008].


### Shortlists vs Non-Shortlists

```{r liwc-shortlists, include=FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(purrr)
library(effsize)

lab_liwc <- read_rds("data/lab_liwc.rds")

lab_liwc_women <- filter(lab_liwc, gender=="Female",
                         house_start_date >= "1997-05-01")

## Group by gender, short_lsit, see what's up
cols <- names(lab_liwc_women)[4:92]

lab_liwc_women_mean <- list(c("WC"), cols) %>%
 map2(lst(mean=mean, funs(weighted.mean(., WC, na.rm=TRUE))),
  ~ lab_liwc_women %>%
   group_by(short_list, y_since_start) %>%
   summarise_at(.x, .y)) %>%
 reduce(inner_join)

lab_liwc_women_tidy_mean <- gather(lab_liwc_women_mean, "attribute",
                                   "weighted_mean", -short_list,
                                   -y_since_start) 

lab_liwc_women_sd <- list(c("WC"), cols) %>%
 map2(lst(mean=mean, funs(sd(., na.rm=TRUE))),
  ~ lab_liwc_women %>%
   group_by(gender, short_list, y_since_start) %>%
   summarise_at(.x, .y)) %>%
 reduce(inner_join)

lab_liwc_women_tidy_sd <- gather(lab_liwc_women_sd, "attribute",
                                 "sd", -short_list, -gender,
                                 -y_since_start) 

## Joining together the SD and Means to get CIs
lab_liwc_women2 <- left_join(lab_liwc_women_tidy_mean,
                             lab_liwc_women_tidy_sd) %>% 
 left_join(lab_liwc_women %>% 
    group_by(gender, short_list, y_since_start) %>% summarise(n=n())) %>%
 mutate(se = sd / sqrt(n),
   lower_ci = weighted_mean - qt(1 - (0.05 / 2), n - 1) * se,
   upper_ci = weighted_mean + qt(1 - (0.05 / 2), n - 1) * se)

lab_liwc_women2_subset <- lab_liwc_women2 %>%
  filter(attribute %in% c(fem_mac, "WC"))

```


The following plots show changes in the occurences of selected LIWC terms, words-per-sentence, total word count and Flesch–Kincaid grade level, over the course of an MP's career. There do not appear to be any notable changes in speaking style over the course of female Labour MPs' careers.

```{r short-list-plot-key-variables, echo=FALSE, fig.cap="\\label{sl-key-variables}Occurence of selected LIWC terms", fig.height=8}
library(ggplot2)

lab_liwc_women2_subset$attribute <- recode(lab_liwc_women2_subset$attribute,
               "pronoun" = "All pronouns",
               "i" = "First person\nsingular pronouns",
               "verb" = "Verbs",
               "auxverb" = "Auxiliary verbs",
               "social" = "Social processes ",
               "posemo" = "Positive emotions",
               "negemo" = "Negative emotions",
               "tentat" = "Tentative words",
               "Sixltr" = "More than six letters",
               "we" = "First person\nplural pronouns",
               "article" = "Articles",
               "prep" = "Prepositions",
               "anger" = "Anger words",
               "swear" = "Swear words",
               "cogproc" = "Cognitive processes",
               "WPS" = "Words per sentence",
               "WC" = "Word count",
               "FK" = "Flesh-Kincaid Grade Level")

lab_liwc_women2_subset$short_list <- recode(
  as.factor(lab_liwc_women2_subset$short_list), 
  "FALSE" = "Open ShortList",
  "TRUE" = "All Women Shortlist")

p_sl1 <- ggplot(data=filter(lab_liwc_women2_subset, 
                            attribute != "Words per sentence", 
                            attribute != "Word count",
                            attribute != "Flesh-Kincaid Grade Level"),
                aes(x = y_since_start, y = weighted_mean, colour = short_list)) + 
  geom_line(alpha=0.7) +
  scale_y_continuous(labels = function(x) paste0(x, "%")) +
  facet_wrap(~attribute) + 
  labs(title = "Occurence of selected LIWC terms", colour = "") + 
  ylab("Weighted Mean") +
  xlab("Years since entering House of Commons") + 
  theme(legend.position = "bottom")

ggsave("p01_sl1.svg", plot = p_sl1, path="plots", device = "svg",
       width = 20, height = 20, units = "cm")

p_sl1
```

```{r sl-wps-plot, eval=FALSE, include=FALSE}
p_sl_wps <- ggplot(data=filter(lab_liwc_women2_subset,
                               attribute=="Words per Sentence"),
                aes(x = y_since_start, y = weighted_mean, colour = short_list)) +
  geom_line(alpha=0.7) +
  labs(title = "Words per Sentence", colour = "") + 
  ylab("Weighted Mean") +
  xlab("Years since entering House of Commons") + 
  theme(legend.position = "bottom")

p_sl_wps
```

```{r sl-wc-plot, eval=FALSE, include=FALSE}
p_sl_wc <- ggplot(data=filter(lab_liwc_women2_subset,
                               attribute=="Total Word Count"),
                aes(x=y_since_start, y = weighted_mean, colour = short_list)) +
  geom_line(alpha=0.7) +
  labs(title = "Total Word Count per Speech", colour = "") + 
  ylab("Mean") +
  xlab("Years since entering House of Commons") + 
  theme(legend.position = "bottom")

p_sl_wc
```

```{r fem-mac-df-sl-creation, include=FALSE}
fem_mac_df_sl <- tibble::tibble(
  word_type = fem_mac,
  short_list = c(1:length(fem_mac)),
  short_list_sd = c(1:length(fem_mac)),
  non_short_list = c(1:length(fem_mac)),
  non_short_list_sd = c(1:length(fem_mac)),
  cohen_d = c(1:length(fem_mac)),
  magnitude = c(1:length(fem_mac)))

lab_liwc_women$short_list <- as.factor(lab_liwc_women$short_list)

for (i in fem_mac) {
  d <- (cohen.d(lab_liwc_women[[i]], lab_liwc_women$short_list, na.rm = TRUE,
                noncentral = FALSE, pooled = TRUE))
  fem_mac_df_sl$short_list[fem_mac_df_sl$word_type==i] <-
    mean(lab_liwc_women[lab_liwc_women$short_list == TRUE, i], na.rm = TRUE)
  fem_mac_df_sl$non_short_list[fem_mac_df_sl$word_type==i] <- 
    mean(lab_liwc_women[lab_liwc_women$short_list == FALSE, i], na.rm = TRUE)
  fem_mac_df_sl$short_list_sd[fem_mac_df_sl$word_type==i]  <- 
      sd(lab_liwc_women[lab_liwc_women$short_list == TRUE, i], na.rm = TRUE)
  fem_mac_df_sl$non_short_list_sd[fem_mac_df_sl$word_type==i] <- 
    sd(lab_liwc_women[lab_liwc_women$short_list == FALSE, i], na.rm = TRUE)
  fem_mac_df_sl$cohen_d[fem_mac_df_sl$word_type == i] <- 
    d$estimate[[1]]
  fem_mac_df_sl$magnitude[fem_mac_df_sl$word_type == i] <-
    as.character(d$magnitude[[1]])
}

fem_mac_df_sl$word_type <- recode(fem_mac_df_sl$word_type,
               "pronoun" = "All Pronouns",
               "i" = "First person singular pronouns",
               "verb" = "Verbs",
               "auxverb" = "Auxiliary verbs",
               "social" = "Social processes ",
               "posemo" = "Positive emotions",
               "negemo" = "Negative emotions",
               "tentat" = "Tentative words",
               "Sixltr" = "More than six letters",
               "we" = "First person plural pronouns",
               "article" = "Articles",
               "prep" = "Prepositions",
               "anger" = "Anger words",
               "swear" = "Swear words",
               "cogproc" = "Cognitive processes",
               "WPS" = "Words per Sentence",
               "WC" = "Total Word Count",
               "FK" = "Flesh-Kincaid Grade Level")

```

```{r sl-effect-sizes, echo=FALSE, results = 'asis'}
library(knitr)
library(kableExtra)
kable(fem_mac_df_sl,  booktabs = TRUE, digits = 2, 
      caption = "Effect Sizes for Female Labour MPs by selection process",
      col.names = c("", "Mean", "SD", "Mean", "SD",
                    "Cohen's D", "Magnitude")) %>%
  kable_styling(latex_options = c("striped", "HOLD_position")) %>% 
  add_header_above(c(" " = 1, "All Women Shortlists" = 2,
                     "Open Shorlists" = 2, "Effect Size" = 2))

```

There are no categories among female Labour MPs by selection process meeting the $|0.2|$ threshold. Only one category -- first person plural pronouns, _d_=0.19 -- exceeded $|0.1|$.

### Conservatives vs Labour

```{r tory-labour-liwc-analysis, include=FALSE}
library(readr)
library(effsize)
library(dplyr)

con_liwc <- read_rds("data/con_liwc.rds")

lab_liwc <- read_rds("data/lab_liwc.rds")

lab_con_liwc <- bind_rows(con_liwc, lab_liwc)

fem_mac <- c("pronoun", "i", "we", "verb", "auxverb", "social", "posemo", 
             "negemo", "tentat", "Sixltr",  "article", "prep",
             "anger", "swear", "cogproc", "WPS", "WC", "FK")

lab_con_df <- tibble::tibble(
  word_type = fem_mac,
  labour = c(1:length(fem_mac)),
  labour_sd = c(1:length(fem_mac)),
  tory = c(1:length(fem_mac)),
  tory_sd = c(1:length(fem_mac)),
  cohen_d = c(1:length(fem_mac)),
  magnitude = c(1:length(fem_mac)))

for (i in fem_mac) {
  d <- (cohen.d(lab_con_liwc[[i]], lab_con_liwc$party_group, na.rm = TRUE,
                noncentral = FALSE, pooled = TRUE))
  lab_con_df$labour[lab_con_df$word_type==i] <- mean(lab_con_liwc[lab_con_liwc$party_group == "Labour", i], na.rm = TRUE)
  lab_con_df$tory[lab_con_df$word_type==i] <- mean(lab_con_liwc[lab_con_liwc$party_group == "Conservative", i], na.rm = TRUE)
  lab_con_df$labour_sd[lab_con_df$word_type==i] <- sd(lab_con_liwc[lab_con_liwc$party_group == "Labour", i], na.rm = TRUE)
  lab_con_df$tory_sd[lab_con_df$word_type==i] <- sd(lab_con_liwc[lab_con_liwc$party_group == "Conservative", i], na.rm = TRUE)
  lab_con_df$cohen_d[lab_con_df$word_type==i] <- (d$estimate[[1]])
  lab_con_df$magnitude[lab_con_df$word_type==i] <- as.character(d$magnitude[[1]])
}

#lab_con_df

lab_con_df$word_type <- recode(lab_con_df$word_type,
                               "pronoun" = "All Pronouns",
                               "i" = "First person singular pronouns",
                               "verb" = "Verbs",
                               "auxverb" = "Auxiliary verbs",
                               "social" = "Social processes ",
                               "posemo" = "Positive emotions",
                               "negemo" = "Negative emotions",
                               "tentat" = "Tentative words",
                               "Sixltr" = "More than six letters",
                               "we" = "First person plural pronouns",
                               "article" = "Articles",
                               "prep" = "Prepositions",
                               "anger" = "Anger words",
                               "swear" = "Swear words",
                               "cogproc" = "Cognitive processes",
                               "WPS" = "Words per Sentence",
                               "WC" = "Total Word Count",
                               "FK" = "Flesh-Kincaid Grade Level")

```


```{r tory-labour-effect-sizes-table, echo=FALSE, results = 'asis'}
library(knitr)
library(kableExtra)
kable(lab_con_df,  booktabs = TRUE, digits = 2, 
      caption = "Effect Sizes for All Labour and Conservative MPs",
      col.names = c("", "Mean", "SD", "Mean", "SD",
                    "Cohen's D", "Magnitude") )  %>%
  kable_styling(latex_options = c("striped", "HOLD_position")) %>% 
  add_header_above(c(" " = 1, "Labour" = 2,
                     "Conservatives" = 2, "Effect Size" = 2))
```

There are no categories with effect sizes exceeding $|0.2|$ between Labour and Conservative MPs, like inter-Labour differences.


### All MPs Gender Differences

There are no categories with effect sizes exceeding $|0.2|$ when comparing all male and female MPs elected from 1997 onwards. There is only one category, "Articles", with an effect size of 0.11, greater than the $|0.1|$ threshold suggested by @newman2008.

```{r all-party-effect-sizes, echo=FALSE, results = 'asis'}
library(knitr)
library(kableExtra)
library(readr)
all_party_gender_df <- read_rds("data/all_party_gender_df.rds")

kable(all_party_gender_df,  booktabs = TRUE, digits = 2, 
      caption = "Effect Sizes for Male and Female MPs, All Parties",
      col.names = c("", "Mean", "SD", "Mean", "SD",
                    "Cohen's D", "Magnitude")) %>%
  kable_styling(latex_options = c("striped", "HOLD_position")) %>% 
  add_header_above(c(" " = 1, "Women" = 2,
                     "Men" = 2, "Effect Size" = 2))

```


## POS Analysis

```{r tag-means, include=FALSE}
library(readr)
library(purrr)
library(dplyr)
library(tidyr)

ano_lab_tag <- read_rds("data/ano_lab_tag.rds")

ano_lab_tag_gender <- ano_lab_tag %>% 
  select(NN, NNS, gender) %>% 
  #gather(key = "type", value = "value", NN, NNS) %>%
  group_by(gender)

ano_lab_tag_gender2 <- ano_lab_tag_gender %>% 
  gather(key = "type", value = "value", NN, NNS) %>%
  group_by(gender, type) %>%
  summarise(mean = mean(value, na.rm = TRUE),
            sd = sd(value, na.rm = TRUE))

ano_lab_tag_sl <- ano_lab_tag %>%
  select(NN, NNS, short_list, gender) %>% 
  #gather(key = "type", value = "value", NN, NNS) %>%
  group_by(short_list) %>% filter(gender == "Female") %>% select(-gender)

ano_lab_tag_sl2 <- ano_lab_tag_sl %>% 
  gather(key = "type", value = "value", NN, NNS) %>%
  group_by(short_list, type) %>%
  summarise(mean = mean(value, na.rm = TRUE),
            sd = sd(value, na.rm = TRUE))
```

```{r pos-means, include=FALSE}
library(readr)
library(purrr)
library(dplyr)
library(tidyr)

ano_lab_pos <- read_rds("data/ano_lab_pos.rds")

ano_lab_pos_gender <- ano_lab_pos %>% 
  select(NOUN, ADV, VERB, ADJ, gender) %>% 
  group_by(gender)

ano_lab_pos_gender2 <- ano_lab_pos_gender %>% 
  gather(key = "type", value = "value", NOUN, ADV, VERB, ADJ) %>%
  group_by(gender, type) %>%
  summarise(mean = mean(value, na.rm = TRUE),
            sd = sd(value, na.rm = TRUE))

ano_lab_pos_sl <- ano_lab_pos %>%
  select(NOUN, ADV, VERB, ADJ, short_list, gender) %>% 
  group_by(short_list) %>% filter(gender == "Female") %>% select(-gender)

ano_lab_pos_sl2 <- ano_lab_pos_sl %>% 
  gather(key = "type", value = "value", NOUN, ADV, VERB, ADJ) %>%
  group_by(short_list, type) %>%
  summarise(mean = mean(value, na.rm = TRUE),
            sd = sd(value, na.rm = TRUE))
```

```{r pos-tag-tables, include=FALSE}
library(effsize)

pos_df_gender <- bind_rows(ano_lab_pos_gender2, ano_lab_tag_gender2)

pos_df_gender <- pos_df_gender %>% 
  gather(variable, value, -(gender:type)) %>%
  unite(temp, gender, variable) %>%
  spread(temp, value)

pos_df_gender$cohen_d <- NA
pos_df_gender$magnitude <- NA

for (i in pos_df_gender$type) {
  
  if (i=="NN" || i == "NNS") {
  
   d <- (cohen.d(ano_lab_tag[[i]], ano_lab_tag$gender,
                na.rm = TRUE, noncentral = FALSE, pooled = TRUE))
  } else {
    
     d <- (cohen.d(ano_lab_pos[[i]], ano_lab_pos$gender,
                na.rm = TRUE, noncentral = FALSE, pooled = TRUE))
  }
   
  pos_df_gender$cohen_d[pos_df_gender$type==i] <- (d$estimate[[1]])
  
  pos_df_gender$magnitude[pos_df_gender$type==i] <- as.character(d$magnitude[[1]])
}

pos_df_gender$type <- factor(pos_df_gender$type, levels=c("NOUN", "NNS", "NN", "ADJ", "ADV", "VERB"))

## Recoding pos_df_sl$type into pos_df_sl$type_rec
pos_df_gender$type <- recode(pos_df_gender$type,
               "NOUN" = "All Nouns",
               "NNS" = "Plural Nouns",
               "NN" = "Singular Nouns",
               "ADJ" = "Adjectives",
               "ADV" = "Adverbs",
               "VERB" = "Verbs")

pos_df_gender <- pos_df_gender[order(pos_df_gender$type),]

pos_df_gender[2:5] <- pos_df_gender[2:5] * 100

pos_df_sl <- bind_rows(ano_lab_pos_sl2, ano_lab_tag_sl2)

pos_df_sl <- pos_df_sl %>% 
  gather(variable, value, -(short_list:type)) %>%
  unite(temp, short_list, variable) %>%
  spread(temp, value)

pos_df_sl$cohen_d <- NA
pos_df_sl$magnitude <- NA

for (i in pos_df_sl$type) {
  
  if (i=="NN" || i == "NNS") {
  
   d <- (cohen.d(ano_lab_tag[[i]], ano_lab_tag$short_list,
                na.rm = TRUE, noncentral = FALSE, pooled = TRUE))
  } else {
    
     d <- (cohen.d(ano_lab_pos[[i]], ano_lab_pos$short_list,
                na.rm = TRUE, noncentral = FALSE, pooled = TRUE))
  }
   
  pos_df_sl$cohen_d[pos_df_sl$type==i] <- (d$estimate[[1]])
  
  pos_df_sl$magnitude[pos_df_sl$type==i] <- as.character(d$magnitude[[1]])
}

pos_df_sl$type <- factor(pos_df_sl$type, levels=c("NOUN", "NNS", "NN", "ADJ", "ADV", "VERB"))

## Recoding pos_df_sl$type into pos_df_sl$type_rec
pos_df_sl$type <- recode(pos_df_sl$type,
               "NOUN" = "All Nouns",
               "NNS" = "Plural Nouns",
               "NN" = "Singular Nouns",
               "ADJ" = "Adjectives",
               "ADV" = "Adverbs",
               "VERB" = "Verbs")

pos_df_sl <- pos_df_sl[order(pos_df_sl$type),]

pos_df_sl[2:5] <- pos_df_sl[2:5] * 100

```

```{r pos-gender-table, echo=FALSE, results = 'asis'}
library(knitr)
library(kableExtra)
kable(pos_df_gender,  booktabs = TRUE, digits = 2, 
      caption = "Part-of-Speech Effect Sizes for Male and Female Labour MPs",
      col.names = c("Word Type", "Mean", "SD", "Mean", "SD",
                    "Cohen's D", "Magnitude") )  %>%
  kable_styling(latex_options = c("striped", "HOLD_position")) %>% 
  add_header_above(c(" " = 1, "Women" = 2, "Men" = 2, "Effect Size" = 2)) %>%
  add_indent(c(2:3))
```

```{r pos-sl-table, echo=FALSE, results = 'asis'}
library(knitr)
library(kableExtra)
kable(pos_df_sl,  booktabs = TRUE, digits = 2, 
      caption = "Part-of-Speech Effect Sizes for AWS and non-AWS Labour MPs",
      col.names = c("Word Type", "Mean", "SD", "Mean", "SD",
                    "Cohen's D", "Magnitude"))  %>%
  kable_styling(latex_options = c("striped", "HOLD_position")) %>% 
  add_header_above(c(" " = 1, "All Women Shortlists" = 2,
                     "Open Shorlists" = 2, "Effect Size" = 2)) %>%
  add_indent(c(2:3))
```

Part-of-speech (POS) tagging was done using `spaCy` [@honnibal2017] and the `spacyr` package [@benoit2018a]. There is one small gender difference (_d_ = $|0.22|$) in the use of plural nouns, which make up  `r paste0(formatC(pos_df_gender$Female_mean[pos_df_gender$type=="Plural Nouns"], digits = 3),"%")` of the words used by female Labour MPs, compared to  `r paste0(formatC(pos_df_gender$Male_mean[pos_df_gender$type=="Plural Nouns"], digits = 3),"%")` of words spoken by male Labour MPs. As with LIWC, there are no categories where _d_ >= $|0.2|$ when comparing female Labour MPs by selection process. 

## Tokenising / Keyness

The most commonly used words by both men and women would be protocol decorum expressions, so we calculate the keyness of words to identify gender differences in the choices of topics raised by men and women, and by short-list and non-shortlist women.

### Men vs Women

Keyness -- a linguistic measure of the frequency of different words in two groups of texts -- reveals clear gender differences in the most disproportionately common words used by female and male Labour MPs. Unsurprisingly, despite male MPs saying almost twice as many words (`r formatC(speech_sum_table$words[speech_sum_table$party_group == "Labour" & speech_sum_table$gender == "Male"], big.mark = ",")` vs `r formatC(speech_sum_table$words[speech_sum_table$party_group == "Labour" & speech_sum_table$gender == "Female"], big.mark = ",")`) as their female colleagues, female Labour MPs were more than two-and-a-half (2.61) times as likely to say "women". They were also much more likely to use "women's" and "woman" in parliamentary debate. Female Labour MPs also appear much more likely to discuss "children", "people", "care", "families", "home", "parents", "work" and social policy areas such as "services", "disabled [people]" and "housing" than their male colleagues. Male MPs were more likely to refer to military topics ("Iraq", "nuclear"), and to parliamentary process and protocol  -- "question", "political", "conservative", "electoral", "house", "party", "argument" "liberal" and "point" are far more common in speeches by male Labour MPs than by female ones. This could suggest that male Labour MPs are more comfortable using the traditional language of House of Commons debate, and are more concerned with the rules, procedures and processes of the parliamentary system than their female colleagues.

```{r gender-keyness-plot, echo=FALSE, fig.height=8, message=FALSE, warning=FALSE, fig.cap="\\label{gender-keyness}Keyness between Labour MPs, by Gender"}
library(ggplot2)
library(readr)
library(dplyr)
library(quanteda)

lab_dfm_key <- read_rds("data/lab_dfm_key.rds")

lab_keyness <- textstat_keyness(lab_dfm_key, measure = c("chi2"))

#head(lab_keyness)

lab_keyness_plot <- textplot_keyness(lab_keyness, n = 25, 
                                     color = c("purple", "darkgreen")) +  
  #coord_cartesian(xlim=c(-3100, 14100)) +
  scale_x_continuous(limits = c(-3100, 14100), 
                     breaks = seq(-3000, 15000, by = 1500)) + 
  labs(title = "Keyness between Labour MPs, by Gender",
       x = "Chi2") + 
  theme(legend.position = "bottom")

ggsave("p02_lab_keyness_plot.svg", plot = lab_keyness_plot,
       device = "svg", path = "plots")

lab_keyness_plot
```

### Shortlists vs Non-Shortlists

Keyness differences by selection process are not as obviously stereotypical. Nonetheless, the most common words amongst AWS MPs included "carers", "disabled", "bedroom" and "sen" (Special Educational Needs). Also of note is AWS MPs making more references to their "constituency" and its "constituents", suggesting that AWS MPs may draw on the fact they were elected by their constituents as a source political legitimacy, at least more than non-AWS MPs.

```{r short-list-keyness-plot, echo=FALSE, fig.height=8, message=FALSE, warning=FALSE, fig.cap="\\label{sl-keyness}Keyness between Female Labour MPs, by Selection Process"}

lab_dfm_key_fem <- read_rds("data/lab_dfm_key_fem.rds")

lab_keyness_fem <- textstat_keyness(lab_dfm_key_fem, measure = c("chi2"))

#head(lab_keyness_fem)

fem_keyness_plot <- textplot_keyness(lab_keyness_fem, n=25) + 
  scale_color_manual(labels = c("Non-AWS", "AWS"),
                     values = c("#ff674c", "#02d5a1"), name = NULL) +
  scale_x_continuous(limits = c(-700, 700), 
                     breaks = seq(-500, 800, by = 100)) + 
  labs(title = "Keyness between Female Labour MPs, by Selection Process",
       x = "Chi2") + 
  theme(legend.position = "bottom")

ggsave("p03_fem_keyness_plot.svg", plot = fem_keyness_plot,
       device = "svg", path = "plots")

fem_keyness_plot
```

### Labour vs Conservative

The keyness differences between Labour and Conservative MPs are much greater than gender differences within Labour. The very high use of "Lady" by Conservative MPs is reflective of the greater proportion of female MPs in other parties, as it is often used to refer to comments by other members of the house. It may also represent a greater use of traditional hosue decorum by Conservative MPs.


```{r lab-con-keyness, echo=FALSE, fig.height=8, message=FALSE, warning=FALSE, fig.cap="\\label{party-keyness}Keyness between Labour and Conservative MPs"}
library(ggplot2)
library(quanteda)

lab_con_dfm <- read_rds("data/lab_con_dfm.rds")

lab_con_keyness <- textstat_keyness(lab_con_dfm, measure = c("chi2"))

#head(lab_keyness_fem)

lab_con_keyness_plot <- textplot_keyness(lab_con_keyness, n=25, 
                                         color = c("blue", "red")) + 
  scale_x_continuous(limits = c(-4100, 8000), 
                     breaks = seq(-3000, 8000, by = 1000)) +
  labs(title = "Keyness between Labour and Conservative MPs",
       x = "Chi2") + 
  theme(legend.position = "bottom")

ggsave("p04_lab_con_keyness_plot.svg", plot = lab_con_keyness_plot,
       device = "svg", path = "plots")

lab_con_keyness_plot
```

## Bigrams

We created bigrams of all first person plural and singular pronouns for female Labour MPs. As above, AWS MPs are far more likely to make references to their constituency or their constituents.

```{r bigrams-short-list-keyness, echo=FALSE, message=FALSE, warning=FALSE, fig.height=8, fig.cap="\\label{bigrams-keyness}Bigram Keyness in Female Labour MPs by Selection Process"}
library(quanteda)
library(readr)
library(ggplot2)

pro_bigram <- read_rds("data/pro_bigram.rds")

pro_dfm <- dfm(pro_bigram, verbose=TRUE, groups = "short_list")

pro_dfm_key <- textstat_keyness(pro_dfm, target = "FALSE", measure = "chi2")

#pro_dfm_key$n_total <- pro_dfm_key$n_reference + pro_dfm_key$n_target

pro_dfm_key_plot <- textplot_keyness(pro_dfm_key, n=25) +  
    scale_color_manual(labels = c("Non-AWS", "AWS"), 
                      values = c("#ff674c", "#02d5a1"), name = NULL) +
    scale_x_continuous(limits = c(-650, 500), 
                     breaks = seq(-600, 500, by = 100)) +
  labs(title = "Bigram Keyness in Female Labour MPs by Selection Process",
       x = "Chi2") + 
  theme(legend.position = "bottom")

ggsave("p05_pro_dfm_key_plot.svg", plot = pro_dfm_key_plot,
       device = "svg", path = "plots")

pro_dfm_key_plot

```

## Naive Bayes classification

We trained a Naive Bayes classifier with document-frequency priors and a multinomial distribution to predict the gender of speakers when given speeches by all Labour MPs in our dataset, and the selection process when only given female Labour MPs. The accuracy of both models were roughly equivalent, 70.67% accuracy when predicting gender and 71.22% when predicting shortlists. By contrast, the classifier could distinguish between Labour and Conservative speeches with 74.23% accuracy.


## Topic Models

Using topic models to classify text is widely used in social sciences [@grimmer2013], as, when combined with the large volume of plain text data available, it allows for a rapid and consistent method of analysis . Topic modelling and other statistic methods of textual analysis are not a substitute for reading the texts themselves, but can augment other analysis or -- as in this case -- analyse and classify larger amounts of text than would be feasible using human coders [@grimmer2013]. Topic models classify a series of documents (in this case individual speeches) into one of a given number of topics, identifying terms that are common in some documents but rare in others. When developing topic models, there is a trade-off between high precision in the classification of each document with broader topics when using smaller numbers of topics, or lower precision in individual speech classification with more finely-grained topics when using larger numbers of topics. @grimmer2013 also highlight the importance of validating unsurpervised topic models when applied to new sets of texts, which we have done [below](#Manual Validation).

The R package `stm` [@roberts2018] implements a structured topic model (STM) [@roberts2016; @arora2013]. An STM incorporates covariates into the topic classification algorithm, creating possibilities for hypothesis testing. This differs from traditional topic modelling methods using latent variables to identify topics [e.g. with latent Dirichlet allocation @blei2003], and then comparing proportions of each topic to one or more external variables. STM allows us to incorporate the variables we are interested in to the topic model itself using a generalised linear model; i.e. the proportion of speechs classified as belonging to each topic can vary as a function of the AWS and gender variables.

We incorporated the AWS status of speakers and their gender as prevalence covariates into our topic model. 

 <!--We then used `stm`'s implementation of Latent Dirichlet Allocation [@blei2003]-->

```{r topic-model-selection-plot, echo=FALSE, fig.cap="\\label{topic-model-selection}Topic Model Selection"}
library(readr)
library(tidyr)
library(ggplot2)
library(purrr)
library(dplyr)

topic_model_k0 <- read_rds("data/topic_model_k0_m.rds")

k_models <- read_rds("data/k_models.rds")

k_result <- k_models %>%
  transmute(K,
            `Lower bound` = lbound,
            Residuals = map_dbl(check_residuals, "dispersion"),
            `Semantic coherence` = map_dbl(semantic_coherence, mean),
            `Held-out likelihood` = map_dbl(eval_heldout, "expected.heldout")) %>%
  gather(Metric, Value, -K)

p_k_result <- ggplot(k_result, aes(K, Value, color = Metric)) +
  geom_line(size = 1.5, alpha = 0.7, show.legend = FALSE) +
  scale_colour_viridis_d() + 
  scale_x_continuous(breaks = c(30, 45, 60, 66, 80, 100)) + 
  facet_wrap(~Metric, scales = "free_y") +
  labs(x = expression(italic("K")),
       y = NULL)

ggsave("p06_k_result.svg", plot = p_k_result, path="plots", device = "svg",
       width = 20, height = 20, units = "cm")

p_k_result
```

We created six topic models with different numbers of topics (_K_). We created models with 30, 45, 60, 80 and 100 topics, and used an algorithm developed by @lee2014c, implemented in the `stm` package [@roberts2018], which resulted in _K_ = 66. Figure \ref{topic-model-selection} shows, clockwise from the top-left, heldout likelihood [explain], lower bound [explain], semantic coherence [@mimno2011], and the multinomial dispersion of the STM residuals [@taddy2012], 

As seen in Figure \ref{topic-model-selection}, the _K_ = 66 result appears to produce the best result, a topic model with `r formatC(topic_model_k0$settings$dim$K, , big.mark = ",")` topics, across `r formatC(topic_model_k0$settings$dim$N, , big.mark = ",")` speeches with a dictionary of `r formatC(topic_model_k0$settings$dim$V, , big.mark = ",")` words. All models were created using the "spectral" method developed by @arora2013, implemented in the `stm` package by @roberts2018. 

One of the topics -- Topic 66 -- is never the most likely topic in the matrix of number of documents by number of topics -- labelled $\theta$ by @roberts2018 -- and so while it is included in the model, assignment of single topics to speeches uses the highest $\theta$ for each speech. Other topics are rarely used -- Topic 53, which we labelled "Dispatch Box", only has five topics assigned to it, four from Male MPs and one from an AWS MP.

Figure \ref{k0-network} is a Fruchterman-Reingold force-directed diagram [@fruchterman1991] of correlations between different topics. Larger vertices indicate more common topics, and the colour scale indicates the proportion of speeches classed in that topic made by AWS and non-AWS female Labour MPs, respectively. Edges indicate positive correlations between the two linked topics.

```{r stm-analysis-k0-network-graph, echo=FALSE, message=FALSE, warning=FALSE, fig.height=7, fig.cap="\\label{k0-network}Fruchterman-Reingold plot of Topic Network"}
library(readr)
library(stm)
library(viridis)
library(dplyr)
library(igraph)
library(ggplot2)
library(quanteda)
#library(tidystm)

corr_topic_k0 <- read_rds("data/corr_topic_k0_m.rds")

prep_k0 <- read_rds("data/prep_k0_m.rds")

lab_corpus_stm <- read_rds("data/lab_corpus_stm.rds")

prep_df_k0 <- summary(prep_k0)[[3]]

prep_df_k0 <- as.data.frame(do.call(rbind, prep_df_k0))

prep_df_k0$topic <- NA

prep_df_k0$topic <- rep(1:66, each = 3)

prep_df_k0$type <- row.names(prep_df_k0)

prep_df_k0$type <- gsub("\\.[0-9][0-9]", "", prep_df_k0$type)

prep_df_k0$type <- gsub("\\.[0-9]", "", prep_df_k0$type)

prep_df_k0$type <- gsub("\\.$", "", prep_df_k0$type)

prep_df_k0_fem  <- prep_df_k0 %>% filter(type != "genderMale")

prep_df_k0_coeff <- prep_df_k0 %>% filter(type == "short_listTRUE")

vlabels=NULL
layout=NULL

topics <- 1:nrow(corr_topic_k0$posadj)
  
x <- corr_topic_k0$posadj[topics, topics]
  
g <- igraph::graph.adjacency(x, mode="directed", weighted=TRUE, diag=FALSE)
igraph::E(g)$size <- 1
igraph::E(g)$lty <- 2
igraph::E(g)$color <- "black"
igraph::V(g)$label <- topics

plotcord_k0 <- data.frame(layout_with_fr(g))
  
edgelist_k0 <- get.edgelist(g)

#convert to a four column edge data frame with source and destination coordinates
edges_k0 <- data.frame(plotcord_k0[edgelist_k0[,1],], 
                    plotcord_k0[edgelist_k0[,2],])

colnames(edges_k0) <- c("X1","Y1","X2","Y2")

plotcord_k0$topic <- as.numeric(row.names(plotcord_k0))
  
#plotcord_k0 <- plotcord_k0 %>% left_join(prep_df_k0)

lab_corpus_stm$meta$eo_id <- docnames(lab_corpus_stm$documents)

topic_dt_k0 <- make.dt(topic_model_k0, lab_corpus_stm$meta)

set.seed(24)
topic_dt_k0$assigned_topic <- colnames(topic_dt_k0[,2:67])[max.col(topic_dt_k0[,2:67],ties.method="random")]

topic_dt_k0$theta <- apply(topic_dt_k0[,2:67], 1, max)

topic_dt_k0$assigned_topic <- as.factor(topic_dt_k0$assigned_topic)

#x <- topic_dt_k0 %>% filter(assigned_topic == "Topic66")

## Reordering x$assigned_topic
topic_dt_k0$assigned_topic <- factor(topic_dt_k0$assigned_topic, 
                           levels=c("Topic1", "Topic2", "Topic3",
                                    "Topic4", "Topic5", "Topic6",
                                    "Topic7", "Topic8", "Topic9",
                                    "Topic10", "Topic11", "Topic12",
                                    "Topic13", "Topic14", "Topic15",
                                    "Topic16", "Topic17", "Topic18",
                                    "Topic19", "Topic20", "Topic21",
                                    "Topic22", "Topic23", "Topic24",
                                    "Topic25", "Topic26", "Topic27",
                                    "Topic28", "Topic29", "Topic30",
                                    "Topic31", "Topic32", "Topic33",
                                    "Topic34", "Topic35", "Topic36",
                                    "Topic37", "Topic38", "Topic39",
                                    "Topic40", "Topic41", "Topic42",
                                    "Topic43", "Topic44", "Topic45",
                                    "Topic46", "Topic47", "Topic48",
                                    "Topic49", "Topic50", "Topic51",
                                    "Topic52", "Topic53", "Topic54",
                                    "Topic55", "Topic56", "Topic57",
                                    "Topic58", "Topic59", "Topic60",
                                    "Topic61", "Topic62", "Topic63",
                                    "Topic64", "Topic65", "Topic66"))

topic_dt_k0_2 <- topic_dt_k0 %>% filter(gender == "Female") %>% 
  group_by(assigned_topic, short_list) %>%
  summarise(count = n()) %>% group_by(short_list) %>%
  mutate(freq = count/sum(count)) %>% 
  ungroup() %>% select(assigned_topic, short_list, count) %>%
  spread(short_list, count) %>%
  rename("sl" = `TRUE`, "not_sl" = `FALSE`) %>%
  mutate(sl_freq = sl/sum(sl),
         not_sl_freq = not_sl/sum(not_sl, na.rm = TRUE),
         estimate = sl_freq - not_sl_freq,
         count = not_sl + sl,
         freq = count/sum(count, na.rm = TRUE))

plotcord_k0$assigned_topic <- paste0("Topic", plotcord_k0$topic)

plotcord_k0_2 <- plotcord_k0 %>% 
  inner_join(topic_dt_k0_2) %>% filter(!is.na(estimate))

# plotcord_k0_2 <- plotcord_k0 %>% 
#   left_join(topic_dt_k0_2) %>%
#   ungroup() %>%
#   select(X1, X2, topic, Estimate, type, count, freq) %>% 
#   tidyr::spread(type, Estimate) %>% 
#   mutate(genderFemale = Intercept + genderFemale,
#          Shortlist = genderFemale + Shortlist,
#          Estimate = genderFemale - Shortlist) %>%
#   tidyr::gather(gender, Estimate, -Intercept, -X1, -X2, -topic, -count, -freq,
#                 -Shortlist, -genderFemale)


p_network_k0 <- ggplot() + 
  geom_segment(aes(x=X1, y=Y1, xend = X2, yend = Y2),
               data=edges_k0, size = 0.5, colour="grey") +
  geom_point(data = plotcord_k0_2, aes(X1, X2, colour = estimate, size = freq)) + 
  geom_text(aes(X1, X2, label=topic), hjust = "center", vjust="top",
            size = 5, data = plotcord_k0_2) + 
  scale_colour_viridis(breaks = c(max(plotcord_k0_2$estimate),
                                  min(plotcord_k0_2$estimate)), 
                       labels = c("More AWS", "More non-AWS"),
                       name=NULL, option = "plasma",
                       end = 0.85, begin = 0.05) + 
  scale_size(guide = "none") + 
  theme_void() + 
  theme(legend.position = "bottom",
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),  
    axis.title.x = element_blank(), 
    axis.title.y = element_blank())

ggsave("p07_network_k0.svg", plot = p_network_k0, path="plots", device = "svg", width = 20, height = 20, units = "cm")

p_network_k0
```

The `stm` package includes the `estimateEffect` function, which creates a regression model (Table \ref{Topic Estimates}) using individual documents (speeches) as observations, with the proportion of a each document fitting each topic as the dependent variable and model covariates (AWS status and gender) as independent variables. The intercept in this model is all speeches by male Labour MPs.

```{r estimate-table-k0, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
library(knitr)
library(kableExtra)
library(dplyr)

row.names(prep_df_k0) <- NULL
prep_df_k0$type <- gsub("X.Intercept", "Intercept", prep_df_k0$type)
prep_df_k0$type <- gsub("short_listTRUE", "AWS", prep_df_k0$type)
prep_df_k0$type <- gsub("genderFemale", "Non-AWS", prep_df_k0$type)

prep_df_k0 <- prep_df_k0 %>% rename("p" = "Pr(>|t|)")

prep_df_k0$stars <- case_when(prep_df_k0$p < 0.001 ~ "***", 
                               prep_df_k0$p < 0.01 ~ "**",
                               prep_df_k0$p < 0.05 ~ "*", 
                               TRUE ~ "")

prep_df_k0_2 <- prep_df_k0 %>% select(type, Estimate,
                                        `Std. Error`, `t value`, p, stars) %>%
  mutate(p = pixiedust::pval_string(p,  digits = 4))

kable(prep_df_k0_2, booktabs = TRUE, longtable = TRUE, 
      caption = "Topic Estimates",
      col.names = c("", "Estimate", "Standard Error",
                    "t value", "Pr(>|t|)", ""),
      align = c("l","r","r","r","r", "l")) %>%
  kable_styling(latex_options = c("HOLD_position",  "repeat_header",
                                    "striped"), full_width = TRUE ) %>%
   group_rows(index = c("Topic 1 -- Employment & unions" = 3,
                        "Topic 2 -- Legal system" = 3,
                        "Topic 3 -- Roads" = 3,
                        "Topic 4 -- Housing" = 3,
                        "Topic 5 -- Police, firefighters & prison" = 3,
                        "Topic 6 -- Northern Ireland" = 3,
                        "Topic 7 -- Committee" = 3,
                        "Topic 8 -- Schools" = 3,
                        "Topic 9 -- Energy & climate change" = 3,
                        "Topic 10 -- Defence" = 3,
                        "Topic 11 -- Parliament" = 3,
                        "Topic 12 -- International politics" = 3,
                        "Topic 13 -- Ministers" = 3,
                        "Topic 14 -- Policy impact" = 3,
                        "Topic 15 -- Gender" = 3,
                        "Topic 16 -- Regional development" = 3,
                        "Topic 17 -- Communications" = 3,
                        "Topic 18 -- Immigration" = 3,
                        "Topic 19 -- Health system" = 3,
                        "Topic 20 -- International development" = 3,
                        "Topic 21 -- Benefits & disability" = 3,
                        "Topic 22 -- Sport & culture" = 3,
                        "Topic 23 -- History" = 3,
                        "Topic 24 -- Higher education & skills" = 3,
                        "Topic 25 -- Concurring point" = 3,
                        "Topic 26 -- Pensions" = 3,
                        "Topic 27 -- Points of order" = 3,
                        "Topic 28 -- Issues" = 3,
                        "Topic 29 -- Constituencies" = 3,
                        "Topic 30 -- Ethnic groups & racism" = 3,
                        "Topic 31 -- Amendments" = 3,
                        "Topic 32 -- Reports" = 3,
                        "Topic 33 -- People" = 3,
                        "Topic 34 -- Wales & Scotland" = 3,
                        "Topic 35 -- Alcohol & tobacco" = 3,
                        "Topic 36 -- Place names" = 3,
                        "Topic 37 -- Budget" = 3,
                        "Topic 38 -- Tax" = 3,
                        "Topic 39 -- Private companies" = 3,
                        "Topic 40 -- Environment & fishing" = 3,
                        "Topic 41 -- Crime" = 3,
                        "Topic 42 -- Bills" = 3,
                        "Topic 43 -- Children" = 3,
                        "Topic 44 -- Utilities & PFI" = 3,
                        "Topic 45 -- Middle East" = 3,
                        "Topic 46 -- Local authorities" = 3,
                        "Topic 47 -- Elections" = 3,
                        "Topic 48 -- Debate" = 3,
                        "Topic 49 -- Transport" = 3,
                        "Topic 50 -- Questions" = 3,
                        "Topic 51 -- Families" = 3,
                        "Topic 52 -- Health research" = 3,
                        "Topic 53 -- Dispatch box" = 3,
                        "Topic 54 -- Parties" = 3,
                        "Topic 55 -- Statements" = 3,
                        "Topic 56 -- European Union" = 3,
                        "Topic 57 -- Locations" = 3,
                        "Topic 58 -- Jobs & manufacturing" = 3,
                        "Topic 59 -- Small business" = 3,
                        "Topic 60 -- Agreement & disagreement" = 3,
                        "Topic 61 -- Voluntary sector" = 3,
                        "Topic 62 -- Comments" = 3,
                        "Topic 63 -- Social care" = 3,
                        "Topic 64 -- Time" = 3,
                        "Topic 65 -- Media & animals" = 3,
                        "Topic 66 -- Other" = 3))
```


```{r topic-dt3-creation-k0, include=FALSE}
topic_dt_k0_3 <- topic_dt_k0 %>%
  mutate(short_list_g = paste0(short_list, "_", gender)) %>%
  group_by(assigned_topic, short_list_g) %>%
  summarise(count = n()) %>%
  ungroup() %>%
  spread(key = "short_list_g", value = "count") %>%
   rename("AWS" = "TRUE_Female", "non_AWS" = "FALSE_Female",
          "man_count" = "FALSE_Male") %>%
   mutate(AWS_freq = AWS/sum(AWS, na.rm = TRUE),
          non_AWS_freq = non_AWS/sum(non_AWS, na.rm = TRUE),
          man_freq = man_count/sum(man_count, na.rm = TRUE),
          assigned_topic = gsub("Topic", "Topic ", assigned_topic)) %>%
   mutate(assigned_topic = factor(assigned_topic, levels=c(
                                    "Topic 1", "Topic 2", "Topic 3",
                                    "Topic 4", "Topic 5", "Topic 6",
                                    "Topic 7", "Topic 8", "Topic 9",
                                    "Topic 10", "Topic 11", "Topic 12",
                                    "Topic 13", "Topic 14", "Topic 15",
                                    "Topic 16", "Topic 17", "Topic 18",
                                    "Topic 19", "Topic 20", "Topic 21",
                                    "Topic 22", "Topic 23", "Topic 24",
                                    "Topic 25", "Topic 26", "Topic 27",
                                    "Topic 28", "Topic 29", "Topic 30",
                                    "Topic 31", "Topic 32", "Topic 33",
                                    "Topic 34", "Topic 35", "Topic 36",
                                    "Topic 37", "Topic 38", "Topic 39",
                                    "Topic 40", "Topic 41", "Topic 42",
                                    "Topic 43", "Topic 44", "Topic 45",
                                    "Topic 46", "Topic 47", "Topic 48",
                                    "Topic 49", "Topic 50", "Topic 51",
                                    "Topic 52", "Topic 53", "Topic 54",
                                    "Topic 55", "Topic 56", "Topic 57",
                                    "Topic 58", "Topic 59", "Topic 60",
                                    "Topic 61", "Topic 62", "Topic 63",
                                    "Topic 64", "Topic 65", "Topic 66")),
          assigned_topic = recode(assigned_topic, 
                          "Topic 1" = "(1) Employment & unions",
                          "Topic 2" = "(2) Legal system",
                          "Topic 3" = "(3) Roads",
                          "Topic 4" = "(4) Housing",
                          "Topic 5" = "(5) Police, firefighters & prison",
                          "Topic 6" = "(6) Northern Ireland",
                          "Topic 7" = "(7) Committee",
                          "Topic 8" = "(8) Schools",
                          "Topic 9" = "(9) Energy & climate change",
                          "Topic 10" = "(10) Defence",
                          "Topic 11" = "(11) Parliament",
                          "Topic 12" = "(12) International politics",
                          "Topic 13" = "(13) Ministers",
                          "Topic 14" = "(14) Policy impact",
                          "Topic 15" = "(15) Gender",
                          "Topic 16" = "(16) Regional development",
                          "Topic 17" = "(17) Communications",
                          "Topic 18" = "(18) Immigration",
                          "Topic 19" = "(19) Health system",
                          "Topic 20" = "(20) International development",
                          "Topic 21" = "(21) Benefits & disability",
                          "Topic 22" = "(22) Sport & culture",
                          "Topic 23" = "(23) History",
                          "Topic 24" = "(24) Higher education & skills",
                          "Topic 25" = "(25) Concurring point",
                          "Topic 26" = "(26) Pensions",
                          "Topic 27" = "(27) Points of order",
                          "Topic 28" = "(28) Issues",
                          "Topic 29" = "(29) Constituencies",
                          "Topic 30" = "(30) Ethnic groups & racism",
                          "Topic 31" = "(31) Amendments",
                          "Topic 32" = "(32) Reports",
                          "Topic 33" = "(33) People",
                          "Topic 34" = "(34) Wales & Scotland",
                          "Topic 35" = "(35) Alcohol & tobacco",
                          "Topic 36" = "(36) Place names",
                          "Topic 37" = "(37) Budget",
                          "Topic 38" = "(38) Tax",
                          "Topic 39" = "(39) Private companies",
                          "Topic 40" = "(40) Environment & fishing",
                          "Topic 41" = "(41) Crime",
                          "Topic 42" = "(42) Bills",
                          "Topic 43" = "(43) Children",
                          "Topic 44" = "(44) Utilities & PFI",
                          "Topic 45" = "(45) Middle East",
                          "Topic 46" = "(46) Local authorities",
                          "Topic 47" = "(47) Elections",
                          "Topic 48" = "(48) Debate",
                          "Topic 49" = "(49) Transport",
                          "Topic 50" = "(50) Questions",
                          "Topic 51" = "(51) Families",
                          "Topic 52" = "(52) Health research",
                          "Topic 53" = "(53) Dispatch box",
                          "Topic 54" = "(54) Parties",
                          "Topic 55" = "(55) Statements",
                          "Topic 56" = "(56) European Union",
                          "Topic 57" = "(57) Locations",
                          "Topic 58" = "(58) Jobs & manufacturing",
                          "Topic 59" = "(59) Small business",
                          "Topic 60" = "(60) Agreement & disagreement",
                          "Topic 61" = "(61) Voluntary sector",
                          "Topic 62" = "(62) Comments",
                          "Topic 63" = "(63) Social care",
                          "Topic 64" = "(64) Time",
                          "Topic 65" = "(65) Media & animals",
                          "Topic 66" = "(66) Other")) %>%
  arrange(assigned_topic)

topic_dt_k0_4 <- topic_dt_k0_3 %>%
    mutate(AWS_freq = paste0(formatC(round(AWS_freq*100, 2), 
            format = "f", digits = 2), "%"),
          non_AWS_freq = paste0(formatC(round(non_AWS_freq*100, 2), 
            format = "f", digits = 2), "%"),
          AWS = formatC(AWS, big.mark = ","),
          non_AWS = formatC(non_AWS, big.mark = ","),
          man_freq = paste0(formatC(
            round((man_freq*100), 2), 
            format = "f", digits = 2), "%"),
          man_count = formatC(man_count, big.mark = ",")) %>%
  select(assigned_topic, AWS, AWS_freq, non_AWS, non_AWS_freq, man_count, man_freq)

```

Table \ref{tab:count-distribution} shows the number and percentage of speeches assigned to each topic, based on its $\theta$ value. The results in this table differ slightly from those in Table \ref{Topic Estimates}, as it uses a "winner-take-all" method to assign a topic to each speech.

```{r topic-summary-table-k0, echo=FALSE, results = 'asis'}
library(knitr)
library(kableExtra)

kable(topic_dt_k0_4, booktabs = TRUE, longtable = TRUE, 
      caption = "Count and Distribution of Topics",
      col.names = c("Topic", "AWS Speeches", "Percent of AWS Speeches",
                    "Non-AWS Speeches", "Percent of non-AWS Speeches",
                    "Male MP Speeches", "Percent of Male MP Speeches"),
      align = c("l","r","r","r","r","r","r")) %>%
    kable_styling(latex_options = c("HOLD_position",  "repeat_header",
                                    "striped"), full_width = TRUE ) %>%
  column_spec(1, width = "5cm")
```


### Topic Graphs

The estimate effects in these graphs were extracted using the `tidystm` package by Mikael Poul Johannesson. Figure \ref{k0-topic-dot-plot} highlights nine topics with different expected proportions between male, AWS and non-AWS Labour MPs. See Figure \ref{k0-topic-bar-plot} for a graph of all 66 topics.

```{r tidystm-graphs, echo=FALSE, fig.cap="\\label{k0-topic-selected-bar-plot}Selected Topic Proportions", message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
effect <- read_rds("data/effect.rds")

p_k0_sel_bar <- ggplot(filter(effect,
                           topic %in% c(27, 2, 21, 63, 60, 54, 29, 30, 38)),
aes(y = estimate, x = as.factor(label),
                   group = covariate.value, fill = covariate.value)) + 
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_errorbar(aes(ymin = ci.lower, ymax = ci.upper), 
                color = "black", width = 0.3, position=position_dodge(.9)) + 
   scale_y_continuous(labels = scales::percent) + 
  scale_fill_manual(values = c("#a06dba", "#7aa457", "#cb6a49"),
                    labels = c( "Men", "Non-AWS", "AWS"),
                    name = "") + 
  labs(x = "Topic",
       y = "Expected Topic Proportion") +
  theme(legend.position = "bottom")

ggsave("p08_k0_sel_bar.svg", plot = p_k0_sel_bar,
       path="plots", device = "svg", width = 20, height = 20, units = "cm")

p_k0_sel_bar
```

```{r k0-topic-bar, echo=FALSE, fig.cap="\\label{k0-topic-bar-plot}All Topic Proportions", message=FALSE, warning=FALSE}
p_k0_bar <- ggplot(effect, aes(y = estimate, x = as.factor(topic),
                   group = covariate.value, fill = covariate.value)) + 
  geom_bar(stat = "identity", position=position_dodge()) +
  geom_errorbar(aes(ymin = ci.lower, ymax = ci.upper), 
                color = "black", width = 0.3, position=position_dodge(.9)) + 
   scale_y_continuous(labels = scales::percent) + 
  scale_fill_manual(values = c("#a06dba", "#7aa457", "#cb6a49"),
                    labels = c( "Men", "Non-AWS", "AWS"),
                    name = "") + 
  labs(x = "Topic",
       y = "Expected Topic Proportion") +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90, hjust = 1.1, vjust = 0.5))

ggsave("p09_k0_bar.svg", plot = p_k0_bar,
       path="plots", device = "svg", width = 20, height = 20, units = "cm")

p_k0_bar
```



```{r stm-topic-words-k0, message=FALSE, warning=FALSE, include=FALSE}
library(tidyr)
topic_words <- labelTopics(topic_model_k0, n = 20, frexweight = 0.5)

topic_words_highest <- tibble::as_tibble(topic_words[[1]])

topic_words_highest <- topic_words_highest %>% unite(V1:V20, sep = ", ") %>%
  rename("highest" = "V1:V20")

topic_words_highest$topic <- paste0("Topic ", row.names(topic_words_highest))

topic_words_frex <- tibble::as_tibble(topic_words[[2]])

topic_words_frex <- topic_words_frex %>% unite(V1:V20, sep = ", ") %>%
  rename("FREX" = "V1:V20")

topic_words_frex$topic <- paste0("Topic ", row.names(topic_words_frex))

topic_words2 <- topic_words_highest %>% left_join(topic_words_frex) %>% 
  select(topic, everything()) %>%
  mutate(topic = recode(topic, 
                         "Topic 1" = "(1) Employment & unions",
                          "Topic 2" = "(2) Legal system",
                          "Topic 3" = "(3) Roads",
                          "Topic 4" = "(4) Housing",
                          "Topic 5" = "(5) Police, firefighters & prison",
                          "Topic 6" = "(6) Northern Ireland",
                          "Topic 7" = "(7) Committee",
                          "Topic 8" = "(8) Schools",
                          "Topic 9" = "(9) Energy & climate change",
                          "Topic 10" = "(10) Defence",
                          "Topic 11" = "(11) Parliament",
                          "Topic 12" = "(12) International politics",
                          "Topic 13" = "(13) Ministers",
                          "Topic 14" = "(14) Policy impact",
                          "Topic 15" = "(15) Gender",
                          "Topic 16" = "(16) Regional development",
                          "Topic 17" = "(17) Communications",
                          "Topic 18" = "(18) Immigration",
                          "Topic 19" = "(19) Health system",
                          "Topic 20" = "(20) International development",
                          "Topic 21" = "(21) Benefits & disability",
                          "Topic 22" = "(22) Sport & culture",
                          "Topic 23" = "(23) History",
                          "Topic 24" = "(24) Higher education & skills",
                          "Topic 25" = "(25) Concurring point",
                          "Topic 26" = "(26) Pensions",
                          "Topic 27" = "(27) Points of order",
                          "Topic 28" = "(28) Issues",
                          "Topic 29" = "(29) Constituencies",
                          "Topic 30" = "(30) Ethnic groups & racism",
                          "Topic 31" = "(31) Amendments",
                          "Topic 32" = "(32) Reports",
                          "Topic 33" = "(33) People",
                          "Topic 34" = "(34) Wales & Scotland",
                          "Topic 35" = "(35) Alcohol & tobacco",
                          "Topic 36" = "(36) Place names",
                          "Topic 37" = "(37) Budget",
                          "Topic 38" = "(38) Tax",
                          "Topic 39" = "(39) Private companies",
                          "Topic 40" = "(40) Environment & fishing",
                          "Topic 41" = "(41) Crime",
                          "Topic 42" = "(42) Bills",
                          "Topic 43" = "(43) Children",
                          "Topic 44" = "(44) Utilities & PFI",
                          "Topic 45" = "(45) Middle East",
                          "Topic 46" = "(46) Local authorities",
                          "Topic 47" = "(47) Elections",
                          "Topic 48" = "(48) Debate",
                          "Topic 49" = "(49) Transport",
                          "Topic 50" = "(50) Questions",
                          "Topic 51" = "(51) Families",
                          "Topic 52" = "(52) Health research",
                          "Topic 53" = "(53) Dispatch box",
                          "Topic 54" = "(54) Parties",
                          "Topic 55" = "(55) Statements",
                          "Topic 56" = "(56) European Union",
                          "Topic 57" = "(57) Locations",
                          "Topic 58" = "(58) Jobs & manufacturing",
                          "Topic 59" = "(59) Small business",
                          "Topic 60" = "(60) Agreement & disagreement",
                          "Topic 61" = "(61) Voluntary sector",
                          "Topic 62" = "(62) Comments",
                          "Topic 63" = "(63) Social care",
                          "Topic 64" = "(64) Time",
                          "Topic 65" = "(65) Media & animals",
                          "Topic 66" = "(66) Other"))
```


### Word Occurences

The table below shows the twenty most common words in each topic, and the twenty words with the highest FREX score, a measure that uses a harmonic mean of word exclusivity and topic coherence  [@airoldi2016]. We have named each topic based on the most common words and highest FREX score words in each topic.

```{r topic-words-table-k0, echo=FALSE, results = 'asis'}
library(knitr)
library(kableExtra)

kable(topic_words2,  booktabs = TRUE, longtable = TRUE, 
      caption = "Words in topic - k0",
      col.names = c("Topic Number", "Top Twenty Words", "Top Twenty FREX")) %>%
    kable_styling(latex_options = c("HOLD_position",  "repeat_header",
                                    "striped"), full_width = TRUE ) %>% 
  column_spec(2:3, width = "6cm")

```


### Manual Validation

As STM is an unsupervised model, we used several different validation strategies to ensure the topics themselves are both interesting and relevant [@grimmer2013]. @quinn2010 suggest that topics are valid if they correspond to external events. Figure \ref{Middle East-plot-validity} shows the number of speeches by Labour MPs on the "Middle East" topic, with a spike in 2003 (at the start of the Iraq War), another spike in 2008 and 2009, as the bulk of British troops left Iraq, a small spike in 2011 coinciding with UK participation in NATO's military intervention in Libya, and debate in 2014--2016 over UK participation in military interventions in the Syrian Civil War. 

Figure \ref{wales-scotland-validity} shows debate over the devolved authorities of Wales and Scotland peaking in 2014, to coincide with Scotland's independence referendum. The post-2015 decline also likely stems from the SNP winning all but three seats in Scotland during the 2015 General Election. Figure \ref{eu-validity} shows the increase in debate over the European Union coinciding with the referendum on the UK's member of the European Union.

```{r validation-prep, include=FALSE}
library(lubridate)
library(ggplot2)

head(topic_dt_k0)

topic_dt_k0_valid <- topic_dt_k0 %>% 
  group_by(assigned_topic, year) %>%
  summarise(count = n())

test10 <- topic_dt_k0_valid %>% filter(assigned_topic == "Topic10")

plot10 <- ggplot(aes(x=year, y = count), data = test10) +
  geom_line() + 
  labs(x = "Year", y = "Number of Speeches")

plot10

```


```{r middle-east-plot, echo=FALSE,fig.cap="\\label{Middle East-plot-validity}Number of Speeches in \"Middle East\" Topic per Year"}
test45 <- topic_dt_k0_valid %>% filter(assigned_topic == "Topic45")

plot45 <- ggplot(aes(x=year, y = count), data = test45) +
  geom_line() + 
  labs(x = "Year", y = "Number of Speeches")

plot45

ggsave("p10_plot45.svg", plot = plot45,
       path="plots", device = "svg", width = 20, height = 20, units = "cm")

```

```{r wales-scotland-plot, echo=FALSE,fig.cap="\\label{wales-scotland-validity}Number of Speeches in \"Wales & Scotland\" Topic per Year"}
test34 <- topic_dt_k0_valid %>% filter(assigned_topic == "Topic34")

plot34 <- ggplot(aes(x=year, y = count), data = test34) +
  geom_line() + 
  labs(x = "Year", y = "Number of Speeches")

plot34

ggsave("p11_plot34.svg", plot = plot34,
       path="plots", device = "svg", width = 20, height = 20, units = "cm")
```



```{r eu-plot, echo=FALSE,fig.cap="\\label{eu-validity}Number of Speeches in \"European Union\" Topic per Year"}

test56 <- topic_dt_k0_valid %>% filter(assigned_topic == "Topic56")

plot56 <- ggplot(aes(x=year, y = count), data = test56) +
  geom_line() + 
  labs(x = "Year", y = "Number of Speeches")

plot56

ggsave("p12_plot56.svg", plot = plot56,
       path="plots", device = "svg", width = 20, height = 20, units = "cm")

```


# Discussion

There do not appear to be substantial or meaningful differences in the speaking styles of female Labour MPs selected through all women shortlists when compared to their female colleagues selected through open shortlists using LIWC. This is possibly due to the speaking style dominant in British parliamentary debate, which is more formal than the speech used in most day-to-day conversation. LIWC was developed by American researchers, and the LIWC dictionary may not be able to capture stylistic differences between American and British English, and may not include words commonly used in formal British English speech, limiting its usefulness in the context of British political debate.

There is more gender distinction in some selected terms and topics. AWS MPs are far more likely to make reference to their constituency and their constituents. In the debate between whether MPs should be "delegates" or "trustees" -- the "mandate-independence controversy" outlined by @pitkin1967 -- the references to their constituents and constituencies suggests AWS MPs shy away from the Burkean concept of trusteeship and see themselves more as strict representatives of their constituents. In Andeweg & Thomassen's [-@andeweg2005] typology of _ex ante_/_ex post_ and above/below political representation, AWS MPs lean towards representation "from below", although their selection process is _ex ante_/_ex post_.

AWS MPs refer to their constituents both specifically and in the abstract, particularly when criticising government policy. For example, in debate on 4th March 2015, Gemma Doyle, than the Labour MP for West Dunbartonshire (elected on an AWS in 2010), when asked if she would give way to Conservative MP Stephen Mosley, responded:

>No, I will not [give way], because my constituents want me to make these points, not to give more time to Conservative Members.

On 2nd June 2010, during debate on Israel-Palestine, Valerie Vaz, MP for Walsall South:

>My constituents want more than pressure. Will the Foreign Secretary come back to the House and report on a timetable for the discussions on a diplomatic solution, just as we did on Ireland?

On 4th April 2001, Betty Williams, member for Conwy from 1997--2010, raised the case of a wilderness guide in her constituency unable to access parts of the countryside due to foot and mouth disease:

>Is my right hon. Friend aware that there is continuing concern about the limited access to the countryside and crags of north Wales? May I draw his attention to the circumstances of my constituent, Ric Potter? Like many others, he has had to travel to Scotland, where there is greater access. Will my right hon. Friend help us to enable people such as Ric Potter to find work in outdoor pursuits?

\clearpage


# Appendix

## Gender effect estimates

Estimate effects of different topics, using only gender.

```{r estimate-table-gender, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
library(knitr)
library(kableExtra)
library(dplyr)

prep_k0_gender <- read_rds("data/prep_k0_gender.rds")

prep_df_k0_gender <- summary(prep_k0_gender)[[3]]

prep_df_k0_gender <- as.data.frame(do.call(rbind, prep_df_k0_gender))

prep_df_k0_gender$topic <- NA

prep_df_k0_gender$topic <- rep(1:66, each = 2)

prep_df_k0_gender$type <- row.names(prep_df_k0_gender)

prep_df_k0_gender$type <- gsub("\\.[0-9][0-9]", "", prep_df_k0_gender$type)

prep_df_k0_gender$type <- gsub("\\.[0-9]", "", prep_df_k0_gender$type)

prep_df_k0_gender$type <- gsub("\\.$", "", prep_df_k0_gender$type)


row.names(prep_df_k0_gender) <- NULL
prep_df_k0_gender$type <- gsub("X.Intercept", "Intercept", prep_df_k0_gender$type)
prep_df_k0_gender$type <- gsub("genderFemale", "Female", prep_df_k0_gender$type)

prep_df_k0_gender <- prep_df_k0_gender %>% rename(
  "p" = "Pr(>|t|)"
)

prep_df_k0_gender$stars <- case_when(prep_df_k0_gender$p < 0.001 ~ "***", 
                              prep_df_k0_gender$p < 0.01 ~ "**",
                              prep_df_k0_gender$p < 0.05 ~ "*", 
                              TRUE ~ "")

prep_df_k0_gender_2 <- prep_df_k0_gender %>% select(type, Estimate,
                                      `Std. Error`, `t value`, p, stars) %>%
  mutate(p = pixiedust::pval_string(p,  digits = 4))


kable(prep_df_k0_gender_2, booktabs = TRUE, longtable = TRUE, 
      caption = "Topic Estimates",
      col.names = c("", "Estimate", "Standard Error",
                    "t value", "Pr(>|t|)", ""),
      align = c("l","r","r","r","r", "l")) %>%
  kable_styling(latex_options = c("HOLD_position",  "repeat_header",
                                    "striped"), full_width = TRUE ) %>%
   group_rows(index = c("Topic 1 -- Employment & unions" = 2,
                        "Topic 2 -- Legal system" = 2,
                        "Topic 3 -- Roads" = 2,
                        "Topic 4 -- Housing" = 2,
                        "Topic 5 -- Police, firefighters & prison" = 2,
                        "Topic 6 -- Northern Ireland" = 2,
                        "Topic 7 -- Committee" = 2,
                        "Topic 8 -- Schools" = 2,
                        "Topic 9 -- Energy & climate change" = 2,
                        "Topic 10 -- Defence" = 2,
                        "Topic 11 -- Parliament" = 2,
                        "Topic 12 -- International politics" = 2,
                        "Topic 13 -- Ministers" = 2,
                        "Topic 14 -- Policy impact" = 2,
                        "Topic 15 -- Gender" = 2,
                        "Topic 16 -- Regional development" = 2,
                        "Topic 17 -- Communications" = 2,
                        "Topic 18 -- Immigration" = 2,
                        "Topic 19 -- Health system" = 2,
                        "Topic 20 -- International development" = 2,
                        "Topic 21 -- Benefits & disability" = 2,
                        "Topic 22 -- Sport & culture" = 2,
                        "Topic 23 -- History" = 2,
                        "Topic 24 -- Higher education & skills" = 2,
                        "Topic 25 -- Concurring point" = 2,
                        "Topic 26 -- Pensions" = 2,
                        "Topic 27 -- Points of order" = 2,
                        "Topic 28 -- Issues" = 2,
                        "Topic 29 -- Constituencies" = 2,
                        "Topic 30 -- Ethnic groups & racism" = 2,
                        "Topic 31 -- Amendments" = 2,
                        "Topic 32 -- Reports" = 2,
                        "Topic 33 -- People" = 2,
                        "Topic 34 -- Wales & Scotland" = 2,
                        "Topic 35 -- Alcohol & tobacco" = 2,
                        "Topic 36 -- Place names" = 2,
                        "Topic 37 -- Budget" = 2,
                        "Topic 38 -- Tax" = 2,
                        "Topic 39 -- Private companies" = 2,
                        "Topic 40 -- Environment & fishing" = 2,
                        "Topic 41 -- Crime" = 2,
                        "Topic 42 -- Bills" = 2,
                        "Topic 43 -- Children" = 2,
                        "Topic 44 -- Utilities & PFI" = 2,
                        "Topic 45 -- Middle East" = 2,
                        "Topic 46 -- Local authorities" = 2,
                        "Topic 47 -- Elections" = 2,
                        "Topic 48 -- Debate" = 2,
                        "Topic 49 -- Transport" = 2,
                        "Topic 50 -- Questions" = 2,
                        "Topic 51 -- Families" = 2,
                        "Topic 52 -- Health research" = 2,
                        "Topic 53 -- Dispatch box" = 2,
                        "Topic 54 -- Parties" = 2,
                        "Topic 55 -- Statements" = 2,
                        "Topic 56 -- European Union" = 2,
                        "Topic 57 -- Locations" = 2,
                        "Topic 58 -- Jobs & manufacturing" = 2,
                        "Topic 59 -- Small business" = 2,
                        "Topic 60 -- Agreement & disagreement" = 2,
                        "Topic 61 -- Voluntary sector" = 2,
                        "Topic 62 -- Comments" = 2,
                        "Topic 63 -- Social care" = 2,
                        "Topic 64 -- Time" = 2,
                        "Topic 65 -- Media & animals" = 2,
                        "Topic 66 -- Other" = 2))
```


## $\theta$ distribution

```{r theta-boxplot, echo=FALSE, fig.height=7, fig.cap="\\label{k0-theta-boxplot}k0 Theta Values in Topic Assignment"}
library(ggplot2)

p_theta <- ggplot(data = topic_dt_k0, aes(assigned_topic, theta)) + 
  geom_boxplot() + 
  scale_x_discrete(labels = c(1:65)) + 
  labs(x = "Assigned Topic",
       y = "Theta")
  
p_theta
```



## AWS References to Constituents in Context

A random selection of 2% of all references to "my constituency", "my constituent" and "my constituents", by AWS MPs, in context. 

```{r constituent-kwic, echo=FALSE, message=FALSE}
library(quanteda)
library(readr)
library(stringi)
library(dplyr)
library(knitr)
library(kableExtra)

## Get this working to remove needless characters

lab_speech <- read_rds("data/lab_speech.rds")

lab_speech$speech <- stri_replace_all_fixed(lab_speech$speech, "\n", " ")

lab_speech$speech <- stri_replace_all_regex(lab_speech$speech, "\\ n\\s", " ")

lab_speech$speech <- stri_replace_all_regex(lab_speech$speech, "\ n\\s", " ")

#head(lab_speech$speech)

lab_fem_sl <- lab_speech %>% 
  filter(gender == "Female" & short_list == TRUE)

set.seed(191)
constit_kwic <- kwic(lab_fem_sl$speech, phrase("my constit*"),
                     window = 10, valuetype = "glob", remove_punct = FALSE) %>% 
  tibble::as_tibble() %>% 
  select(pre:post) %>% 
  sample_frac(0.02) 

constit_kwic$pre <- stri_replace_all_fixed(constit_kwic$pre, " \\ n ", " ")

constit_kwic$post <- stri_replace_all_fixed(constit_kwic$post, " \\ n ", " ")

constit_kwic$post <- stri_replace_all_regex(constit_kwic$post, "^\\\\ n ", " ")

constit_kwic$post <- stri_replace_all_regex(constit_kwic$post, " \\\\ n$", " ")

constit_kwic$post <- stri_replace_all_regex(constit_kwic$post, "^n ", "")

constit_kwic$post <- stri_replace_all_regex(constit_kwic$post, " \\\"", " ")

constit_kwic$post <- stri_replace_all_regex(constit_kwic$post, " ([:punct:])", "$1")

constit_kwic$pre <- stri_replace_all_fixed(constit_kwic$pre, " \\ n ", " ")

constit_kwic$pre <- stri_replace_all_regex(constit_kwic$pre, "^\\\\ n ", " ")

constit_kwic$pre <- stri_replace_all_regex(constit_kwic$pre, " \\\\ n$", " ")

constit_kwic$pre <- stri_replace_all_regex(constit_kwic$pre, "^n ", "")

constit_kwic$pre <- stri_replace_all_regex(constit_kwic$pre, " \\\"", " ")

constit_kwic$pre <- stri_replace_all_regex(constit_kwic$pre, " ([:punct:])", "$1")

kable(constit_kwic,  booktabs = TRUE, longtable = TRUE, 
      col.names = c("Pre", "Keyword", "Post"),
      caption = "A random sample of KWIC's", row.names = FALSE) %>%
    kable_styling(latex_options = c("HOLD_position",  "repeat_header",
                                    "striped"), full_width = TRUE )
```

# References

[^1]: e.g. a reference to "the member for Bethnal Green and Bow" in keeping with Parliamentary convention of identifying MPs by their seat rather than their name would be followed by "(Rushnara Ali)".
