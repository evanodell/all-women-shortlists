---
title: "All Women Short lists Methodology"
editor_options:
  chunk_output_type: console
link-citations: yes
output:
  pdf_document: default
  html_notebook: default
  word_document: default
  html_document:
    df_print: paged
bibliography: women.bib
---

# Methodology

Previous research on gender differences in political speech patterns has focused on differences between male and female politicians [@yu2014] or on variations in Hilary Clinton's speech patterns [@jones2016; @bligh2010].

To account for the possible effects of age, parliamentary experience and cohort, and in order to compare women selected through all women short lists to women who were not (but theoretically had the possibility to contest all-women short lists), speech analysis has been restricted only to Labour MPs elected during or after the 1997 General Election, and before the 2017 General Election. Words contained in parentheses were removed, as they are added by Hansard to provide additional information not actually spoken by the MP.[^1] Speeches and MP data is from a previously assembled dataset [@odell2018]. Information on candidates selected through all women short lists is from the House of Commons Library [@kelly2016]. Unsuccessful General Election candidates selected through all women short lists who were subsequently elected in a byelection are classified as having been selected on an all women short list. 

Word classification used the `Linguistic Inquiry and Word Count 2015` (LIWC) dictionary [@pennebaker2015] and tokenising tools from the `Quanteda` R package [@benoit2018]. Word counts and words-per-sentence were calculated using `stringi` [@gagolewski2018], a wrapper to the ICU regex library.

Following Yu [-@yu2014] drawing on [@newman2008] we used the following LIWC categories:

<!-- Feminine: -->
* All Pronouns (pronoun)
* First person singular pronouns (i) 
* Verbs (verb)
* Auxiliary verbs (auxverb) 
* Social processes (social) 
* Positive emotions (posemo) 
* Negative emotions (negemo) 
* Tentative words (tentat)
<!-- Masculine: -->
* Words longer than six letters (Sixltr)
* First person plural pronouns (we)
* Articles (article) 
* Prepositions (preps) 
* Anger words (anger)
* Swear words (swear)
* Cognitive processes (cogproc)

We also included words-per-sentence (WPS), total word count (WC) and Fleschâ€“Kincaid grade level (FK) [@kincaid1975], calculated using `Quanteda` [@benoit2018] and `stringi` [@gagolewski2018].

<!--## Corpus creation -->

```{r Extracing-post-1997-Labour-speeches, eval=FALSE, include=FALSE}
### Extracing post-1997 Labour speeches
library(readr)
library(dplyr)
library(quanteda)
library(readxl)
library(lubridate)
library(stringi)

all_speech <- read_rds("senti_df2.rds")

all_speech$eo_id <- rownames(all_speech)

## Binned into quarters of a year
all_speech$y_since_start <- round(time_length(all_speech$speech_date -
                                          as.Date(all_speech$house_start_date),
                                        unit = "years")* 4)/4

lab_speech <- filter(all_speech, party_group=="Labour", 
                     house_start_date >= "1997-05-01",
                     speech_date >= "1997-05-01", 
                     speech_date < "2017-06-08", word_count > 0)

rm(all_speech)

all_women97_15 <- read_excel("list-of-mps.xlsx")

lab_speech$short_list <- lab_speech$mnis_id %in% all_women97_15$mnis

lab_speech$speech <- stri_replace_all_regex(lab_speech$speech, "\\s\\(.*?\\)",
                                            "", vectorize_all = TRUE)

write_rds(lab_speech, "lab_speech.rds")

lab_corpus <- corpus(lab_speech, docid_field = "eo_id", text_field = "speech")

write_rds(lab_corpus, "lab_corpus.rds")
```

<!--### Descriptive Statistics -->

```{r eval=FALSE, include=FALSE}
elections <- as.POSIXct(c("1997-05-01", "2001-06-07", "2005-05-05", 
               "2010-05-06", "2015-05-07", "2017-06-07"), tz = "UTC")

labour_intakes <- lab_speech %>% 
  filter(house_start_date %in% elections) %>% 
  group_by(house_start_date, mnis_id) %>% 
  summarise() %>% 
  group_by(house_start_date) %>% 
  summarise(total=n()) 

labour_intakes_women <- lab_speech %>% 
  filter(house_start_date %in% elections, gender=="Female") %>% 
  group_by(house_start_date, mnis_id) %>% 
  summarise() %>% 
  group_by(house_start_date) %>% 
  summarise(women=n()) 

labour_intakes <- labour_intakes %>%  left_join(labour_intakes_women)
labour_intakes$perc_women <- (labour_intakes$women/labour_intakes$total)*100

```


| General Election | Total MPs | Total Labour MPs | Total Female Labour MPs | Percentage Women MPs | Newly elected MPs | Intake Women | Percentage Intake Women | Intake Short list | Nominated Short list |
|------------------|-----------|------------------|-------------------------|----------------------|-------------------|--------------|-------------------------|-------------------|----------------------|
| 1997 | 659 | 418 | 101 | 24.2% | 177 | 64 | 36% | 35 | 38 |
| 2001 | 659 | 412 | 95 | 23.1% | 38 | 4 | 11% | 0 | 0 |
| 2005 | 646 | 355 | 98 | 27.6% | 40 | 26 | 65% | 23 | 30 |
| 2010 | 650 | 258 | 81 | 31.4% | 64 | 32 | 50% | 28 | 63 |
| 2015 | 650 | 232 | 99 | 42.7% | 49 | 31 | 63% | 31 | 77 |



Data in this table is from House of Commons library reports [@kelly2016; @audickas2017]. All women short lists were not used by Labour during the 2001 General Election.

<!--## LIWC creation-->

```{r women-v-men, eval=FALSE, include=FALSE}
#remotes::install_github("kbenoit/quanteda.dictionaries")
library(quanteda.dictionaries)
library(purrr)
library(tidyr)
library(effsize)

liwc15_dict <- dictionary(file = "dict/LIWC2015_English_Flat.dic",
       format = "LIWC")

lab_liwc <- liwcalike(lab_corpus, 
      dictionary = liwc15_dict, 
      verbose = TRUE) %>%
 left_join(lab_speech, by = c("docname" = "eo_id"))

lab_liwc[["Sixltr"]] <- sapply(
  tokens(texts(lab_corpus), remove_hyphens = TRUE),
  function(y) sum(stri_length(y) > 6)) / lab_liwc[["WC"]] * 100

lab_liwc$WC <- stri_count_boundaries(lab_liwc$speech,
                                       type="word", skip_word_none=FALSE)

# lab_liwc$FK <-  textstat_readability(texts(lab_corpus), "Flesch.Kincaid")
# 
# lab_liwc$FK <- lab_liwc$FK$Flesch.Kincaid
# 
# lab_liwc$FK <- if_else(lab_liwc$WC < 5, NA_real_, lab_liwc$FK)

lab_liwc$WPS <- lab_liwc$WC/stri_count_boundaries(lab_liwc$speech,
                                       type="sentence", skip_word_none=FALSE)

lab_liwc$FK <- case_when(lab_liwc$WC >= 5 ~ 
                            0.39 * lab_liwc$WPS + 
                            11.8 * quanteda::nsyllable(lab_liwc$speech)/
                            lab_liwc$WC - 15.59, TRUE ~ NA_real_)

#lab_liwc$FK2 <- if_else(lab_liwc$WC < 5, NA_real_, lab_liwc$FK2)

lab_liwc <- lab_liwc %>% select(docname, Segment, WC, WPS, FK, everything())

#lab_liwc <- read_rds("lab_liwc.rds")

write_rds(lab_liwc, "lab_liwc.rds")
```


## Women vs Men

```{r liwc-women-men, include=FALSE}
library(readr)
library(dplyr)
library(purrr)
library(tidyr)
library(effsize)

lab_liwc <- read_rds("lab_liwc.rds")

## Group by gender, short_list, see what's up
cols <- names(lab_liwc)[4:92]

lab_liwc_men_women_mean <- list(c("WC"), cols) %>%
 map2(lst(mean=mean, funs(weighted.mean(., WC))),
  ~ lab_liwc %>%
   group_by(gender) %>%
   summarise_at(.x, .y)) %>%
 reduce(inner_join)

#tibble::glimpse(lab_liwc_men_women_mean)

lab_liwc_men_women_tidy_mean <- gather(lab_liwc_men_women_mean, 
          "attribute", "weighted_mean", -gender, -WC) 

lab_liwc_men_women_sd <- list(c("WC"), cols) %>%
 map2(lst(mean=mean, funs(sd(., na.rm=TRUE))),
  ~ lab_liwc %>%
   group_by(gender) %>%
   summarise_at(.x, .y)) %>%
 reduce(inner_join)

lab_liwc_men_women_tidy_sd <- gather(lab_liwc_men_women_sd, "attribute",
                                     "sd", -gender, -WC) 

## Joining together the SD and Means to get CIs

## Calculate Cohen's D in here somehow?
lab_liwc_men_women2 <- left_join(lab_liwc_men_women_tidy_mean, 
         lab_liwc_men_women_tidy_sd) %>% 
 left_join(lab_liwc %>% 
    group_by(gender) %>% summarise(n=n())) %>%
 mutate(se = sd / sqrt(n),
   lower_ci = weighted_mean - qt(1 - (0.05 / 2), n - 1) * se,
   upper_ci = weighted_mean + qt(1 - (0.05 / 2), n - 1) * se)

rm(lab_liwc_men_women_tidy_sd, lab_liwc_men_women_tidy_mean)

fem_mac <- c("pronoun", "i", "we", "verb", "auxverb", "social", "posemo", 
             "negemo", "tentat", "Sixltr",  "article", "prep",
             "anger", "swear", "cogproc", "WPS", "WC", "FK")

lab_liwc_men_women2_subset <- lab_liwc_men_women2 %>%
  filter(attribute %in% fem_mac)

fem_mac_df <- tibble::tibble(
  word_type = fem_mac,
  women = c(1:length(fem_mac)),
  women_sd = c(1:length(fem_mac)),
  men = c(1:length(fem_mac)),
  men_sd = c(1:length(fem_mac)),
  cohen_d = c(1:length(fem_mac)),
  magnitude = c(1:length(fem_mac)))

for (i in fem_mac) {
  d <- (cohen.d(lab_liwc[[i]], lab_liwc$gender, na.rm = TRUE,
                noncentral = FALSE, pooled = TRUE))
  fem_mac_df$women[fem_mac_df$word_type==i] <- mean(lab_liwc[lab_liwc$gender == "Female", i], na.rm = TRUE)
  fem_mac_df$men[fem_mac_df$word_type==i] <- mean(lab_liwc[lab_liwc$gender == "Male", i], na.rm = TRUE)
  fem_mac_df$women_sd[fem_mac_df$word_type==i] <- sd(lab_liwc[lab_liwc$gender == "Female", i], na.rm = TRUE)
  fem_mac_df$men_sd[fem_mac_df$word_type==i] <- sd(lab_liwc[lab_liwc$gender == "Male", i], na.rm = TRUE)
  fem_mac_df$cohen_d[fem_mac_df$word_type==i] <- (d$estimate[[1]])
  fem_mac_df$magnitude[fem_mac_df$word_type==i] <- as.character(d$magnitude[[1]])
}

#fem_mac_df

fem_mac_df$word_type <- recode(fem_mac_df$word_type,
               "pronoun" = "All Pronouns",
               "i" = "First person singular pronouns",
               "verb" = "Verbs",
               "auxverb" = "Auxiliary verbs",
               "social" = "Social processes ",
               "posemo" = "Positive emotions",
               "negemo" = "Negative emotions",
               "tentat" = "Tentative words",
               "Sixltr" = "More than six letters",
               "we" = "First person plural pronouns",
               "article" = "Articles",
               "prep" = "Prepositions",
               "anger" = "Anger words",
               "swear" = "Swear words",
               "cogproc" = "Cognitive processes",
               "WPS" = "Words per Sentence",
               "WC" = "Total Word Count",
               "FK" = "Flesh-Kincaid Grade Level")

```

```{r gender-effect-sizes-table, echo=FALSE, results = 'asis'}
library(knitr)
library(kableExtra)
kable(fem_mac_df, digits = 2, 
      caption = "Effect Sizes for Male and Female Labour MPs",
      col.names = c("", "Mean", "SD", "Mean", "SD",
                    "Cohen's D", "Magnitude") )  %>%
  kable_styling(latex_options = "striped") %>% 
  add_header_above(c(" " = 1, "Women" = 2, "Men" = 2, "Effect Size" = 2))
```

There are no categories where gender differences meet the effect size threshold of $|0.2|$ suggested by Cohen [-@cohen1988, 25--26] to indicate a small effect. 4 categories -- words with more than six letters, prepositions, words-per-sentence and Flesh-Kincaid grade level -- exceeded the $|0.1|$ threshold suggested by Newman et al [-@newman2008].


## Short lists vs Non-Short lists

```{r liwc-short lists, include=FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(purrr)
library(effsize)

lab_liwc <- read_rds("lab_liwc.rds")

lab_liwc_women <- filter(lab_liwc, gender=="Female",
                         house_start_date >= "1997-05-01")

## Group by gender, short_lsit, see what's up
cols <- names(lab_liwc_women)[4:92]

lab_liwc_women_mean <- list(c("WC"), cols) %>%
 map2(lst(mean=mean, funs(weighted.mean(., WC, na.rm=TRUE))),
  ~ lab_liwc_women %>%
   group_by(short_list, y_since_start) %>%
   summarise_at(.x, .y)) %>%
 reduce(inner_join)

lab_liwc_women_tidy_mean <- gather(lab_liwc_women_mean, "attribute",
                                   "weighted_mean", -short_list,
                                   -y_since_start) 

lab_liwc_women_sd <- list(c("WC"), cols) %>%
 map2(lst(mean=mean, funs(sd(., na.rm=TRUE))),
  ~ lab_liwc_women %>%
   group_by(gender, short_list, y_since_start) %>%
   summarise_at(.x, .y)) %>%
 reduce(inner_join)

lab_liwc_women_tidy_sd <- gather(lab_liwc_women_sd, "attribute",
                                 "sd", -short_list, -gender,
                                 -y_since_start) 

## Joining together the SD and Means to get CIs
lab_liwc_women2 <- left_join(lab_liwc_women_tidy_mean,
                             lab_liwc_women_tidy_sd) %>% 
 left_join(lab_liwc_women %>% 
    group_by(gender, short_list, y_since_start) %>% summarise(n=n())) %>%
 mutate(se = sd / sqrt(n),
   lower_ci = weighted_mean - qt(1 - (0.05 / 2), n - 1) * se,
   upper_ci = weighted_mean + qt(1 - (0.05 / 2), n - 1) * se)

lab_liwc_women2_subset <- lab_liwc_women2 %>%
  filter(attribute %in% c(fem_mac, "WC"))

```


The following plots show changes in the occurences of selected LIWC terms, words-per-sentence, total word count and Fleschâ€“Kincaid grade level, over the course of an MP's career. There do not appear to be any notable changes in speaking style over the course of female Labour MPs' careers.

```{r short-list-plot-key-variables, include=FALSE}
library(ggplot2)

lab_liwc_women2_subset$attribute <- recode(lab_liwc_women2_subset$attribute,
               "pronoun" = "All Pronouns",
               "i" = "First person singular pronouns",
               "verb" = "Verbs",
               "auxverb" = "Auxiliary verbs",
               "social" = "Social processes ",
               "posemo" = "Positive emotions",
               "negemo" = "Negative emotions",
               "tentat" = "Tentative words",
               "Sixltr" = "More than six letters",
               "we" = "First person plural pronouns",
               "article" = "Articles",
               "prep" = "Prepositions",
               "anger" = "Anger words",
               "swear" = "Swear words",
               "cogproc" = "Cognitive processes",
               "WPS" = "Words per Sentence",
               "WC" = "Total Word Count",
               "FK" = "Flesh-Kincaid Grade Level")

lab_liwc_women2_subset$short_list <- recode(
  as.factor(lab_liwc_women2_subset$short_list), 
  "FALSE" = "Open Short List",
  "TRUE" = "All Women Short List")

p_sl1 <- ggplot(data=filter(lab_liwc_women2_subset, 
                            attribute != "Words per Sentence", 
                            attribute != "Total Word Count"),
                aes(x = y_since_start, y = weighted_mean, colour = short_list)) + 
  geom_line(alpha=0.7) +
  scale_y_continuous(labels = function(x) paste0(x, "%")) +
  facet_wrap(~attribute) + 
  labs(title = "Occurence of selected LIWC terms", colour = "") + 
  ylab("Weighted Mean") +
  xlab("Years since entering House of Commons") + 
  theme(legend.position = "bottom")

p_sl1

```


```{r sl-wps-plot, include=FALSE}
p_sl_wps <- ggplot(data=filter(lab_liwc_women2_subset,
                               attribute=="Words per Sentence"),
                aes(x=y_since_start, y = weighted_mean, colour = short_list)) +
  geom_line(alpha=0.7) +
  labs(title = "Words per Sentence", colour = "") + 
  ylab("Weighted Mean") +
  xlab("Years since entering House of Commons") + 
  theme(legend.position = "bottom")

p_sl_wps
```

```{r sl-wc-plot, include=FALSE}
p_sl_wc <- ggplot(data=filter(lab_liwc_women2_subset,
                               attribute=="Total Word Count"),
                aes(x=y_since_start, y = weighted_mean, colour = short_list)) +
  geom_line(alpha=0.7) +
  labs(title = "Total Word Count per Speech", colour = "") + 
  ylab("Mean") +
  xlab("Years since entering House of Commons") + 
  theme(legend.position = "bottom")

p_sl_wc
```



```{r, echo=FALSE,results = 'asis'}
fem_mac_df_sl <- tibble::tibble(
  word_type = fem_mac,
  short_list = c(1:length(fem_mac)),
  short_list_sd = c(1:length(fem_mac)),
  non_short_list = c(1:length(fem_mac)),
  non_short_list_sd = c(1:length(fem_mac)),
  cohen_d = c(1:length(fem_mac)),
  magnitude = c(1:length(fem_mac)))

lab_liwc_women$short_list <- as.factor(lab_liwc_women$short_list)

for (i in fem_mac) {
  d <- (cohen.d(lab_liwc_women[[i]], lab_liwc_women$short_list, na.rm = TRUE,
                noncentral = FALSE, pooled = TRUE))
  fem_mac_df_sl$short_list[fem_mac_df_sl$word_type==i] <-
    mean(lab_liwc_women[lab_liwc_women$short_list == TRUE, i], na.rm = TRUE)
  fem_mac_df_sl$non_short_list[fem_mac_df_sl$word_type==i] <- 
    mean(lab_liwc_women[lab_liwc_women$short_list == FALSE, i], na.rm = TRUE)
  fem_mac_df_sl$short_list_sd[fem_mac_df_sl$word_type==i]  <- 
      sd(lab_liwc_women[lab_liwc_women$short_list == TRUE, i], na.rm = TRUE)
  fem_mac_df_sl$non_short_list_sd[fem_mac_df_sl$word_type==i] <- 
    sd(lab_liwc_women[lab_liwc_women$short_list == FALSE, i], na.rm = TRUE)
  fem_mac_df_sl$cohen_d[fem_mac_df_sl$word_type == i] <- 
    d$estimate[[1]]
  fem_mac_df_sl$magnitude[fem_mac_df_sl$word_type == i] <-
    as.character(d$magnitude[[1]])
}

fem_mac_df_sl$word_type <- recode(fem_mac_df_sl$word_type,
               "pronoun" = "All Pronouns",
               "i" = "First person singular pronouns",
               "verb" = "Verbs",
               "auxverb" = "Auxiliary verbs",
               "social" = "Social processes ",
               "posemo" = "Positive emotions",
               "negemo" = "Negative emotions",
               "tentat" = "Tentative words",
               "Sixltr" = "More than six letters",
               "we" = "First person plural pronouns",
               "article" = "Articles",
               "prep" = "Prepositions",
               "anger" = "Anger words",
               "swear" = "Swear words",
               "cogproc" = "Cognitive processes",
               "WPS" = "Words per Sentence",
               "WC" = "Total Word Count",
               "FK" = "Flesh-Kincaid Grade Level")

```

```{r sl-effect-sizes, echo=FALSE, results = 'asis'}
library(knitr)
library(kableExtra)
kable(fem_mac_df_sl, digits = 2, 
      caption = "Effect Sizes for Female Labour MPs by selection process",
      col.names = c("", "Mean", "SD", "Mean", "SD",
                    "Cohen's D", "Magnitude")) %>%
  kable_styling(latex_options = "striped") %>% 
  add_header_above(c(" " = 1, "All Women Short lists" = 2,
                     "Open Shorlists" = 2, "Effect Size" = 2))

```


There are no categories among female Labour MPs by selection process meeting the $|0.2|$ threshold. Only one category -- first person plural pronouns, _d_=0.19 -- exceeded $|0.1|$.


```{r eval=FALSE, include=FALSE}
library(spacyr)
library(progress)

lab_speech <- read_rds("lab_speech.rds")

lab_speech$year <- as.factor(lab_speech$year)

split_data <- split(lab_speech, lab_speech$year) ### Splitting data variable

all_names <- names(split_data)

pb_save <- progress_bar$new(total = length(all_names),
                            format = "[:bar] :percent ETA: :eta Elapsed: :elapsedfull")

for (this_name in all_names) {
  save_name <- paste0(this_name, "x.rds")
  write_rds(split_data[[this_name]], path = save_name)
  pb_save$tick()
}


# 
# lab_corpus_sample <- corpus(lab_speech_sample,
#                             docid_field = "eo_id", text_field = "speech")
# 
# system.time(
#   lab_annotate_sample <- spacy_parse(lab_corpus_sample, tag = TRUE,
#                                    dependency = TRUE,  lemma = FALSE,
#                                    pos = FALSE) # need to use lab_corpus for this
# )


#devtools::install_github("quanteda/spacyr")
#spacy_install(python_path = "/Users/evanodell/Documents/anaconda3/bin/python3")
spacy_initialize()

atemp <- list.files(pattern = "*x.rds")

pb <- progress_bar$new(total = length(atemp), 
                       format = "[:bar] :percent ETA: :eta Elapsed: :elapsedfull\n")

for (i in atemp) {
   pb$tick(0)
  
  df <- read_rds(i)
  
  message(cat("Corpusising "), i, "\n")
  
  lab_corpus <- corpus(df, docid_field = "eo_id", text_field = "speech")
  
  i <- gsub("x.rds", "", i)
  
  message(cat("Annotating "), i, "\n")
  
  # need to use corpus object for this
  lab_annotate <- spacy_parse(lab_corpus, tag = TRUE, dependency = TRUE,
                            lemma = FALSE, pos = FALSE, entity = TRUE) 
 
  save_name <- paste0("./annotated/ano_", i, ".rds")
  
  write_rds(lab_annotate, path = save_name)
  
  pb$tick()
  
  gc()

}

atemp2 <- list.files("./annotated/", pattern = "*.rds")

atemp2 <- paste0("annotated/", atemp2)

df.list <- sapply(atemp2, read_rds, simplify = FALSE)

annotated_labour <- bind_rows(df.list)

rm(df.list, atemp2)

write_rds(annotated_labour, "annotated_labour.rds")

### Calculate the number of different parts of speech



```

```{r eval=FALSE, include=FALSE}
# !diagnostics off
library(readr)
library(dplyr)
annotated_labour <- read_rds("annotated_labour.rds")

post_df <- tibble::tribble(
     ~tag,    ~POS,
  "-LRB-", "PUNCT",
  "-RRB-", "PUNCT",
      ",", "PUNCT",
      ":", "PUNCT",
      ".", "PUNCT",
     "''", "PUNCT",
   "\"\"", "PUNCT",
     "``", "PUNCT",
      "$",   "SYM",
    "ADD",     "X",
    "AFX",   "ADJ",
    "BES",  "VERB",
     "CC",  "CONJ",
     "CD",   "NUM",
     "DT",   "DET",
     "EX",   "ADV",
     "FW",     "X",
     "GW",     "X",
    "HVS",  "VERB",
   "HYPH", "PUNCT",
     "IN",   "ADP",
     "JJ",   "ADJ",
    "JJR",   "ADJ",
    "JJS",   "ADJ",
     "LS", "PUNCT",
     "MD",  "VERB",
    "NFP", "PUNCT",
    "NIL",    "NA",
     "NN",  "NOUN",
    "NNP", "PROPN",
   "NNPS", "PROPN",
    "NNS",  "NOUN",
    "PDT",   "ADJ",
    "POS",  "PART",
    "PRP",  "PRON",
   "PRP$",   "ADJ",
     "RB",   "ADV",
    "RBR",   "ADV",
    "RBS",   "ADV",
     "RP",  "PART",
    "_SP", "SPACE",
    "SYM",   "SYM",
     "TO",  "PART",
     "UH",  "INTJ",
     "VB",  "VERB",
    "VBD",  "VERB",
    "VBG",  "VERB",
    "VBN",  "VERB",
    "VBP",  "VERB",
    "VBZ",  "VERB",
    "WDT",   "ADJ",
     "WP",  "NOUN",
    "WP$",   "ADJ",
    "WRB",   "ADV",
     "XX",     "X"
  )

post_df$POS <- as.factor(post_df$POS)

annotated_labour <- annotated_labour %>% left_join(post_df)

summary(annotated_labour)

write_rds(annotated_labour, "annotated_labour.rds")

```

## POS Analysis

Part-of-speech (POS) tagging was done using `spaCy` [@honnibal2017] and the `spacyr` package [@benoit2018a]. 

```{r tidying-annotations, eval=FALSE, include=FALSE}
library(readr)
library(dplyr)
library(magrittr)
library(tidyr)
library(effsize)

ano_lab <- read_rds("annotated_labour.rds")

ano_lab_tag <- ano_lab %>% 
  filter(POS != "PUNCT", is.na(POS) == FALSE, POS != "SPACE") %>%
  group_by(doc_id, tag) %>%
  summarise(count = n()) %>%
  mutate(freq = count / sum(count)) %>% ungroup() 

ano_lab_tag$count <- NULL

ano_lab_tag <- ano_lab_tag %>% spread(tag, freq)

ano_lab_tag[is.na(ano_lab_tag)] <- 0

ano_lab_pos <- ano_lab %>% 
  filter(POS != "PUNCT", is.na(POS) == FALSE, POS != "SPACE") %>%
  group_by(doc_id, POS) %>%
  summarise(count = n()) %>%
  mutate(freq = count / sum(count)) %>% ungroup() 

ano_lab_pos$count <- NULL

ano_lab_pos <- ano_lab_pos %>% spread(POS, freq)

ano_lab_pos[is.na(ano_lab_pos)] <- 0

lab_speech <- read_rds("lab_speech.rds")

ano_lab_tag <- ano_lab_tag %>% 
  left_join(select(lab_speech, eo_id, gender, short_list),
            by = c("doc_id"="eo_id"))

ano_lab_pos <- ano_lab_pos %>% 
  left_join(select(lab_speech, eo_id, gender, short_list),
            by = c("doc_id"="eo_id"))

ano_lab_pos$short_list <- as.factor(ano_lab_pos$short_list)
ano_lab_tag$short_list <- as.factor(ano_lab_tag$short_list)

write_rds(ano_lab_pos, "ano_lab_pos.rds")

write_rds(ano_lab_tag, "ano_lab_tag.rds")

```


```{r tag-means, include=FALSE}

library(readr)
library(purrr)
library(dplyr)

ano_lab_tag <- read_rds("ano_lab_tag.rds")

### POS

#word_types_tags <- c("NN", "NNS")

ano_lab_tag_gender <- ano_lab_tag %>% 
  select(NN, NNS, gender) %>% 
  #gather(key = "type", value = "value", NN, NNS) %>%
  group_by(gender)

ano_lab_tag_gender2 <- ano_lab_tag_gender %>% 
  gather(key = "type", value = "value", NN, NNS) %>%
  group_by(gender, type) %>%
  summarise(mean = mean(value, na.rm = TRUE),
            sd = sd(value, na.rm = TRUE))

ano_lab_tag_sl <- ano_lab_tag %>%
  select(NN, NNS, short_list, gender) %>% 
  #gather(key = "type", value = "value", NN, NNS) %>%
  group_by(short_list) %>% filter(gender == "Female") %>% select(-gender)

ano_lab_tag_sl2 <- ano_lab_tag_sl %>% 
  gather(key = "type", value = "value", NN, NNS) %>%
  group_by(short_list, type) %>%
  summarise(mean = mean(value, na.rm = TRUE),
            sd = sd(value, na.rm = TRUE))
```


```{r pos-means, include=FALSE}
library(readr)
library(purrr)
library(dplyr)

ano_lab_pos <- read_rds("ano_lab_pos.rds")

ano_lab_pos_gender <- ano_lab_pos %>% 
  select(NOUN, ADV, VERB, ADJ, gender) %>% 
  group_by(gender)

ano_lab_pos_gender2 <- ano_lab_pos_gender %>% 
  gather(key = "type", value = "value", NOUN, ADV, VERB, ADJ) %>%
  group_by(gender, type) %>%
  summarise(mean = mean(value, na.rm = TRUE),
            sd = sd(value, na.rm = TRUE))

ano_lab_pos_sl <- ano_lab_pos %>%
  select(NOUN, ADV, VERB, ADJ, short_list, gender) %>% 
  group_by(short_list) %>% filter(gender == "Female") %>% select(-gender)

ano_lab_pos_sl2 <- ano_lab_pos_sl %>% 
  gather(key = "type", value = "value", NOUN, ADV, VERB, ADJ) %>%
  group_by(short_list, type) %>%
  summarise(mean = mean(value, na.rm = TRUE),
            sd = sd(value, na.rm = TRUE))

# ano_lab_pos_sl3 <- list(.vars = lst(c("NOUN", "ADV", "VERB", "ADJ")),
#                         .funs = lst(funs(mean = mean, sd = sd,
#                                          .args = c(na.rm = TRUE)))) %>% 
#   pmap(~ ano_lab_pos_sl %>% group_by(short_list) %>% summarise_at(.x, .y)) %>% 
#   reduce(inner_join, by = "short_list")
```

```{r pos-tag-tables, include=FALSE}

pos_df_gender <- bind_rows(ano_lab_pos_gender2, ano_lab_tag_gender2)

pos_df_gender <- pos_df_gender %>% 
  gather(variable, value, -(gender:type)) %>%
  unite(temp, gender, variable) %>%
  spread(temp, value)

pos_df_gender$cohen_d <- NA
pos_df_gender$magnitude <- NA

for (i in pos_df_gender$type) {
  
  if (i=="NN" || i == "NNS") {
  
   d <- (cohen.d(ano_lab_tag[[i]], ano_lab_tag$short_list,
                na.rm = TRUE, noncentral = FALSE, pooled = TRUE))
  } else {
    
     d <- (cohen.d(ano_lab_pos[[i]], ano_lab_pos$short_list,
                na.rm = TRUE, noncentral = FALSE, pooled = TRUE))
  }
   
  pos_df_gender$cohen_d[pos_df_gender$type==i] <- (d$estimate[[1]])
  
  pos_df_gender$magnitude[pos_df_gender$type==i] <- as.character(d$magnitude[[1]])
}

pos_df_gender$type <- factor(pos_df_gender$type, levels=c("NOUN", "NNS", "NN", "ADJ", "ADV", "VERB"))

## Recoding pos_df_sl$type into pos_df_sl$type_rec
pos_df_gender$type <- recode(pos_df_gender$type,
               "NOUN" = "All Nouns",
               "NNS" = "Plural Nouns",
               "NN" = "Singular Nouns",
               "ADJ" = "Adjectives",
               "ADV" = "Adverbs",
               "VERB" = "Verbs")

pos_df_gender <- pos_df_gender[order(pos_df_gender$type),]

pos_df_gender[2:5] <- pos_df_gender[2:5] * 100

pos_df_sl <- bind_rows(ano_lab_pos_sl2, ano_lab_tag_sl2)

pos_df_sl <- pos_df_sl %>% 
  gather(variable, value, -(short_list:type)) %>%
  unite(temp, short_list, variable) %>%
  spread(temp, value)

pos_df_sl$cohen_d <- NA
pos_df_sl$magnitude <- NA

for (i in pos_df_sl$type) {
  
  if (i=="NN" || i == "NNS") {
  
   d <- (cohen.d(ano_lab_tag[[i]], ano_lab_tag$short_list,
                na.rm = TRUE, noncentral = FALSE, pooled = TRUE))
  } else {
    
     d <- (cohen.d(ano_lab_pos[[i]], ano_lab_pos$short_list,
                na.rm = TRUE, noncentral = FALSE, pooled = TRUE))
  }
   
  pos_df_sl$cohen_d[pos_df_sl$type==i] <- (d$estimate[[1]])
  
  pos_df_sl$magnitude[pos_df_sl$type==i] <- as.character(d$magnitude[[1]])
}

pos_df_sl$type <- factor(pos_df_sl$type, levels=c("NOUN", "NNS", "NN", "ADJ", "ADV", "VERB"))

## Recoding pos_df_sl$type into pos_df_sl$type_rec
pos_df_sl$type <- recode(pos_df_sl$type,
               "NOUN" = "All Nouns",
               "NNS" = "Plural Nouns",
               "NN" = "Singular Nouns",
               "ADJ" = "Adjectives",
               "ADV" = "Adverbs",
               "VERB" = "Verbs")

pos_df_sl <- pos_df_sl[order(pos_df_sl$type),]

pos_df_sl[2:5] <- pos_df_sl[2:5] * 100

```


```{r pos-gender-table, echo=FALSE, results = 'asis'}
library(knitr)
library(kableExtra)
kable(pos_df_gender, digits = 2, 
      caption = "Part-of-Speech Effect Sizes for Male and Female Labour MPs",
      col.names = c("Word Type", "Mean", "SD", "Mean", "SD",
                    "Cohen's D", "Magnitude") )  %>%
  kable_styling(latex_options = "striped") %>% 
  add_header_above(c(" " = 1, "Women" = 2, "Men" = 2, "Effect Size" = 2)) %>%
  add_indent(c(2:3))
```


```{r pos-sl-table, echo=FALSE, results = 'asis'}
library(knitr)
library(kableExtra)
kable(pos_df_sl, digits = 2, 
      caption = "Part-of-Speech Effect Sizes for Male and Female Labour MPs",
      col.names = c("Word Type", "Mean", "SD", "Mean", "SD",
                    "Cohen's D", "Magnitude"))  %>%
  kable_styling(latex_options = "striped") %>% 
  add_header_above(c(" " = 1, "All Women Short lists" = 2,
                     "Open Shorlists" = 2, "Effect Size" = 2)) %>%
  add_indent(c(2:3))
```


## Tokenising / Keyness

The most commonly used words by both men and women would be protocol boilerplate expressions, so we calculate the keyness of words to identify gender differences in the choices of topics raised by men and women, and by short-list and non-short list women.

### Men vs Women

```{r dfm-creation, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
library(readr)
library(dplyr)
library(quanteda)

lab_corpus <- read_rds("lab_corpus.rds")

parliament_stopwords <- c(stopwords(), "hon", "rose", "n", "friend", "way", 
                          "give", "gentleman", "right", "percent", "per",
                          "cent", "prime", "minister")

lab_dfm_key <- lab_corpus %>% 
  dfm(remove = parliament_stopwords, remove_punct = TRUE,
      verbose = TRUE, groups = "gender") %>%
  dfm_weight("count")

write_rds(lab_dfm_key, "lab_dfm_key.rds")

lab_corpus_fem <- corpus_subset(lab_corpus, gender=="Female")

lab_dfm_key_fem <- lab_corpus_fem %>% 
  dfm(remove = parliament_stopwords, remove_punct = TRUE,
      verbose = TRUE, groups = "short_list") %>%
  dfm_weight("count")

write_rds(lab_dfm_key_fem, "lab_dfm_key_fem.rds")
```

```{r gender-keyness, include=FALSE}
library(ggplot2)
lab_keyness <- textstat_keyness(lab_dfm_key, measure = c("chi2"))

#head(lab_keyness)

lab_keyness_plot <- textplot_keyness(lab_keyness, n=15) +  
  coord_cartesian(xlim=c(-5000, 14800)) +
  labs(title = "Keyness in Labour MPs by Gender",
       x = "Chi2")


lab_keyness_plot
## Figure out what the fuck is up with Hull?
```

Keyness -- a linguistic measure of the frequency of different words in two groups of texts -- reveals clear gender differences in the most disproportionately common words used by female and male Labour MPs. Unsurprisingly, despite male MPs saying almost twice as many words (30601887 vs 15898845) <!--Double-check these numbers--> as their female colleagues, female Labour MPs were more than two-and-a-half (2.61) times as likely to say "women". They were also much more likely to refer to "women's" and "woman". Female Labour MPs also appear much more likely to discuss "children", "people", "care", "families", "home", "parents", "work" and social policy areas such as "services", "disabled [people]" and "housing" than their male colleagues. Male MPs were more likely to refer to military topics ("Iraq", "nuclear"), and to parliamentary process and protocol  -- "question", "political", "conservative", "electoral", "house", "party", "argument" "liberal" and "point" are far more common in speeches by male Labour MPs than by female ones. This could suggest that male MPs are more comfortable using the traditional language of House of Commons debate.

### Short lists vs Non-Short lists

```{r short-list-keyness, include=FALSE}

lab_keyness_fem <- textstat_keyness(lab_dfm_key_fem, measure = c("chi2"))

#head(lab_keyness_fem)

fem_keyness_plot <- textplot_keyness(lab_keyness_fem, n=15) + 
  coord_cartesian(xlim=c(-1700,1000)) +
  labs(title = "Keyness in Female Labour MPs by Selection Process",
       x = "Chi2")

fem_keyness_plot

```


Keyness differences by selection process are not as obviously stereotypical. Nonetheless, the most common words amongst AWS MPs included "carers", "disabled", "bedroom" and "sen"[^2]. Also of note is AWS MPs making more references to their "constituency" and its "constituents"



## Topic Models

### Short lists vs Non-Short lists

```{r topic-model-women, eval=FALSE, include=FALSE}
library(quanteda)
library(quanteda.corpora)
library(lubridate)
library(topicmodels)
library(readr)

lab_corpus <- read_rds("lab_corpus.rds")

lab_corpus_fem <- corpus_subset(lab_corpus, gender=="Female")

ndoc(lab_corpus_fem)

lab_corpus_fem_dfm <- dfm(lab_corpus_fem, remove_punct = TRUE,
                           remove = parliament_stopwords) %>% 
  dfm_remove(c('*-time', '*-timeUpdated', 'GMT', 'BST')) %>% 
  dfm_trim(min_termfreq = 0.95, termfreq_type = "quantile", 
           max_docfreq = 0.1, docfreq_type = "prop")

lab_corpus_fem_dfm <- lab_corpus_fem_dfm[ntoken(lab_corpus_fem_dfm) > 0,]

dtm <- convert(lab_corpus_fem_dfm, to = "topicmodels")
fem_lda <- LDA(dtm, k = 20) #

terms(fem_lda, 10)

docvars(lab_corpus_fem_dfm, 'topic') <- topics(lda)
head(topics(fem_lda), 20)

write_rds(fem_lda, "fem_lda.rds")

write_rds(lab_corpus_fem_dfm, "lab_corpus_fem_dfm.rds")
```
<!--
```{r topic-model-short-list, eval=FALSE, include=FALSE}

lab_corpus_fem_sl <- corpus_subset(lab_corpus, gender == "Female",
                                   short_list == TRUE)

lab_corpus_fem_dfm_sl <- dfm(lab_corpus_fem_sl, remove_punct = TRUE,
                          remove = parliament_stopwords) %>% 
  dfm_trim(min_termfreq = 0.95, termfreq_type = "quantile", 
           max_docfreq = 0.1, docfreq_type = "prop")

lab_corpus_fem_dfm_sl <- lab_corpus_fem_dfm_sl[ntoken(lab_corpus_fem_dfm_sl) > 0,]

dtm_sl <- convert(lab_corpus_fem_dfm_sl, to = "topicmodels")
fem_lda_sl <- LDA(dtm_sl, k = 15) #

docvars(lab_corpus_fem_dfm_sl, 'topic') <- topics(fem_lda_sl)

write_rds(fem_lda_sl, "fem_lda_sl.rds")

write_rds(lab_corpus_fem_dfm_sl, "lab_corpus_fem_dfm_sl.rds")
```

```{r topic-model-non-short-list, eval=FALSE, include=FALSE}

lab_corpus_fem_not_sl <- corpus_subset(lab_corpus, gender == "Female",
                                       short_list == FALSE)

lab_corpus_fem_dfm_not_sl <- dfm(lab_corpus_fem_not_sl, remove_punct = TRUE,
                             remove = parliament_stopwords) %>% 
  dfm_trim(min_termfreq = 0.95, termfreq_type = "quantile", 
           max_docfreq = 0.1, docfreq_type = "prop")

lab_corpus_fem_dfm_not_sl <- lab_corpus_fem_dfm_not_sl[ntoken(lab_corpus_fem_dfm_not_sl) > 0,]

dtm_not_sl <- convert(lab_corpus_fem_dfm_not_sl, to = "topicmodels")
fem_lda_not_sl <- LDA(dtm_not_sl, k = 15) #

docvars(lab_corpus_fem_dfm_not_sl, 'topic') <- topics(fem_lda_not_sl)

write_rds(fem_lda_not_sl, "fem_lda_not_sl.rds")

write_rds(lab_corpus_fem_dfm_not_sl, "lab_corpus_fem_dfm_not_sl.rds")

```
-->

```{r topic-model-analysis, echo=FALSE}
library(readr)
library(topicmodels)
library(quanteda)
library(dplyr)
library(ggplot2)

fem_lda <- read_rds("fem_lda.rds")

lab_corpus_fem_dfm <- read_rds("lab_corpus_fem_dfm.rds")

terms_table <- tibble::as.tibble(terms(fem_lda, 10))

fem_df <- as.data.frame(docvars(lab_corpus_fem_dfm))

fem_df$topic <- recode(fem_df$topic,
               "1" = "Topic 1",
               "2" = "Topic 2",
               "3" = "Topic 3",
               "4" = "Topic 4",
               "5" = "Topic 5",
               "6" = "Topic 6",
               "7" = "Topic 7",
               "8" = "Topic 8",
               "9" = "Topic 9",
               "10" = "Topic 10"
               )
fem_df$topic <- factor(fem_df$topic)

fem_df2 <- fem_df %>%
  group_by(short_list, topic) %>%
  summarise(topic_count = n()) %>%
    mutate(freq = topic_count / sum(topic_count))

fem_df2$topic <- factor(fem_df2$topic, 
                        levels=c("Topic 1", "Topic 2", "Topic 3", "Topic 4",
                                 "Topic 5", "Topic 6", "Topic 7", "Topic 8",
                                 "Topic 9", "Topic 10"))

fem_df2 <- fem_df2[order(-fem_df2$short_list, fem_df2$topic),]

p_lda <- ggplot(fem_df2, aes(x = short_list, y=freq)) +
  geom_col(aes(fill = topic)) +
  scale_y_continuous(labels=scales::percent) + 
  labs(title = "Frequency of Topic Models",
       subtitle = "Female Labour MPs grouped by selection process",
       fill = "Topic Model") + 
  ylab("") + 
  xlab("Elected Through All Women Short list")

p_lda

```


```{r topic-model-table, echo=FALSE, results = 'asis'}
library(pander)
pander(terms_table, caption = "Topic Model Terms",
       split.table = 80, style = 'rmarkdown', justify = 'left')

# library(knitr)
# library(kableExtra)
# kable(terms_table, caption = "Topic Model Terms")  %>%
#   kable_styling(full_width = TRUE, latex_options = "striped") %>%
#   landscape()

```


```{r topic-model-distribution-table, echo=FALSE, results = 'asis'}

#fem_df2$freq <- paste0(round(fem_df2$freq * 100, 2), "%")

fem_df2 <- fem_df2 %>% ungroup() %>% select(-freq)

fem_df2_table <- fem_df2 %>% ungroup() %>%
  spread(short_list, topic_count) %>%
  mutate(not_sl_freq = (`FALSE` / sum(`FALSE`))*100, 
         sl_freq = (`TRUE` / sum(`TRUE`))*100) %>%
  rename("not_sl_total" = `FALSE`, "sl_total" = `TRUE`)


library(knitr)
library(kableExtra)
kable(fem_df2_table, caption = "Topic Model Distribution", digits = 2, 
      col.names = c("Topic", "Not Short List Total", "Short List Total",
                    "Not Short List Percentage", "Short List Percentage")) %>%
  kable_styling(full_width = FALSE)


```

We assigned topic models using Latent Dirichlet Allocation [@blei2003], implemented in the `topicmodels` R package [@grun2011]. See [TABLE NUMBER?] for the ten most common words in each topic model. 

Non-AWS women had more speeches assigned to topic 3 (14.20% vs 10.05%), a topic that, like the gender-differences in word keyness above, refers to the parliamentary process itself. Conversely, AWS women had more speeches in topic 1 (15.23% vs 12.55%) which also includes multiple references to the parliamentary process itself.


## Machine learning

We trained a Naive Bayes classifier with document-frequency priors and a multinomial distribution to predict the gender of speakers when given speeches by all Labour MPs in our dataset, and the selection process when only given female Labour MPs. The accuracy of both models were roughly equivalent, 70.83% accuracy when predicting gender and 70.31% when predicting short lists.

```{r naive-bayes1, eval=FALSE, include=FALSE}
library(quanteda)
library(quanteda.corpora)
library(caret)
library(readr)

lab_corpus <- read_rds("lab_corpus.rds")

#set.seed(42)
id_train <- sample(1:262071, 104828, replace = FALSE) ## 40% in training
#head(id_train, 10)

docvars(lab_corpus, "id_numeric") <- 1:ndoc(lab_corpus)

# get training set
training_dfm <- corpus_subset(lab_corpus, id_numeric %in% id_train) %>%
  dfm(stem = TRUE)

# get test set (documents not in id_train)
test_dfm <- corpus_subset(lab_corpus, !id_numeric %in% id_train) %>%
  dfm(stem = TRUE)

nb <- textmodel_nb(training_dfm, docvars(training_dfm, "gender"),
                   prior = "docfreq")
#summary(nb)

test_dfm <- dfm_select(test_dfm, training_dfm)

actual_class <- docvars(test_dfm, "gender")
predicted_class <- predict(nb, test_dfm)
class_table <- table(actual_class, predicted_class)
class_table

gender_accuracy <- confusionMatrix(class_table, mode = "everything")
gender_accuracy$overall[[1]]

```

```{r naive-bayes2, eval=FALSE, include=FALSE}

### Short List classification
lab_corpus_fem <- corpus_subset(lab_corpus, gender=="Female")

#set.seed(42)
id_train <- sample(1:84572, 33829, replace = FALSE) ## 40% in training
head(id_train, 10)

docvars(lab_corpus_fem, "id_numeric") <- 1:ndoc(lab_corpus_fem)

# get training set
training_dfm <- corpus_subset(lab_corpus_fem, id_numeric %in% id_train) %>%
  dfm(stem = TRUE)

# get test set (documents not in id_train)
test_dfm <- corpus_subset(lab_corpus_fem, !id_numeric %in% id_train) %>%
  dfm(stem = TRUE)

nb_fem <- textmodel_nb(training_dfm, docvars(training_dfm, "short_list"),
                   prior = "docfreq")
summary(nb_fem)

test_dfm <- dfm_select(test_dfm, training_dfm)

actual_class <- docvars(test_dfm, "short_list")
predicted_class <- predict(nb_fem, test_dfm)
class_table <- table(actual_class, predicted_class)
class_table

sl_accuracy <- confusionMatrix(class_table, mode = "sens_spec")
sl_accuracy$overall[[1]]
```

```{r svm, eval=FALSE, include=FALSE}
library(readr)
library(quanteda)
library(tidyr)
library(e1071) ## look up name of this SVM library
library(dplyr)

parliament_stopwords <- c(stopwords(), "hon", "rose", "n", "friend", "way", 
                          "give", "gentleman", "right", "percent", "per",
                          "cent", "prime", "minister")

lab_corpus <- read_rds("lab_corpus.rds")

lab_corpus2 <- corpus_sample(lab_corpus, size = 1000, replace = TRUE)

lab_dfm2 <- lab_corpus2 %>% 
  dfm(remove = parliament_stopwords, remove_punct = TRUE,
      verbose = TRUE) 

x2 <- as.data.frame(as.matrix(lab_dfm2), row.names = docnames(lab_dfm2))

#x2 <- convert(lab_dfm2, to = "tm", docvars = docvars(lab_corpus2))

x2$eo_id <- row.names(x2)

y <- docvars(lab_corpus2)

y$eo_id <- row.names(y)

y <- select(y, gender, eo_id) %>% rename(mp_gender=gender)

x3 <- left_join(x2, y)

x3$mp_gender <- as.factor(x3$mp_gender)

# #x <- x[,2:3402]
# 
# x2 <- as.data.frame(t(x))
# 
# x2 <- x2[,2:3402]
# 
# x3 <- gather(x2, key = "gender", value = "count")
# # 
# # x2 <- as.data.frame(t(x))
# # 
# # 
index     <- 1:nrow(x3)
   testindex <- sample(index, trunc(length(index)/3))
   testset   <- x3[testindex,]
   trainset  <- x3[-testindex,]

    ## svm
    #   svm.model <- svm(Type ~ ., data = trainset, cost = 100, gamma = 1)
    # svm.pred  <- predict(svm.model, testset[,-10])   

model <- svm(gender~., data = trainset) ## This is failing, find out why
pred  <- predict(model, testset[,-10])   



## need to get svm(x,y) working, with vector of document classes

lab_dfm_fem <- read_rds("lab_dfm_key_fem.rds")

vm.model <- svm(docs ~ ., data = x, cost = 100, gamma = 1)

 data(Glass, package="mlbench")
 ## split data into a train and test set
   index     <- 1:nrow(Glass)
   testindex <- sample(index, trunc(length(index)/3))
   testset   <- Glass[testindex,]
   trainset  <- Glass[-testindex,]

```

## Discussion

There do not appear to be substantial or meaningful differences in the speaking styles or topic choices of female Labour MPs selected through all women short lists when compared to their female colleagues selected through open short lists. Small differences between male and female Labour MPs were not replicated when comparing female Labour MPs by how they were selected.


# References

[^1]: e.g. a reference to "the member for Bethnal Green and Bow" in keeping with Parliamentary convention of identifying MPs by their seat rather than their name would be followed by "(Rushnara Ali)".

[^2]: Special Educational Needs